---
title: "Muntjacs invading Germany"
subtitle: "Potential distribution of the small Deer (Cervidae) species Reeves’ Muntjac (Muntiacus reevesi) in Germany - Code documentation"
author: "Louis-Marvin Sander"
date: 
output:
  html_notebook:
    toc: true
    toc_float: true
    number_sections: true
    theme: united
  
---

```{r setup}
knitr::opts_chunk$set(eval = FALSE)
```

Generate the data outside of the repository.
```{r}
setwd(paste0(getwd(), "/.."))
```

# Preparation

## Packages
```{r}
library(raster)
library(tidyverse)
library(sf)
library(terra)
library(rgdal)
library(dismo)
library(tmap)
library(tmaptools)
library(magrittr)
library(pROC)
library(spdep)
library(stan4bart)
library(countrycode)
library(geodata)
library(whitebox)
library(readxl)
library(ROCR)
library(scales)
library(reshape2)
library(ggbreak)
library(ggstatsplot)
library(spatstat)
library(gridExtra)
library(xtable)
library(latex2exp)
```

## Seed
```{r}
set.seed(2121997)
```

## Self defined functions {.tabset}

### Negate
Negated version of the "Value Matching"-Function.

```{r}
`%!in%` <- Negate(`%in%`)
```

### Get n Minimal/Maximal result
Lists the first n results of a data frame sorted by a column. Interesting for seeing the most collinear values later on.

Input:

- __a__ = Data frame/tibble that should be displayed.
- __b__ = Column to sort the results.
- __c__ = Number of rows that should be displayed.
- __mode__ = c("max", "min") means either sort decreasing or increasing.

Output:

- __result__ = Ordered tibble with nrow() = c.

```{r}
owncount <- function(a, b, c = ncol(a), mode = c("max", "min")) {
    mode <- ifelse(mode == "max", TRUE, FALSE)
    if (c > nrow(a)) c <- nrow(a)
    result <- tibble()
    b <- match(b, colnames(a))
    result <- a[order(a[, b], decreasing = mode), ] %>% head(., n = c)
    return(result)
}
```

### Data Preparation
It automatically appends the data set with randomly sampled absence points based on the extent of the SpatRaster and creates data frames that can be used in the modelling process.
The data have to be in the same coordinate reference system.

Attention: This is the direct implementation of the rule of thumb after Huberty (1994) reviewed in [Fielding, A. H., & Bell, J. F. (1997)](https://doi.org/10.1017/S0376892997000088) for splitting into train and test data.

Inputs:

- __start__ = Environment as a SpatRaster with different layers as predictors.
- __species__ = Sf object of occurrence points.
- __most.important__ = Vector of variables threatened as important ones that should be extracted from the SpatRaster.
- __randoms__ = Same as most.important but for the random variables.

Output:

List of:

- __train.points__ = Sf object of model training points.
- __test.points__ = Sf object of model test points.
- __train.df__ = Data frame of variables at train points + pa = column for presence absence.
- __test.df__ = Data frame of variables at test points + pa = column for presence absence.
- __removedNA__ = Removed points due to NA in an environmental layer.

```{r}
fuzzySim::percentTestData(5) # in our case at the end 5 main variables

extraction_format <- function(start, species, most.important = NULL, randoms = NULL) {
    if (class(most.important) != "NULL") {
        start <- start[[c(most.important, randoms)]]
    }

    sample <- sample(
        c(TRUE, FALSE),
        nrow(species),
        replace = TRUE,
        prob = c(0.66, 0.33) # variable split after Huberty
    )

    species.train.points <- species[sample, ]
    species.test.points <- species[!sample, ]


    maxabsencepoints <- nrow(species.train.points)

    absences <- 
        dismo::randomPoints(
            mask = start[[1]] %>% 
                raster(), 
            n = maxabsencepoints, 
            p = species.train.points %>% 
                st_coordinates())
    
    absences.train <- absences

    species.train.df <- data.frame(
        rbind(
            terra::extract(start, species.train.points, ID = F),
            terra::extract(start, absences)
        ),
        pa = c(rep(1, nrow(absences)), rep(0, nrow(species.train.points)))
    ) %>%
        as_tibble()


    maxabsencepoints <- nrow(species.test.points)

    absences <- 
    dismo::randomPoints(
            mask = start[[1]] %>% 
                raster(), 
            n = maxabsencepoints, 
            p = species.test.points %>% 
                st_coordinates())

    absences.test <- absences

    species.test.df <- data.frame(
        rbind(
            terra::extract(start, species.test.points, ID = F),
            terra::extract(start, absences)
        ),
        pa = c(rep(1, nrow(absences)), rep(0, nrow(species.test.points)))
    ) %>%
        as_tibble()

    train.points <- 
        species.train.points %>%
        mutate(pa = 1) %>%
        select(pa, geometry) %>%
        add_row(
            st_as_sf(
                absences.train %>% as_tibble(), 
                coords = c("x", "y"), 
                crs = st_crs(species.train.points)
                ) %>% 
            mutate(pa = 0)
            )

    test.points <- 
        species.test.points %>%
        mutate(pa = 1) %>%
        select(pa, geometry) %>%
        add_row(
            st_as_sf(
                absences.test %>% 
                    as_tibble(), 
                coords = c("x", "y"), 
                crs = st_crs(species.test.points)
                ) %>% 
            mutate(pa = 0)
            )

    removedNA <- 
        list(
            train.data = 
                complete.cases(species.train.df) %>%
                table() %>%
                as_tibble() %>%
                rename("which" = ".") %>%
                mutate(which = c("Out", "In")),
            test.data = 
                complete.cases(species.test.df) %>%
                table() %>%
                as_tibble() %>%
                rename("which" = ".") %>%
                mutate(which = c("Out", "In"))
    )
    train.points <- train.points[complete.cases(species.train.df), ]
    test.points <- test.points[complete.cases(species.test.df), ]
    species.train.df <- species.train.df[complete.cases(species.train.df), ]
    species.test.df <- species.test.df[complete.cases(species.test.df), ]

    return(
        list(
            train.points = train.points,
            test.points = test.points,
            train.df = species.train.df,
            test.df = species.test.df,
            removedNA = removedNA
        )
    )
}
```

### wbt_resample bugfix

I do not know when it is fixed, therefore I included the fixed function here. For more information see issue on [GitHub](https://github.com/opengeos/whiteboxR/issues/112).
For documentation see: [WhiteboxTools](https://cran.r-project.org/web/packages/whitebox/whitebox.pdf).

```{r}
wbt_resample <- function(
    inputs, output, cell_size = NULL, base = NULL, method = "cc",
    wd = NULL, verbose_mode = FALSE, compress_rasters = FALSE,
    command_only = FALSE) {
    wbt_init()
    args <- ""
    args <- paste(args, paste0("--inputs=", whitebox:::wbt_file_path(inputs)))
    args <- paste(args, paste0("--output=", whitebox:::wbt_file_path(output)))
    if (!is.null(cell_size)) {
        args <- paste(args, paste0("--cell_size=", cell_size))
    }
    if (!is.null(base)) {
        args <- paste(args, paste0("--base=", whitebox:::wbt_file_path(base)))
    }
    if (!is.null(method)) {
        args <- paste(args, paste0("--method=", method))
    }
    if (!missing(wd)) {
        args <- paste(args, paste0("--wd=", whitebox:::wbt_file_path(wd))) # corrected error in this line
    }
    if (!missing(compress_rasters)) {
        args <- paste(args, paste0("--compress_rasters=", compress_rasters))
    }
    tool_name <- "resample"
    wbt_run_tool(tool_name, args, verbose_mode, command_only)
}
```


### Multi collinearity
Adapted "multicol" function from the "fuzzySim"-Package to display more information in the result.

Input:

- __vars__ = Data frame of environmental conditions.
- __model__ = Not needed in this context.
- __reorder__ = Order result at the end?

Output:

- result = tibble with several columns, nrow(result) = ncol(vars).
    - __Rsquared__ = R² of the built model.
    - __Tolerance__ = 1 - R²
    - __VIF__ = Variance Inflation Factor 1 / (1 - R²).
    - __count__ = Number of collinear variables.
    - __significant_vars__ = Significant collinear variables.
    - __insignificant_vars__ = Not collinear variables.

```{r}
multicol_own <- function(vars = NULL, model = NULL, reorder = TRUE) {
    if (is.null(vars)) {
        if (is.null(model)) {
            stop("You must provide either 'vars' or 'model'.")
        }
        if (!("glm" %in% class(model))) {
            stop("'model' must be an object of class 'glm'.")
        }
        vars <- model$model[, -1]
    }
    vars <- as.data.frame(vars)
    if (ncol(vars) < 2) {
        return(message("Cannot compute collinearity with less than two variables."))
    }

    result <- tibble(factor = colnames(vars))

    for (v in 1:ncol(vars)) {
        v.name <- colnames(vars)[v]
        other.v.names <- colnames(vars)[-v]
        mod.formula <- as.formula(paste(v.name, "~", paste(other.v.names,
            collapse = "+"
        )))
        mod <- lm(mod.formula, data = vars)
        R2 <- summary(mod)$r.squared
        result[v, "R²"] <- R2
        result[v, "Tolerance"] <- 1 - R2
        result[v, "VIF"] <- 1 / (1 - R2)
        result[v, "Count"] <- (summary(mod)$coefficients[, 4] < 0.05) %>%
            table() %>%
            .["TRUE"]
        result[v, "significant_vars"] <- enframe(list(names(summary(mod)$coefficients[, 4])[summary(mod)$coefficients[, 4] < 0.05][order(summary(mod)$coefficients[, 1][summary(mod)$coefficients[, 4] < 0.05])]))[2]
        result[v, "insignificant_vars"] <- enframe(list(names(summary(mod)$coefficients[, 4])[summary(mod)$coefficients[, 4] > 0.05][order(summary(mod)$coefficients[, 1][summary(mod)$coefficients[, 4] > 0.05])]))[2]
    }

    if (reorder) {
        result <- result[order(result$VIF, decreasing = TRUE), ]
    }
    return(result)
}
```


### Nearest distance
Creation of a vector that represents the distance of a point to the nearest feature.
This can be used if there is no raster available, for example if you want to use "distance to streets/urban areas".

Input:

- __a__ = Sf object, here: presence/absence points.
- __b__ = Sf object, here: polygons of cities, lines of streets, .... It can also be a named list if more than one variable should be added.

Output:

- __distance__ = Distance of every point in _a_ to the nearest polygon in _b_.

```{r}
nearestdistance_to <- function(a, b) {
    nearest <- vector()
    distance <- tibble(1:nrow(a))


    for (i in seq(1, length(b), 1)) {
        nearest <- st_nearest_feature(a, b[[i]])
        distance[, i] <- st_distance(a, b[[i]][nearest, ], by_element = TRUE) %>% as.vector()
    }
    names(distance) <- names(b)

    return(distance)
}
```

### Weights 
Creation of weights according to the number of features in a radius, means 0.5/n where n = number of points in a radius. 
That means, if n = 1, then the occurrence has one neighbour, therefore 0.5/1 = 0.5 and both occurrences are weighted 0.5.
Default: The radius of a circle that results in the average territorial size of the muntjac according to [Chapman et. al (1993)](https://doi.org/10.1111/j.1469-7998.1993.tb02660.x).

Input:

- __sf_geom__ = sf object of points, here: muntjac occurrences
- __buffer_radius__ = radius of a circle that results in the size of an average territory

Output:

- Vector of length(sf_geom) with values $\in$ [1,0[.

```{r}
nbfunction <- function(sf_geom, buffer_radius = 298.5411) {
    # function from the spdep package, count of neighbours within a radius
    dnearneigh(sf_geom, 0, buffer_radius) %>%
        # set NA to 0 neigbours
        lapply(function(x) ifelse(x == 0, NA, length(x))) %>%
        lapply(unique) %>%
        unlist() %>%
        # calculate the weights
        (function(x) (0.5 / x)) %>%
        # division by 0 not possible, therefore exchange NA by 0
        ifelse(is.na(.), 1, .)
}
```

### Brier Score
Get data out of a ROCR-Object and calculate the brier score.

Input: 

- ROCR-Object

Output:

- Brier Score

```{r}
get_and_calc_bri <- function(x) {
    tru <- x@labels %>%
        unlist() %>%
        as.character() %>%
        as.numeric()

    preds <- x@predictions %>% unlist()

    return(
        (1 / length(tru) * sum((preds - tru)^2))
    )
}
```


### Easy prediction wrapper - NOT RECOMMENDED!
Predicts a stan4bart model to a SpatRaster of environmental variables.
Only recommended if the raster is relatively small, low number of predictions or predictions to different raster are pending.
If you often use the same raster stack for prediction, use the other function where you have to export your raster as table first.

Input:

- __model__ = stan4bart object with "keepTrees = T".
- __raster__ = SpatRaster with new environment (for prediction) or old environment (for inter/extrapolation).
- __type__ = One of types of predict.stan4bartFit.

Output:

- __new_raster__ = Predicted raster.

```{r}
raster_pred_stan4bart <- function(model, raster, type = "ev") {
    # Raster conversion to df and save places where not NA, afterwards remove NAs
    data_map_df <- as.matrix(raster, xy = F, na.rm = F, byrow = T) %>% as.data.frame()
    data_map_df_comp <- which(complete.cases(data_map_df))
    data_map_df <- data_map_df[data_map_df_comp, ]

    # predicting the df with help of the generic function
    new_data <- predict.stan4bartFit(
        object = model,
        newdata = data_map_df,
        type = type,
        combine_chains = TRUE,
        sample_new_levels = TRUE
    ) %>%
        rowMeans(na.rm = T) # Here you can tweak how many iterations should be included at the end. If the model needs a long time for reaching convergence it might be interesting to look at different stages. Looking at only one iteration at once, you can see the model "learning".

    # preparation to rasterize the df
    pre_raster <- rep(NA, ncell(raster))
    pre_raster[data_map_df_comp] <- new_data
    pre_raster %<>%
        matrix(
            nrow = nrow(raster),
            ncol = ncol(raster),
            byrow = T
        )

    # create the new raster
    new_raster <- rast(
        pre_raster,
        crs = crs(raster),
        extent = ext(raster)
    )

    return(new_raster)
}
```

### Efficient prediction

#### Raster preparation
Function that converts a raster into a table for efficient reuse in prediction function.

Input:

- __in_raster__ = Raster stack to be converted.
- __in_vars__ = Names of the layers that should be converted.
- __save.path__ = Path where to store + Base name of the documents. Attention: File ending and identifier are added automatically.


Output = Two output files:

- __*_na-free.txt__ = Raster as table, every column that does not match "complete.cases()" removed.
- __*_comp_cases.txt__ = Vector of line numbers that match "complete.cases()".

```{r}
raster_prep_stan4bart <- function(in_raster, in_vars, save.path = tempdir()) {
    
    data_map_df <- as.matrix( # Raster as data frame, one row per pixel and one column per variable
        in_raster[[in_vars]],
        xy = F,
        na.rm = F,
        byrow = T
    ) %>%
        as.data.frame()

    data_map_df_comp <- which(complete.cases(data_map_df)) # get index of lines that include no NA for later raster recreation

    data_map_df <- data_map_df[data_map_df_comp, ] # shrink of the data frame

    write.table(data_map_df, paste0(save.path, "_na-free.txt")) # save the data frame

    write.table(data_map_df_comp, paste0(save.path, "_comp_cases.txt")) # save vector with indices that include 
}
```

#### Fast prediction
Prediction of a stan4bart-object to new data that has been prepaired with the "raster_prep_stan4bart"-function.

Input:

- __model__ = stan4bart-object
- __newdata__ = Object created with read.table("*_na-free.txt").
- __complete_cases__ = Object created with read.table("*_comp_cases.txt").
- __base_raster__ = Raster with the same properties as the raster from which the newdata object was created. --> The function needs to know on which basis the resulting raster has to be built.
- __type__ = One of the types of predict.stan4bartFit.
- __coltake__ = Object created in the for-loop later on, is only needed if you want only a part of the iterations/chains in your result. It simply is a vector of values $\in$ [1, iterations*chains] for every iteration (of chains) that should be used.

As the predicted chains and iterations are combined to one big matrix (colbind, one column per iteration) it applies for creating __coltake__:

- 1. Chain [1, iterations-burn_in]
- 2. Chain [iterations-burn_in+1, (iterations-burn_in)*2]
- n. Chain [(iterations-burn_in)\*(n-1)+1, (iterations-burn_in)\*n]

Output:

- fast_result = Raster with the same properties than __base_raster__.

```{r}
fast_predict <- function(model, newdata, complete_cases, base_raster, type = "ev", coltake = NULL) {
    
    new_data <- predict(
        object = model,
        newdata = newdata,
        type = type,
        combine_chains = TRUE,
        sample_new_levels = TRUE
    )

    if (is.null(coltake)) {
        new_data %<>% rowMeans(na.rm = T)
    } else {
        new_data %<>%
            .[, coltake] %>%
            rowMeans(na.rm = T)
    }

    pre_raster <- rep(NA, ncell(base_raster))
    pre_raster[complete_cases$x] <- new_data
    pre_raster %<>%
        matrix(
            nrow = nrow(base_raster),
            ncol = ncol(base_raster),
            byrow = T
        )

    fast_result <- rast(
        pre_raster,
        crs = crs(base_raster),
        extent = ext(base_raster)
    )


    return(fast_result)
}
```

#### Finding the threshold
This function tries to find the threshold for a 1/0 classification of a map, according to a specific accurracy/confidence.

Input:

- __eval_list__ = ROCR-Object
- __thresh__ = Confidence/Accurracy threshold.

Output:

- 1/0 classification threshold $\in$ [1,0]


```{r}
thresh_01 <- function(eval_list, thresh = 0.925) {
    lapply(eval_list, function(x) {
        ROCR::performance(x, measure = "acc")@x.values[[1]][which(ROCR::performance(x, measure = "acc")@y.values[[1]] > 0.925)] %>%
            unlist() %>%
            min()
    }) %>%
        unlist() %>%
        mean()
}
```


## Directories
```{r}
dir.create("./1_input/")
dir.create("./2_work")
dir.create("./3_ready")
dir.create("./4_output")
```

## Variables 
### Boundaries World and Area of interest {.tabset}
Chosen countries as area of interest (AOI).
```{r}
countryCodes <- tibble(isoA3 = vector(length = 40))

countryCodes$isoA3 <- c("AUT", "BEL", "BGR", "HRV", "CYP", "CZE", "DNK", "EST", "FIN", "FRA", "DEU", "GRC", "HUN", "IRL", "ITA", "LVA", "LTU", "LUX", "MLT", "NLD", "POL", "PRT", "ROU", "SVK", "SVN", "ESP", "SWE", "GBR", "TWN", "CHE", "NOR", "BLR", "UKR", "SRB", "MKD", "MNE", "BIH", "HRV", "MDA", "CHN")

countryCodes$isoA2 <- countrycode(countryCodes$isoA3, "iso3c", "iso2c")
```

#### World border 
Downloaded from [opendatasoft.com](https://public.opendatasoft.com/explore/dataset/world-administrative-boundaries/information/?location=2,44.59047,46.93359&basemap=jawg.light&dataChart=eyJxdWVyaWVzIjpbeyJjb25maWciOnsiZGF0YXNldCI6IndvcmxkLWFkbWluaXN0cmF0aXZlLWJvdW5kYXJpZXMiLCJvcHRpb25zIjp7fX0sImNoYXJ0cyI6W3siYWxpZ25Nb250aCI6dHJ1ZSwidHlwZSI6ImNvbHVtbiIsImZ1bmMiOiJDT1VOVCIsInNjaWVudGlmaWNEaXNwbGF5Ijp0cnVlLCJjb2xvciI6IiNGRjUxNUEifV0sInhBeGlzIjoic3RhdHVzIiwibWF4cG9pbnRzIjo1MCwic29ydCI6IiJ9XSwidGltZXNjYWxlIjoiIiwiZGlzcGxheUxlZ2VuZCI6dHJ1ZSwiYWxpZ25Nb250aCI6dHJ1ZX0%3D).

```{r}
world_border <- st_read("https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/world-administrative-boundaries/exports/kml?lang=en&timezone=Europe%2FBerlin")
st_write(world_border, "./1_input/world-administrative-boundaries.shp")

world_border %<>%
    select(Name, geometry) %>%
    st_transform(crs = 4087)

st_write(world_border, "./3_ready/WORLD_border.shp")
world_border <- st_read(("./3_ready/WORLD_border.shp"))
```

#### AOI border
Crop the world shape to AOI border.
```{r}
AOI <- world_border

AOI %<>%
    select(Name, geometry) %>%
    filter(Name %in% countryCodes$isoA3)

st_write(AOI, "./3_ready/AOI_border.shp", append = F)
AOI <- st_read("./3_ready/AOI_border.shp")
```

### Response (_Muntiacus reevesi_ occurrences) {.tabset}
#### GBIF
Source: [GBIF](https://www.gbif.org/occurrence/download/0065916-230224095556074)
 
```{r}
muntgbif <- read_delim("./1_input/occurrence.txt", delim = "\t")

muntgbif %<>%
    select(year, countryCode, decimalLatitude, decimalLongitude) %>%
    drop_na() %>%
    st_as_sf(coords = c("decimalLongitude", "decimalLatitude"), crs = 4326) %>%
    st_transform(crs = 4087) %>%
    mutate(source = rep("GBIF", nrow(.))) %>%
    unique() %>%
    distinct(geometry, .keep_all = T) %>%
    .[AOI, ]
```

#### Own extraction
Please find the document in the "important_files" directory and copy it to the "1_input" directory.

```{r}
muntown <- readxl::read_xlsx("./1_input/Own_muntiac.xlsx")

muntown %<>%
    st_as_sf(coords = c("decimalLongitude", "decimalLatitude"), crs = 4326) %>%
    st_transform(crs = 4087) %>%
    unique() %>%
    distinct(geometry, .keep_all = T) %>%
    mutate(year = as.numeric(year)) %>%
    .[AOI, ]
```

#### NBN Atlas 
Source: [NBN Atlas](https://ror.org/00mcxye41)

```{r}
muntnbn <- read_delim("./1_input/records-NBN.csv", delim = ",")

muntnbn %<>%
    select("year processed", "decimalLongitude processed", "decimalLatitude processed") %>%
    drop_na() %>%
    st_as_sf(coords = c("decimalLongitude processed", "decimalLatitude processed"), crs = 4326) %>%
    st_transform(crs = 4087) %>%
    mutate(source = rep("NBN", nrow(.)), countryCode = rep("GB", nrow(.))) %>%
    unique() %>%
    distinct(geometry, .keep_all = T) %>%
    .[AOI, ]

colnames(muntnbn)[1] <- "year"
```

#### Schleswig Holstein
Source: [Landesamt für Landwirtschaft, Umwelt und ländliche Räume in Schleswig-Holstein](https://www.schleswig-holstein.de/DE/landesregierung/ministerien-behoerden/LLUR/llur_node.html), received from [Dipl.-Geogr. Heiko Schmüser (CAU Kiel)](https://www.landscape-ecology.uni-kiel.de/de/team-1/heiko-schmueser)

Please find the document in the "important_files" directory and copy it to the "1_input" directory.

```{r}
muntsw <- st_read("./1_input/schmueser muntjac/20221219_MuntjakDaten_Multibase.shp")

muntsw %<>%
    select("Wolfsjahr", "geometry") %>%
    set_colnames(c("year", "geometry")) %>%
    drop_na() %>%
    st_transform(crs = 4087) %>%
    mutate(source = rep("SW", nrow(.)), countryCode = rep("DE", nrow(.))) %>%
    unique() %>%
    distinct(geometry, .keep_all = T) %>%
    .[AOI, ]

muntsw$year %<>% 
    gsub(".*/", "", .) %>% 
    as.numeric()
```

#### Combine to one dataset
```{r}
all_occs <- add_row(muntgbif, muntnbn) %>%
    add_row(muntown) %>%
    add_row(muntsw) %>%
    unique() %>%
    distinct(geometry, .keep_all = T)

rm(muntgbif, muntnbn, muntown, muntsw)

st_write(all_occs, "./2_work/all_occs.shp")
```

### Water bodies
Sources: [water bodies](https://hub.arcgis.com/content/esri::world-water-bodies/about) and [linear waters](https://www.arcgis.com/home/item.html?id=273980c20bc74f94ac96c7892ec15aff)

Preprocessing via QGIS:

- Combine both files
- Export as shape file with CRS = EPSG4087

```{r}
water <- st_read("./2_work/world_water.shp")

water %<>%
    select(ISO_CC, geometry) %>%
    sf::st_simplify(dTolerance = 100)

st_write(water, "./2_work/water_simple.shp")
water <- st_read("./2_work/water_simple.shp")
```

#### Check occurrences of ones in waterbodies
```{r}
water_dubles <- all_occs %>% 
    st_filter(water, .predicate = st_intersects)

all_occs %<>% .[all_occs$geometry %!in% water_dubles$geometry, ]

st_write(all_occs, "./3_ready/all_occs.shp", append = F)
```

### Road data
Source: [Natural Earth](https://naciscdn.org/naturalearth/10m/cultural/ne_10m_roads.zip)
```{r}
download.file(
    url = "https://naciscdn.org/naturalearth/10m/cultural/ne_10m_roads.zip",
    destfile = "./1_input/ne_10m_roads.zip"
)

unzip(
    "./1_input/ne_10m_roads.zip",
    exdir = "./1_input/"
)

roads <- st_read("./1_input/ne_10m_roads.shp")

roads %<>%
    select(type, name, length_km, continent, geometry) %>%
    filter(type != "Ferry Route", type != "Ferry, seasonal") %>% # Important: Filter water ways5
    st_transform(crs = 4087)

st_write(roads, "./3_ready/roads.shp", append = F)
```

### Urban areas
Source: [Natural Earth](https://naciscdn.org/naturalearth/10m/cultural/ne_10m_urban_areas.zip)
```{r}
download.file(
    url = "https://naciscdn.org/naturalearth/10m/cultural/ne_10m_urban_areas.zip",
    destfile = "./1_input/ne_10m_urban_areas.zip"
)

unzip(
    "./1_input/ne_10m_urban_areas.zip",
    exdir = "./1_input/"
)

urban <- st_read("./1_input/ne_10m_urban_areas.shp")

urban %<>%
    select(area_sqkm, geometry) %>%
    st_transform(crs = 4087)

st_write(urban, "./3_ready/urban.shp", append = F)
```

### Elevation + Slope
```{r}
elevation <- elevation_global(res = 0.5, path = "./1_input/elevation")

elevation %<>% terra::project(AOI)

terra::writeRaster(elevation_work, "./2_work/elevation.tif", overwrite = T)

slope <- elevation %>%
    terra::terrain(
        v = c("slope"),
        unit = "degrees",
        filename = "./2_work/slope.tif",
        overwrite = T
    )

elevation <- rast("./2_work/elevation.tif")
slope <- rast("./2_work/slope.tif")
```

### Climate
```{r}
climate <- worldclim_global(
    var = "bio",
    res = 0.5,
    path = "./1_input/bioclim",
    version = "2.1"
)

climate %<>% terra::project(AOI)

terra::writeRaster(climate_work, "./2_work/climate.tif", overwrite = T)

climate <- rast("./2_work/climate.tif")
```

### Landcover
Get the data and prepare them for stacking with climate.

```{r}
landcover(var = "trees", path = "./1_input/landcover")
landcover(var = "grassland", path = "./1_input/landcover")
landcover(var = "shrubs", path = "./1_input/landcover")
landcover(var = "cropland", path = "./1_input/landcover")
landcover(var = "built", path = "./1_input/landcover")
landcover(var = "wetland", path = "./1_input/landcover")

landCover <- rast(paste0("./1_input/landcover/", list.files("./1_input/landcover")))

landCover %<>% terra::project(crs(AOI))

writeRaster(landCover, "./2_work/landcover.tif")

landCover <- rast("./2_work/landcover.tif")

# Creating a raster that matches the resolution and extent of the climate raster, as the land cover rasters are cropped at the top and bottom.
mergerast <- rast(
    ext(climate$wc2.1_30s_bio_1), 
    resolution = res(climate$wc2.1_30s_bio_1), 
    crs = crs(climate), 
    names = names(landCover), 
    nlyrs = nlyr(landCover))

merge(mergerast, landCover, filename = "./2_work/landcover_merge.tif") 

landCover <- rast("./2_work/landcover_merge.tif")
```

### Distance maps to Urban areas, Water and streets {.tabset}
#### Step I
The fist step was the rasterization of the urban areas, waters and streets in QGIS. Export them as "WORLD_roads_raster.tif", "WORLD_urban_raster.tif" and "WORLD_water_raster.tif" with CRS = EPSG4087. R works too inefficiently on large rasters. You can also try the ´fasterize´ function, though its not working with MULTILINESTRING at the moment. Alternatively, use the "RQGIS"-Package.

#### Step II
NAs have to be set to 0 for further processing in whitebox. Additionally, the rasters were cropped to the AOI.

```{r}
# Roads
WORLD_road_distance <- rast("./2_work/WORLD_roads_raster.tif")
WORLD_road_distance <- ifel(is.na(WORLD_road_distance), 0, WORLD_road_distance)
writeRaster(WORLD_road_distance, "./2_work/WORLD_roads_raster_0_1.tif", overwrite = T)
WORLD_road_distance %<>% mask(AOI) %>% crop(AOI)
writeRaster(WORLD_road_distance, "./2_work/AOI_roads_raster_0_1.tif", overwrite = T)

# Urban areas
WORLD_urban_distance <- rast("./2_work/WORLD_urban_raster.tif")
WORLD_urban_distance <- ifel(is.na(WORLD_urban_distance), 0, WORLD_urban_distance)
writeRaster(WORLD_urban_distance, "./2_work/WORLD_urban_raster_0_1.tif", overwrite = T)
WORLD_urban_distance %<>% mask(AOI) %>% crop(AOI)
writeRaster(WORLD_urban_distance, "./2_work/AOI_urban_raster_0_1.tif", overwrite = T)

# Water
WORLD_water_distance <- rast("./2_work/WORLD_water_raster.tif")
WORLD_water_distance <- ifel(is.na(WORLD_water_distance), 0, WORLD_water_distance)
writeRaster(WORLD_water_distance, "./2_work/WORLD_water_raster_0_1.tif", overwrite = T)
WORLD_water_distance %<>% mask(AOI) %>% crop(AOI)
writeRaster(WORLD_water_distance, "./2_work/AOI_water_raster_0_1.tif", overwrite = T)
```

#### Step III
Calculade euclidean distance maps via whitebox.

```{r}
wbt_euclidean_distance(
    "./2_work/AOI_roads_raster_0_1.tif",
    "./2_work/AOI_road_distance.tif"
)

wbt_euclidean_distance(
    "./2_work/AOI_urban_raster_0_1.tif",
    "./2_work/AOI_urban_distance.tif"
)

wbt_euclidean_distance(
    "./2_work/AOI_water_raster_0_1.tif",
    "./2_work/AOI_water_distance.tif"
)
```

### Combine
Combine all, crop to AOI and resample for faster preliminary model runs.

Note: The distane maps are not available in world size, therefore the distances to roads, waters and urban areas have to be extracted in another way later on.
That means that the AOI_environment.tif is fully self contained in all environmental factors that are needed but the WORLD_environment.tif is not.

```{r}
WORLD_environment <- terra::rast(
    c(
        "./2_work/elevation.tif",
        "./2_work/slope.tif",
        "./2_work/climate.tif",
        "./2_work/landcover_merge.tif"
    )
)

names(WORLD_environment) %<>% gsub(".*s_", "", .)

writeRaster(WORLD_environment, "./3_ready/WORLD_environment.tif")

WORLD_environment <- rast("./3_ready/WORLD_environment.tif")

AOI_environment <- WORLD_environment %>%
    crop(AOI) %>%
    mask(AOI) %>%
    c(
        .,
        rast(c(
            "./2_work/AOI_road_distance.tif",
            "./2_work/AOI_urban_distance.tif",
            "./2_work/AOI_water_distance.tif"
        ))
    )

names(AOI_environment) %<>% gsub("AOI_", "", .)

writeRaster(AOI_environment, "./3_ready/AOI_environment.tif")

AOI_environment <- rast("./3_ready/AOI_environment.tif")

EU_environment <- 
    rast("./3_ready/AOI_environment.tif") %>%
    crop(AOI[AOI$Name %!in% c("TWN", "CHN"), ]) %>%
    terra::mask(AOI[AOI$Name %!in% c("TWN", "CHN"), ])

writeRaster(EU_environment, "./3_ready/EU_environment.tif")

EU_environment <- rast("./3_ready/EU_environment.tif")

# Resample with stacks is not possible at this moment in whitebox but will hopefully be included in future, therefore use the terra function, velox or QGIS.

wbt_resample(
    inputs = "./3_ready/WORLD_environment.tif",
    output = "./3_ready/WORLD_environment_low.tif",
    cell_size = 5000,
    method = "cc"
)

wbt_resample(
    inputs = "./3_ready/AOI_environment.tif",
    output = "./3_ready/AOI_environment_low.tif",
    cell_size = 5000,
    method = "cc"
)

wbt_resample(
    inputs = "./3_ready/EU_environment.tif",
    output = "./3_ready/EU_environment_low.tif",
    cell_size = 5000,
    method = "cc"
)

# Terra aggregrate

WORLD_environment_low <- 
    terra::aggregate(
        WORLD_environment, 
        fact = 10, 
        filename = "./3_ready/WORLD_environment_low.tif")

AOI_environment_low <- 
    terra::aggregate(
        AOI_environment, 
        fact = 10, 
        filename = "./3_ready/AOI_environment_low.tif")

EU_environment_low <- 
    terra::aggregate(
        EU_environment, 
        fact = 10, 
        filename = "./3_ready/EU_environment_low.tif")

WORLD_environment_low <- rast("./3_ready/WORLD_environment_low.tif")
AOI_environment_low <- rast("./3_ready/AOI_environment_low.tif")
EU_environment_low <- rast("./3_ready/EU_environment_low.tif")
```


### Future conditions {.tabset}
#### Future climate
Source: [World Climate Reseach Programme](https://doi.org/10.22033/ESGF/CMIP6.4332)

Can be cropped directly to Europe because of no need of data outside of AOI for prediction.

```{r}
future_climate <- rast("./1_input/future data/wc2.1_2.5m_bioc_ACCESS-CM2_ssp585_2061-2080.tif")[[c(1, 12)]]

future_climate %<>% terra::project(AOI) %>%
    crop(AOI[AOI$Name %!in% c("TWN", "CHN"), ]) %>%
    terra::mask(AOI[AOI$Name %!in% c("TWN", "CHN"), ])

names(future_climate) <- c("bio_1", "bio_12")

dir.create("./2_work/future data")

writeRaster(future_climate, "./2_work/future data/EU_climate.tif", overwrite = T)
```

#### Future Urban
Source: [Land-Use Harmonization²](https://luh.umd.edu/data.shtml) and [Extractions made available here](https://doi.org/10.17161/bi.v16i1.15483)

Only Europe is needed for prediction.
```{r}
future_urban <- rast("./1_input/future data/CMIP6_Land_Use_Harmonization_urban_SSP5_85_2071.tif")

future_urban %<>%
    terra::project(AOI) %>%
    crop(AOI[AOI$Name %!in% c("TWN", "CHN"), ]) %>%
    terra::mask(AOI[AOI$Name %!in% c("TWN", "CHN"), ])

writeRaster(future_urban, "./2_work/future data/urban_low.tif", overwrite = T)
```

#### Future Forest
Source: [Land-Use Harmonization²](https://luh.umd.edu/data.shtml) and [Extractions made available here](https://doi.org/10.17161/bi.v16i1.15483)

Here two forest raster files are combined: primary and secondary forest.

```{r}
future_forest <- rast(c("./1_input/future data/CMIP6_Land_Use_Harmonization_primf_SSP5_85_2071.tif", "./1_input/future data/CMIP6_Land_Use_Harmonization_secdf_SSP5_85_2071.tif"))

future_forest <- future_forest[[1]] + future_forest[[2]]

future_forest %<>% terra::project(AOI) %>%
    crop(AOI[AOI$Name %!in% c("TWN", "CHN"), ]) %>%
    terra::mask(AOI[AOI$Name %!in% c("TWN", "CHN"), ])

writeRaster(future_forest, "./2_work/future data/forest_low.tif", overwrite = T)
```

#### Resampling
Attention: In my case, the whitebox had a bug in piping the resample function to the shell. Therefore I corrected the function.

```{r}
wbt_resample(
    inputs = "./2_work/future data/forest_low.tif",
    output = "./2_work/future data/forest_high.tif",
    base = "./2_work/future data/EU_climate.tif",
    method = "cc"
)

wbt_resample(
    inputs = "./2_work/future data/urban_low.tif",
    output = "./2_work/future data/urban_high.tif",
    base = "./2_work/future data/EU_climate.tif",
    method = "cc"
)

future_EU_environment <- rast("./3_ready/EU_environment.tif")[[c("slope", "water_distance", "road_distance")]]

writeRaster(future_EU_environment[[1]], "./2_work/future data/EU_environment_slope.tif")
writeRaster(future_EU_environment[[2]], "./2_work/future data/EU_environment_water_dist.tif")
writeRaster(future_EU_environment[[3]], "./2_work/future data/EU_environment_road_dist.tif")

wbt_resample(
    inputs = "./2_work/future data/EU_environment_slope.tif",
    output = "./2_work/future data/EU_environment_slope_final.tif",
    base = "./2_work/future data/EU_climate.tif",
    method = "cc"
)

wbt_resample(
    inputs = "./2_work/future data/EU_environment_water_dist.tif",
    output = "./2_work/future data/EU_environment_water_dist_final.tif",
    base = "./2_work/future data/EU_climate.tif",
    method = "cc"
)

wbt_resample(
    inputs = "./2_work/future data/EU_environment_road_dist.tif",
    output = "./2_work/future data/EU_environment_road_dist_final.tif",
    base = "./2_work/future data/EU_climate.tif",
    method = "cc"
)
```

#### New urban distance map
```{r}
future_urban <- rast("./2_work/future data/urban_high.tif")
future_urban <- ifel(is.na(future_urban) | future_urban < 0.1, 0, 1)
writeRaster(future_urban, "./2_work/future data/urban_distance.tif", overwrite = T)
future_urban %<>% mask(AOI) %>% crop(AOI)
writeRaster(future_urban, "./2_work/future data/urban_distance.tif", overwrite = T)

wbt_euclidean_distance(
    "./2_work/future data/urban_distance.tif",
    "./2_work/future data/urban_distance.tif"
)
```

#### Combine
```{r}
future_final <- rast(
    c(
        "./2_work/future data/EU_environment_slope_final.tif",
        "./2_work/future data/EU_environment_water_dist_final.tif",
        "./2_work/future data/EU_environment_road_dist_final.tif",
        "./2_work/future data/EU_climate.tif",
        "./2_work/future data/forest_high.tif",
        "./2_work/future data/urban_distance.tif"
    )
)

names(future_final) <- c("slope", "water_distance", "road_distance", "bio_1", "bio_12", "trees", "urban_distance")

writeRaster(future_final, "./3_ready/FUTURE_EU_environment.tif")

future_final <- rast("./3_ready/FUTURE_EU_environment.tif")
```

# Data extraction
```{r}
dir.create("./3_ready/model input")
```

## Input environment {.tabset}
### World high resolution
```{r}
all_data <- extraction_format(
    start = WORLD_environment,
    species = all_occs
)

all_data$train.df %<>%
    add_column(
        nearestdistance_to(
            all_data$train.points,
            list(
                road_distance = roads,
                urban_distance = urban,
                water_distance = water
            )
        )
    )

all_data$test.df %<>%
    add_column(
        nearestdistance_to(
            all_data$test.points,
            list(
                road_distance = roads,
                urban_distance = urban,
                water_distance = water
            )
        )
    )

save(all_data, file = "./3_ready/model input/PA_WORLD.Rdata")

load("./3_ready/model input/PA_WORLD.Rdata")
```

### AOI high resolution

```{r}
all_data <- extraction_format(
    start = AOI_environment,
    species = all_occs
)

save(all_data, file = "./3_ready/model input/PA_AOI.Rdata")

load("./3_ready/model input/PA_AOI.Rdata")
```

Now jump to the step "Collinearity". Once you have determined the least collinear variables, proceed here.

## Prediction environment

Define the chosen predictors and chosen randoms from the step "Collinearity".

```{r}
most.important <- c("bio_1", "bio_12", "trees", "water_distance", "slope")
randoms <- c("road_distance", "urban_distance")
```

Export raster environment as table for faster repetitive prediction.

```{r}
raster_prep_stan4bart(
    in_raster = rast("./3_ready/EU_environment.tif"),
    in_vars = c(most.important, randoms),
    save.path = "./3_ready/model input/EU_environment_rast"
)

raster_prep_stan4bart(
    in_raster = rast("./3_ready/EU_environment_low.tif"),
    in_vars = c(most.important, randoms),
    save.path = "./3_ready/model input/EU_environment_low_rast"
)

raster_prep_stan4bart(
    in_raster = rast("./3_ready/FUTURE_EU_environment.tif"),
    in_vars = c(most.important, randoms),
    save.path = "./3_ready/model input/FUTURE_environment_rast"
)
```

# Spatial Cluster Analysis
Analysis of spatial muntiac occurrence pattern. Strong spatial clustering is assumed.

```{r}
load("./3_ready/model input/PA_AOI.Rdata")
Presences <- all_data$train.df %>%
    filter(pa == 1) %>%
    add_row(
        all_data$test.df %>%
            filter(pa == 1)
    )

Pres.points <- all_data$train.points %>%
    filter(pa == 1) %>%
    add_row(all_data$test.points %>% filter(pa == 1))

Presences.join <- Pres.points %>%
    cbind(Presences) %>%
    mutate(Name = seq(1, nrow(.), 1)) %>%
    st_transform()

AOI <- st_read("./3_ready/AOI_border.shp")

autocorr <- list()

## GB
autocorr$muntgbif_GB_ppp <- as.ppp(Presences.join$geometry[AOI[AOI$Name %in% c("GBR", "IRL"), ]])
Window(autocorr$muntgbif_GB_ppp) <- as.owin(AOI[AOI$Name %in% c("GBR", "IRL"), ])
unitname(autocorr$muntgbif_GB_ppp) <- "m/m"

## Taiwan
autocorr$muntgbif_TW_ppp <- as.ppp(Presences.join$geometry[AOI[AOI$Name %in% c("TWN"), ]])
Window(autocorr$muntgbif_TW_ppp) <- as.owin(AOI[AOI$Name %in% c("TWN"), ])
unitname(autocorr$muntgbif_TW_ppp) <- "m/m"

# Test against 100 Monte Carlo iterations of complete spatial randomness
autocorr$GB_fest <- envelope(autocorr$muntgbif_GB_ppp, fun = "Fest", nsim = 1000, funargs = list(r = seq(0, 14000, 500)))
autocorr$TW_fest <- envelope(autocorr$muntgbif_TW_ppp, fun = "Fest", nsim = 1000, funargs = list(r = seq(0, 14000, 500)))

## GB Plot
autocorr$GB_fest_plot <- ggplot(autocorr$GB_fest, aes(x = r / 1000, y = obs)) +
    geom_line(aes(), col = "black", lwd = 1.5) +
    geom_line(aes(y = theo), col = "red", lwd = 1.5) +
    geom_ribbon(aes(ymin = lo, ymax = hi), fill = "red", alpha = 0.5, show.legend = FALSE) +
    scale_colour_manual(
        name = "F(r) statistics",
        values = c("black" = "black", "red" = "red"), labels = c("Observed", "Theoretical")
    ) +
    ylab("F(r)") +
    xlab("Radius (km)") +
    labs(
        title = TeX("$\\textbf{A)\\ United\\ Kingdom$}"),
        subtitle = paste0(
            "p = ", 
            (autocorr$GB_fest %>% attr("einfo") %>% .$nSD)/(autocorr$GB_fest %>% attr("einfo") %>% .$nsim), 
            ",", 
            " n = ", 
            autocorr$muntgbif_GB_ppp$n
            )) + 
    theme_minimal() + 
    theme(panel.border = element_rect(colour = "black", fill=NA, linewidth=1))

## TW Plot
autocorr$TW_fest_plot <- ggplot(autocorr$TW_fest, aes(x = r / 1000, y = obs)) +
    geom_line(aes(col = "black"), lwd = 1.5) +
    geom_line(aes(y = theo, col = "red"), lwd = 1.5, show.legend = F) +
    geom_ribbon(aes(ymin = lo, ymax = hi, fill = "red"), alpha = 0.5, show.legend = FALSE) +
    scale_colour_manual(
        name = "F(r) statistics",
        values = c("black" = "black", "red" = "red"), labels = c("Observed", "Theoretical")
    ) +
    ylab("F(r)") +
    xlab("Radius (km)") +
    labs(
        title = TeX("$\\textbf{B)\\  Taiwan$}"),
        subtitle = paste0(
            "p = ", 
            (autocorr$TW_fest %>% attr("einfo") %>% .$nSD)/(autocorr$TW_fest %>% attr("einfo") %>% .$nsim), 
            ",", 
            " n = ", 
            autocorr$muntgbif_TW_ppp$n
            )) + 
    theme_minimal() + 
    theme(panel.border = element_rect(colour = "black", fill=NA, linewidth=1))


# Inter-event distribution for Taiwanese and Brittish muntjac occurrences
autocorr$both_plot <- grid.arrange(autocorr$GB_fest_plot , autocorr$TW_fest_plot, nrow = 1, widths = c(2.55, 3))
 

save.to <- "./4_output/Plots and tables/"
ggsave(
    filename = paste0(save.to, "point_pattern",".pdf"),
    plot = autocorr$both_plot,
    device = "pdf",
    width = 12.0,
    height = 5
   )



#### Continent wide ####
# Not really needed, just for the sake of completeness

## Europe
autocorr$muntgbif_GB_ppp <- as.ppp(Presences.join$geometry[AOI[AOI$Name %!in% c("TWN", "CHN"), ]])
Window(autocorr$muntgbif_GB_ppp) <- as.owin(AOI[AOI$Name %!in% c("TWN", "CHN"), ])
unitname(autocorr$muntgbif_GB_ppp) <- "m/m"

## ASIA
autocorr$muntgbif_TW_ppp <- as.ppp(Presences.join$geometry[AOI[AOI$Name %in% c("TWN", "CHN"), ]])
Window(autocorr$muntgbif_TW_ppp) <- as.owin(AOI[AOI$Name %in% c("TWN", "CHN"), ])
unitname(autocorr$muntgbif_TW_ppp) <- "m/m"

# Test against 100 Monte Carlo Iterations of complete spatial randomness
autocorr$GB_fest <- envelope(autocorr$muntgbif_GB_ppp, fun = "Fest", nsim = 100, funargs = list(r = seq(0, 14000, 500)))
autocorr$TW_fest <- envelope(autocorr$muntgbif_TW_ppp, fun = "Fest", nsim = 100, funargs = list(r = seq(0, 14000, 500)))


## Europe Plot
autocorr$GB_fest_plot <- ggplot(autocorr$GB_fest, aes(x = r / 1000, y = obs)) +
    geom_line(aes(), col = "black", lwd = 1.5) +
    geom_line(aes(y = theo), col = "red", lwd = 1.5) +
    geom_ribbon(aes(ymin = lo, ymax = hi), fill = "red", alpha = 0.5, show.legend = FALSE) +
    scale_colour_manual(
        name = "F(r) statistics",
        values = c("black" = "black", "red" = "red"), labels = c("Observed", "Theoretical")
    ) +
    ylab("F(r)") +
    xlab("Radius (km)") +
    ggtitle("A)")

## Asia Plot
autocorr$TW_fest_plot <- ggplot(autocorr$TW_fest, aes(x = r / 1000, y = obs)) +
    geom_line(aes(col = "black"), lwd = 1.5) +
    geom_line(aes(y = theo, col = "red"), lwd = 1.5, show.legend = F) +
    geom_ribbon(aes(ymin = lo, ymax = hi, fill = "red"), alpha = 0.5, show.legend = FALSE) +
    scale_colour_manual(
        name = "F(r) statistics",
        values = c("black" = "black", "red" = "red"), labels = c("Observed", "Theoretical")
    ) +
    ylab("F(r)") +
    xlab("Radius (km)") +
    ggtitle("B)")


# Inter-event distribution for European and Asian muntjac occurrences
grid.arrange(autocorr$GB_fest_plot, autocorr$TW_fest_plot, nrow = 1, widths = c(2.55, 3))
```

# Collinearity
```{r}
load("./3_ready/model input/PA_WORLD.Rdata")

col_test_df <- all_data$train.df %>%
    add_row(all_data$test.df) %>%
    filter(pa == 1)

col_result <- col_test_df %>%
    select(bio_1, bio_12, road_distance, trees, shrubs, cropland, water_distance, slope, grassland, urban_distance, water) %>%
    multicol_own()

owncount(col_result, "VIF", 10, "max")

col_result <- col_test_df %>%
    select(bio_1, bio_12, trees, water_distance, slope) %>%
    multicol_own()

owncount(col_result, "VIF", 10, "max") %>%
    mutate(Predictor = case_when(
        factor == "bio_1" ~ "Mean temp.",
        factor == "bio_12" ~ "Mean prec.",
        factor == "slope" ~ "Slope",
        factor == "trees" ~ "Trees",
        factor == "water_distance" ~ "Water distance",
        .default = factor
    )) %>%
    select(Predictor, "R²", VIF, Count) %>% 
    xtable(.,
        caption = "Collinearity statistics of the used predictors. Mean prec. = Annual mean precipitation, Mean temp. = Annual mean temperature, $R^2$ = Proportion of the variation in the response that can be accounted for by the predictors, VIF = $\\frac{1}{R²}$ = Variance inflation factor. Table sorted after VIF. Count = Number of significant corellated variables + Intercept.",
        label = "tab:collinearity"
        ) %>%
    print(file = "./4_output/Plots and tables/Collinearity.tex", caption.placement = getOption("xtable.caption.placement", "top"), include.rownames=FALSE)

```

Remaining variables: 
- Annual Precipitation (bio_12)
- Slope (slope)
- Annual Mean Temperature (bio_1)
- Tree cover in % (trees)
- Water distance in m (water_distance)

For expected sampling bias the following were included as random factors:
- Road distance (road_distance)
- Urban distance (urban_distance)

# Model
Create the necessary directories.
```{r}
dir.create("./4_output/1.EU_high_res_CV_PRED_low_res/")
dir.create("./4_output/2.EU_high_res_CV_PRED_high_res/")
dir.create("./4_output/3.WORLD_high_res_CV_PRED_low_res/")
dir.create("./4_output/4.WORLD_high_res_CV_PRED_high_res/")
dir.create("./4_output/5. EU_hig_res_CV_PRED_future/")
dir.create("./4_output/6. WORLD_hig_res_CV_PRED_future/")
```

Cross valiation loop, parameterization and predictions.

Input:

- __all_data__ = Saved in PA_*.Rdata --> The muntjac occurrences + environment.
- __path_to_store__ = Path to the output directory --> Output raster + Test values.
- __prediction_to_what__ = Template raster for transforming the prediction data frame to a raster.
- __data_map_df__ = Pre-built data frame of the prediction environment.
- __data_map_df_comp__ = Vector with nrow(__data_map_df_comp__) = nrow(__data_map_df__) where __data_map_df__ matches complete_cases().

Output:

- __test_stat.RData__ = RData document that includes the calculated test statistics. All objects are lists of lenght == cv.runs.
    - evaluation.cv = ROCR-Object for evaluation of the model i.
    - auc.cv = Area under the curve value per model $\in$ [0,1], the higher the better.
    - tss.thresh = Threshold where TSS $\in$ [0,1] is highest, the higher the better.
    - tss = True skill statistics test value $\in$ [0,1], the higher the better.
    - acceptance = Is the model accepted $\in$ {TRUE, FALSE}.
    - accurr = Accurracy of the model $\in$ [0,1], the higher the better.
    - convergence = Internal convergence check $\in$ {0,1}, has to be 1 .
    - tree_vars_imp = Variable importance, mean and standard deviation per used environmental variable per CV-run. List of arrays with list lenght == cv.runs and array dimensions $\in$ {lenght(most.important), 2, cv.runs}.
    - bri = Brier Score $\in$ [0,1], the lower the better.
- __Run_[1,cv.runs].tif__ = GEOTiffs of one raster per CV-Run with the spatial probability of presence prediction.



```{r}
# Settings for the test runs:
# cv.runs <- 25
# iter_own <- 40
# warmup_own <- 20
# chains_own <- 2
# trees_own <- 50


# Settings for the final run:
cv.runs <- 25
iter_own <- 500
warmup_own <- 150
chains_own <- 3
trees_own <- 200

### In the following:
## Comment or uncomment the necessary parts for predicting AOI or WORLD data sets to high/low resolution EU or the FUTURE data set.
## The low resolution rasters were taken for finding the right parameterization (chains, iterations, trees, ...)

# ################ 1
# Predict from AOI to low EU
load("./3_ready/model input/PA_AOI.Rdata")
path_to_store <- "./4_output/1.EU_high_res_CV_PRED_low_res/"
prediction_to_what <- rast("./3_ready/EU_environment_low.tif")
data_map_df <- read.table("./3_ready/model input/EU_environment_low_rast_na-free.txt")
data_map_df_comp <- read.table("./3_ready/model input/EU_environment_low_rast_comp_cases.txt")


# ################ 2
# Predict from AOI to high EU
# load("./3_ready/model input/PA_AOI.Rdata")
# path_to_store <- "./4_output/2.EU_high_res_CV_PRED_high_res/"
# prediction_to_what <- rast("./3_ready/EU_environment.tif")
# data_map_df <- read.table("./3_ready/model input/EU_environment_rast_na-free.txt")
# data_map_df_comp <- read.table("./3_ready/model input/EU_environment_rast_comp_cases.txt")

# ################ 3
# Predict from WORLD to low EU
# load("./3_ready/model input/PA_WORLD.Rdata")
# path_to_store <- "./4_output/3.WORLD_high_res_CV_PRED_low_res/"
# prediction_to_what <- rast("./3_ready/EU_environment_low.tif")
# data_map_df <- read.table("./3_ready/model input/EU_environment_low_rast_na-free.txt")
# data_map_df_comp <- read.table("./3_ready/model input/EU_environment_low_rast_comp_cases.txt")

# ################ 4
# Predict from WORLD to high EU
# load("./3_ready/model input/PA_WORLD.Rdata")
# path_to_store <- "./4_output/4.WORLD_high_res_CV_PRED_high_res/"
# prediction_to_what <- rast("./3_ready/EU_environment.tif")
# data_map_df <- read.table("./3_ready/model input/EU_environment_rast_na-free.txt")
# data_map_df_comp <- read.table("./3_ready/model input/EU_environment_rast_comp_cases.txt")

################## 5
# Predict from AOI to FUTURE
# load("./3_ready/model input/PA_AOI.Rdata")
# path_to_store <- "./4_output/5. EU_hig_res_CV_PRED_future/"
# prediction_to_what <- rast("./3_ready/FUTURE_EU_environment.tif")
# data_map_df <- read.table("./3_ready/model input/FUTURE_environment_rast_na-free.txt")
# data_map_df_comp <- read.table("./3_ready/model input/FUTURE_environment_rast_comp_cases.txt")

################## 6
# Predict from WORLD to FUTURE
# load("./3_ready/model input/PA_WORLD.Rdata")
# path_to_store <- "./4_output/6. WORLD_hig_res_CV_PRED_future/"
# prediction_to_what <- rast("./3_ready/FUTURE_EU_environment.tif")
# data_map_df <- read.table("./3_ready/model input/FUTURE_environment_rast_na-free.txt")
# data_map_df_comp <- read.table("./3_ready/model input/FUTURE_environment_rast_comp_cases.txt")


# Do not change!
prediction.count.cv <- 0 # Has to be 0

# Empty output vectors
model.stan.cv <- list()
model.stan.predict.cv <- list()
PA_test_pred.cv <- list()
evaluation.cv <- list()
auc.cv <- list()
tss.thresh <- list()
tss <- list()
bri <- list()
accurr <- list()
acceptance <- list()
conf.matrix <- list()
convergence <- list()
tree_vars_imp <- list()

# Preparing data for CV
Presences.cv <- all_data$train.df %>%
    filter(pa == 1) %>%
    add_row(
        all_data$test.df %>%
            filter(pa == 1)
    )

Absences.cv <- all_data$train.df %>%
    filter(pa == 0) %>%
    add_row(
        all_data$test.df %>%
            filter(pa == 0)
    )

all.points <- all_data$train.points %>%
    filter(pa == 1) %>%
    add_row(all_data$test.points %>% filter(pa == 1)) %>%
    add_row(all_data$train.points %>% filter(pa == 0)) %>%
    add_row(all_data$test.points %>% filter(pa == 0))


#################### Automatic CV loop #######################

for (i in 1:cv.runs) {
    # Random assembling of the data
    sample.pres <- sample(
        c(TRUE, FALSE),
        nrow(Presences.cv),
        replace = TRUE,
        prob = c(0.67, 0.33)
    )

    sample.abs <- sample(
        c(TRUE, FALSE),
        nrow(Absences.cv),
        replace = TRUE,
        prob = c(0.67, 0.33)
    )

    PA_train.cv <- Presences.cv[sample.pres, ] %>% rbind(Absences.cv[sample.abs, ])
    PA_train.cv %<>% .[, c(most.important, randoms, "pa")]
    PA_test.cv <- Presences.cv[!sample.pres, ] %>% rbind(Absences.cv[!sample.abs, ])
    PA_test.cv %<>% .[, c(most.important, randoms, "pa")]

    # Creating weights
    my_weights.cv <- nbfunction(all.points$geometry[c(sample.pres, sample.abs)], buffer_radius = 298.5411)
    print(paste("Weights", i, "created!"))

    # Defining and running the model
    model.stan.cv[[i]] <- stan4bart(
        formula = pa ~ bart(. - urban_distance - road_distance) +
            (1 + road_distance) + (1 + urban_distance),
        verbose = 1, # print progress
        data = PA_train.cv, # train data
        cores = 3, # Cores to use
        weights = my_weights.cv, # Weights to use
        chains = chains_own, # No. of independent created chains
        iter = iter_own, # No. of iterations and [result = iter - warmup]
        warmup = warmup_own, # No. of "iter" to draw and reject for warmup
        bart_args = list(
            weights = my_weights.cv, # Weights to use
            n.trees = trees_own, # No. of trees to form
            keepTrees = T, # Save trees for prediction
            combineChains = F, # Combine seperate chains to one
            n.chains = 1 # Nr. of MCMC-Chains within the bart component
        ),
    )

    print(paste("Model", i, "created!"))

    # Definition of how many iterations and chains should be combined for prediction (needs to be activated in the prediction for testing and further down for the raster)
    # coltake <- seq(iter_own - warmup_own, (iter_own - warmup_own) * chains_own, iter_own - warmup_own)

    # Variable importance
    tree_vars_imp[[i]] <- apply(model.stan.cv[[i]]$bart_varcount, 3, FUN = rowMeans) %>%
        rowMeans() %>%
        as.data.frame() %>%
        cbind((apply(model.stan.cv[[i]]$bart_varcount, c(1, 3), FUN = sd) %>%
            rowMeans() %>%
            as.data.frame())) %>%
        setNames(c("mean", "sd")) %>%
        divide_by(sum(.$mean))

    # Inclusion of coltake
    # tree_vars_imp[[i]] <- model.stan.cv[[i]]$bart_varcount %>%
    #     .[,coltake[1],] %>%
    #     rowMeans() %>%
    #     as.data.frame() %>%
    #     cbind((apply(model.stan.cv[[i]]$bart_varcount %>% .[,coltake[1],], 1, FUN = sd) %>%
    #         as.data.frame())) %>%
    #     setNames(c("mean", "sd")) %>%
    #     divide_by(sum(.$mean))


    # Prediction of the model
    testpred <- predict(model.stan.cv[[i]], newdata = PA_test.cv) %>%
        # .[, coltake] %>% # uncomment if coltake should be used
        rowMeans()

    # Create a ROCR-object from the prediction + calculate several indices
    evaluation.cv[[i]] <- ROCR::prediction(testpred, PA_test.cv$pa)

    auc.cv[[i]] <- ROCR::performance(evaluation.cv[[i]], measure = "auc")@y.values %>%
        unlist() # area under the curve

    tss[[i]] <- max(
        ROCR::performance(evaluation.cv[[i]], measure = "tpr")@y.values %>%
            unlist() +
            ROCR::performance(evaluation.cv[[i]], measure = "tnr")@y.values %>%
            unlist() - 1
    ) # true skill statistics

    bri[[i]] <- get_and_calc_bri(evaluation.cv[[i]]) # brier score

    tss.thresh[[i]] <- ROCR::performance(evaluation.cv[[i]], measure = "acc")@x.values[[1]][which(ROCR::performance(evaluation.cv[[i]], measure = "acc")@y.values[[1]] == max(ROCR::performance(evaluation.cv[[i]], measure = "acc")@y.values[[1]]))] %>%
        unlist() %>%
        min() # "best" threshold at maximum accurracy

    accurr[[i]] <- max(ROCR::performance(evaluation.cv[[i]], measure = "acc")@y.values[[1]]) # accurracy

    acceptance[[i]] <- ifelse(accurr[[i]] > 0.9 & auc.cv[[i]] > 0.9 & bri[[i]] < 0.05, TRUE, FALSE) # can the model be accepted?

    convergence[[i]] <- model.stan.cv[[i]]$stan[6, , ] # internal convergence test

    prediction if model is accepted
    if (acceptance[[i]]) {
        print(paste("Model", i, "accepted!"))
        prediction.count.cv <- prediction.count.cv + 1

        # Predict the model on basis of the new data (extracted rasters from before) and build new rasters
        model.stan.predict.cv <- fast_predict(
            model = model.stan.cv[[i]],
            newdata = data_map_df,
            complete_cases = data_map_df_comp,
            base_raster = prediction_to_what,
            type = "ev",
            coltake = NULL # exchange NULL to coltake if you want to use the coltake columns
        )

        names(model.stan.predict.cv) <- paste("Run", i)

        # Save created raster
        writeRaster(model.stan.predict.cv,
            paste0(path_to_store, "Run_", i, ".tif"),
            overwrite = T
        )
        print(paste("Model", i, "saved!"))


        # remove prediction from workspace
        rm(model.stan.predict.cv)
    } else {
        print(paste("Model", i, "rejected!"))
    }

    # save model and test results in case of PC crashing when calculating big models
    if (i %% 2 == 0) {
        save(evaluation.cv, auc.cv, tss.thresh, tss, acceptance, accurr, convergence, tree_vars_imp, bri, file = paste0(path_to_store, "test_stat.RData"))
    }
} # end of the loop

# save last state data
save(evaluation.cv, auc.cv, tss.thresh, tss, acceptance, accurr, convergence, tree_vars_imp, bri, file = paste0(path_to_store, "test_stat.RData"))

# load all created predictions
model.stan.predict.cv <- rast(paste0(path_to_store, list.files(path_to_store, pattern = "*.tif")))

# Calculate Mean and standard deviation
model.stan.predict.cv <- c(model.stan.predict.cv, model.stan.predict.cv %>% mean(na.rm = T))
model.stan.predict.cv <- c(model.stan.predict.cv, model.stan.predict.cv[[-(nlyr(model.stan.predict.cv))]] %>% stdev(na.rm = T))

# save mean
writeRaster(model.stan.predict.cv[["mean"]],
    paste0(path_to_store, "Run_mean.tif"),
    overwrite = T
)

# save standard deviation
writeRaster(model.stan.predict.cv[["std"]],
    paste0(path_to_store, "Run_std.tif"),
    overwrite = T
)
print("############### DONE! ###############")
```

# Exploring the data
## Load right data for further proceeding
Here you can run the necessary columns to load the data of a specific CV-run.

```{r}
# ################ 1
# Predict from AOI to low EU
path_to_store <- "./4_output/1.EU_high_res_CV_PRED_low_res/"
load(paste0(path_to_store, "test_stat.RData"))
model.stan.predict.cv <- rast(paste0(path_to_store, list.files(path_to_store, pattern = "*.tif")))

# ################ 2
# Predict from AOI to high EU
path_to_store <- "./4_output/2.EU_high_res_CV_PRED_high_res/"
load(paste0(path_to_store, "test_stat.RData"))
model.stan.predict.cv <- rast(paste0(path_to_store, list.files(path_to_store, pattern = "*.tif")))

# ################ 3
# Predict from WORLD to low EU
path_to_store <- "./4_output/3.WORLD_high_res_CV_PRED_low_res/"
load(paste0(path_to_store, "test_stat.RData"))
model.stan.predict.cv <- rast(paste0(path_to_store, list.files(path_to_store, pattern = "*.tif")))

# ################ 4
# Predict from WORLD to high EU
path_to_store <- "./4_output/4.WORLD_high_res_CV_PRED_high_res/"
load(paste0(path_to_store, "test_stat.RData"))
model.stan.predict.cv <- rast(paste0(path_to_store, list.files(path_to_store, pattern = "*.tif")))

# ################ 5
# Predict from AOI to FUTURE
path_to_store <- "./4_output/5. EU_hig_res_CV_PRED_future/"
load(paste0(path_to_store, "test_stat.RData"))
model.stan.predict.cv <- rast(paste0(path_to_store, list.files(path_to_store, pattern = "*.tif")))

# ################ 6
# Predict from WORLD to FUTURE
path_to_store <- "./4_output/6. WORLD_hig_res_CV_PRED_future/"
load(paste0(path_to_store, "test_stat.RData"))
model.stan.predict.cv <- rast(paste0(path_to_store, list.files(path_to_store, pattern = "*.tif")))
```

## Variable importance

Plots for checking each prediction subset

```{r}

for (i in seq(1,length(tree_vars_imp), 1)) {
   rownames(tree_vars_imp[[i]]) <- c("Mean temp.", "Mean prec.", "Tree density", "Water distance", "Slope")
}


tree_vars_imp_mean <- array(unlist(tree_vars_imp), dim = c(nrow(tree_vars_imp[[1]]), 2, length(tree_vars_imp))) %>%
    apply(1:2, mean) %>%
    as_tibble() %>%
    mutate(
        names = c("Mean temp.", "Mean prec.", "Tree density", "Water distance", "Slope"),
        mean = V1*100, 
        sd = V2*100) %>% 
    select(names, mean, sd)




# Mean Importance in percent over all chains and iterations
ggplot(tree_vars_imp_mean, aes(y = names, x = mean), size = 2) +
    geom_linerange(aes(xmin = mean - sd, xmax = mean + sd), col = "#1e854b", linewidth = 1.2) +
    geom_point(col = "black", size = 3) +
    xlab("Permutation importance in %") +
    ylab("Predictors in BART component") +
    theme_bw() +
    theme(
        text=element_text(size=20), 
        axis.text.x = element_text(vjust = -2), 
        axis.title.y = element_text(margin = margin(r = 20)), 
        axis.title.x = element_text(margin = margin(t = 20))
        )


# Convert matrix to data frame for use in ggplot2
my_dataframe <- reshape2::melt(tree_vars_imp, level = 2) %>% mutate(name = rep(rownames(tree_vars_imp[[1]]), max(L2) * 2))

# Advanced plot
# X-Axis = Iterations
# Y-Axis = Variable importance
# Boxplot = Importance of that variable over the CV-runs
# Line = Exact variable importance per iteration
ggplot(my_dataframe %>% filter(variable == "mean"), aes(x = L2, y = value, group = name)) +
    geom_line(aes(col = name)) +
    geom_boxplot(aes(col = name), fill = NA) + 
        xlab("CV run") +
    ylab("Permutation importance in %") +
    theme_bw() +
    theme(
        text=element_text(size=20), 
        axis.text.x = element_text(vjust = -2), 
        axis.title.y = element_text(margin = margin(r = 20)), 
        axis.title.x = element_text(margin = margin(t = 20))
        )  + 
    labs(color="Predictors in \nBART component")

```

## Final variable importance plot
### Europe
```{r}


# Predict from AOI to high EU
path_to_store <- "./4_output/2.EU_high_res_CV_PRED_high_res/"
load(paste0(path_to_store, "test_stat.RData"))

for (i in seq(1,length(tree_vars_imp), 1)) {
   rownames(tree_vars_imp[[i]]) <- c("Mean temp.", "Mean prec.", "Tree density", "Water distance", "Slope")
}

tree_vars_imp_EU <- tree_vars_imp

tree_vars_imp_mean_EU <- array(unlist(tree_vars_imp_EU), dim = c(nrow(tree_vars_imp_EU[[1]]), 2, length(tree_vars_imp_EU))) %>%
    apply(1:2, mean) %>%
    as_tibble() %>%
    mutate(
        names = c("Mean temp.", "Mean prec.", "Tree density", "Water distance", "Slope"),
        mean = V1*100, 
        sd = V2*100) %>% 
    select(names, mean, sd)


# Mean Importance in percent over all chains and iterations
tree_vars_imp_plot_EU <- ggplot(tree_vars_imp_mean_EU, aes(y = names, x = mean), size = 2) +
    geom_linerange(aes(xmin = mean - sd, xmax = mean + sd), col = "#1e854b", linewidth = 1.2) +
    geom_point(col = "black", size = 3) +
    xlab("Permutation importance in %") +
    ylab("Predictors in BART component") +
    theme_bw() +
    theme(
        text=element_text(size=20), 
        axis.text.x = element_text(vjust = -2), 
        axis.title.y = element_text(margin = margin(r = 20)), 
        axis.title.x = element_text(margin = margin(t = 20))
        ) +
    scale_y_discrete(limits=rev)

# Convert matrix to data frame for use in ggplot2
my_dataframe_EU <- reshape2::melt(tree_vars_imp_EU, level = 2) %>% mutate(name = rep(rownames(tree_vars_imp_EU[[1]]), max(L2) * 2))

# Advanced plot
# X-Axis = Iterations
# Y-Axis = Variable importance
# Boxplot = Importance of that variable over the CV-runs
# Line = Exact variable importance per iteration
tree_vars_imp_plot_EU_adv <- ggplot(my_dataframe_EU %>% filter(variable == "mean"), aes(x = L2, y = value, group = name)) +
    geom_line(aes(col = name)) +
    geom_boxplot(aes(col = name), fill = NA) + 
        xlab("Cross validation run") +
    ylab("Permutation importance in %") +
    theme_bw() +
    theme(
        text=element_text(size=20), 
        axis.text.x = element_text(vjust = -2), 
        axis.title.y = element_text(margin = margin(r = 20)), 
        axis.title.x = element_text(margin = margin(t = 20))
        )  + 
    labs(color="Predictors in \nBART component")


```

### World

```{r}

# Predict from WORLD to high EU
path_to_store <- "./4_output/4.WORLD_high_res_CV_PRED_high_res/"
load(paste0(path_to_store, "test_stat.RData"))

for (i in seq(1,length(tree_vars_imp), 1)) {
   rownames(tree_vars_imp[[i]]) <- c("Mean temp.", "Mean prec.", "Tree density", "Water distance", "Slope")
}

tree_vars_imp_WORLD <- tree_vars_imp
tree_vars_imp_mean_WORLD <- array(unlist(tree_vars_imp_WORLD), dim = c(nrow(tree_vars_imp_WORLD[[1]]), 2, length(tree_vars_imp_WORLD))) %>%
    apply(1:2, mean) %>%
    as_tibble() %>%
    mutate(
        names = c("Mean temp.", "Mean prec.", "Tree density", "Water distance", "Slope"),
        mean = V1*100, 
        sd = V2*100) %>% 
    select(names, mean, sd)


tree_vars_imp_plot_WORLD <- ggplot(tree_vars_imp_mean_WORLD, aes(y = names, x = mean), size = 2) +
    geom_linerange(aes(xmin = mean - sd, xmax = mean + sd), col = "#1e854b", linewidth = 1.2) +
    geom_point(col = "black", size = 3) +
    xlab("Permutation importance in %") +
    ylab("Predictors in BART component") +
    theme_bw() +
    theme(
        text=element_text(size=20), 
        axis.text.x = element_text(vjust = -2), 
        axis.title.y = element_text(margin = margin(r = 20)), 
        axis.title.x = element_text(margin = margin(t = 20))
        )+
    scale_y_discrete(limits=rev)



# Convert matrix to data frame for use in ggplot2
my_dataframe_WORLD <- reshape2::melt(tree_vars_imp_WORLD, level = 2) %>% mutate(name = rep(rownames(tree_vars_imp_WORLD[[1]]), max(L2) * 2))

# Advanced plot
# X-Axis = Iterations
# Y-Axis = Variable importance
# Boxplot = Importance of that variable over the CV-runs
# Line = Exact variable importance per iteration
tree_vars_imp_plot_WORLD_adv <- ggplot(my_dataframe_WORLD %>% filter(variable == "mean"), aes(x = L2, y = value, group = name)) +
    geom_line(aes(col = name)) +
    geom_boxplot(aes(col = name), fill = NA) + 
        xlab("Cross validation run") +
    ylab("Permutation importance in %") +
    theme_bw() +
    theme(
        text=element_text(size=20), 
        axis.text.x = element_text(vjust = -2), 
        axis.title.y = element_text(margin = margin(r = 20)), 
        axis.title.x = element_text(margin = margin(t = 20))
        )  + 
    labs(color="Predictors in \nBART component")

```

### Mean of both

```{r}

tree_vars_imp_mean_TOGETHER <- tibble(
    names = tree_vars_imp_mean_EU$names,
    mean = rowMeans(cbind(tree_vars_imp_mean_EU$mean, tree_vars_imp_mean_WORLD$mean)),
    sd = rowMeans(cbind(tree_vars_imp_mean_EU$sd, tree_vars_imp_mean_WORLD$sd))
    )


tree_vars_imp_plot_tog <- ggplot(tree_vars_imp_mean_TOGETHER, aes(y = names, x = mean), size = 2) +
    geom_linerange(aes(xmin = mean - sd, xmax = mean + sd), col = "#1e854b", linewidth = 1.2) +
    geom_point(col = "black", size = 3) +
    xlab("Permutation importance in %") +
    ylab("Predictors in BART component") +
    theme_bw() +
    theme(
        text=element_text(size=20), 
        axis.text.x = element_text(vjust = -2), 
        axis.title.y = element_text(margin = margin(r = 20)), 
        axis.title.x = element_text(margin = margin(t = 20))
        )+
    scale_y_discrete(limits=rev)
```

### Save

```{r}
save.to <- "./4_output/Plots and tables/"

plots <- list(tree_vars_imp_plot_EU, tree_vars_imp_plot_EU_adv, tree_vars_imp_plot_WORLD, tree_vars_imp_plot_WORLD_adv, tree_vars_imp_plot_tog)

plot_names <- c("tree_vars_imp_plot_EU", "tree_vars_imp_plot_EU_adv", "tree_vars_imp_plot_WORLD", "tree_vars_imp_plot_WORLD_adv", "tree_vars_imp_plot_tog")

for (i in 1:5) {
   ggsave(
    filename = paste0(save.to, plot_names[[i]],".pdf"),
    plot = plots[[i]],
    device = "pdf",
    width = 12.0,
    height = 7
   )
}

```



## Test statistics
```{r}
evaluation.cv # Can be used in the ROCR internal statistic functions

# pre evaluated statistics
auc.cv
tss.thresh
tss
acceptance
accurr
convergence
bri
```

### Appendix table for Test statistics

#### Europe - Appendix

```{r}
path_to_store <- "./4_output/2.EU_high_res_CV_PRED_high_res/"
load(paste0(path_to_store, "test_stat.RData"))
convergence_new <- lapply(convergence, 1, FUN = mean) %>% unlist()

test_stat <- 
    cbind(
        AUC = auc.cv,
        Accuracy = accurr,
        TSS = tss,
        "TSS Thresh" = tss.thresh,
        Accepted = as.integer(as.logical(acceptance)),
        Divergent = convergence_new,
        BRI = bri
    ) %>% apply(., 2, as.numeric) 

xtable(test_stat,
        caption = "Test statistics of the 25 cross-validation runs of the conservative model runs. AUC = Area under the receiver operator curve, Accuracy = Accurracy of the models, TSS = True skill statistics, TSS Thresh = Threshold of suitability where Accuracy maximal, Accepted = Acceptance of the model run (1 = Accepted, 0 = Not accepted), Divergent = Check whether the model internal algorithm discovers divergency and BRI = Brier score.",
        label = "tab:eu_test_stat"
        ) %>% 
    print(
        file = "./4_output/Plots and tables/EU_Test_Statistics.tex", 
        caption.placement = getOption("xtable.caption.placement", "top")
        )
```

#### World - Appendix

```{r}
path_to_store <- "./4_output/4.WORLD_high_res_CV_PRED_high_res/"
load(paste0(path_to_store, "test_stat.RData"))
convergence_new <- lapply(convergence, 1, FUN = mean) %>% unlist()

test_stat2 <-  
    cbind(
        AUC = auc.cv,
        Accuracy = accurr,
        TSS = tss,
        "TSS Thresh" = tss.thresh,
        Accepted = as.integer(as.logical(acceptance)),
        Divergent = convergence_new,
        BRI = bri
    ) %>% apply(., 2, as.numeric) 

xtable(test_stat2,
        caption = "Test statistics of the 25 cross-validation runs of the less conservative model runs. AUC = Area under the receiver operator curve, Accuracy = Accurracy of the models, TSS = True skill statistics, TSS Thresh = Threshold of suitability where Accuracy maximal, Accepted = Acceptance of the model run (1 = Accepted, 0 = Not accepted), Divergent = Check whether the model internal algorithm discovers divergency and BRI = Brier score.",
        label = "tab:world_test_stat"
     ) %>% 
    print(file = "./4_output/Plots and tables/WORLD_Test_Statistics.tex", caption.placement = getOption("xtable.caption.placement", "top"))
```

#### Summary - results

```{r}

test_stat3 <- c(test_stat %>% colMeans(), test_stat2 %>% colMeans()) %>% round(2)
test_stat3_sd <- c(test_stat %>% apply(., 2,sd), test_stat2 %>% apply(., 2,sd)) %>% round(5)

test_stat4 <- vector()

for (i in 1:14) {
   test_stat4[i] <- paste0(test_stat3[i], " ± ", test_stat3_sd[i])
}


test_stat5 <- c(0.9, 0.9, 0.9, NA, 1,0, 0.05,test_stat4) %>% matrix(nrow = 3, byrow = T)

rownames(test_stat5) <- c("Min. Thresh", "Europe", "World")
colnames(test_stat5) <- colnames(test_stat2)

test_stat5 %<>% t()

xtable(test_stat5,
        caption = "Min Thresholds (Min. Thresh) and mean test statistics of the 25 cross-validation runs of both the conservative (Europe) and less conservative (World) model runs. AUC = Area under the receiver operator curve, Accuracy = Accurracy of the models, TSS = True skill statistics, TSS Thresh = Threshold of suitability where Accuracy maximal, Accepted = Acceptance of the model run (1 = Accepted, 0 = Not accepted), Divergent = Check whether the model internal algorithm discovers divergency and BRI = Brier score. Values including  standard deviation calculated across the cross validation runs.",
        label = "tab:mean_test_stat"
        ) %>% 
    print(file = "./4_output/Plots and tables/MEAN_Test_Statistics.tex", caption.placement = getOption("xtable.caption.placement", "top"))


```


## Result map stacks
### Directory
```{r}
dir.create("./4_output/Result")
```

### Today {.tabset}
#### Mean over all CV-Runs and base datasets
```{r}
###### Europe
Curr_EU_mean <- rast("./4_output/2.EU_high_res_CV_PRED_high_res/Run_mean.tif")

path_to_store <- "./4_output/2.EU_high_res_CV_PRED_high_res/"
load(paste0(path_to_store, "test_stat.RData"))

thresh1 <- thresh_01(evaluation.cv)

Curr_EU_mean[["thresh"]] <- ifel(Curr_EU_mean > thresh1, 1, 0)


####### World
Curr_WORLD_mean <- rast("./4_output/4.WORLD_high_res_CV_PRED_high_res/Run_mean.tif")

path_to_store <- "./4_output/4.WORLD_high_res_CV_PRED_high_res/"
load(paste0(path_to_store, "test_stat.RData"))

thresh1 <- thresh_01(evaluation.cv)

Curr_WORLD_mean[["thresh"]] <- ifel(Curr_WORLD_mean > thresh1, 1, 0)


####### Final Map
final_map <- c(Curr_WORLD_mean[["thresh"]], Curr_EU_mean[["thresh"]]) %>% mean()

final_map <- ifel(final_map == 1, 2, final_map)
final_map <- ifel(final_map == 0.5, 1, final_map)

cls <- data.frame(id = seq(0, 2, 1), cover = c("Not Suitable", "1/2 Agrees", "Both Agree"))
levels(final_map) <- cls
```

#### Standard deviation
```{r}
Curr_ALL_std <- rast(c(
    "./4_output/2.EU_high_res_CV_PRED_high_res/Run_std.tif",
    "./4_output/4.WORLD_high_res_CV_PRED_high_res/Run_std.tif"
)) %>% mean()
```

#### Final stack
```{r}
final_res <- c(Curr_EU_mean, Curr_WORLD_mean, final_map, Curr_ALL_std)

names(final_res) <- c("EU_mean", "EU_thresh", "WORLD_mean", "WORLD_thresh", "final", "std")

terra::writeRaster(final_res, "./4_output/Result/TODAY_Final_map.tif", overwrite = T)
```

### Future {.tabset}
#### Mean overall CV-Runs and base datasets
```{r}
###### Europe
Fut_EU_mean <- rast("./4_output/5. EU_hig_res_CV_PRED_future/Run_mean.tif")

path_to_store <- "./4_output/5. EU_hig_res_CV_PRED_future/"
load(paste0(path_to_store, "test_stat.RData"))

thresh1 <- thresh_01(evaluation.cv)

Fut_EU_mean[["thresh"]] <- ifel(Fut_EU_mean > thresh1, 1, 0)


####### World
Fut_WORLD_mean <- rast("./4_output/6. WORLD_hig_res_CV_PRED_future/Run_mean.tif")

path_to_store <- "./4_output/6. WORLD_hig_res_CV_PRED_future/"
load(paste0(path_to_store, "test_stat.RData"))

thresh1 <- thresh_01(evaluation.cv)

Fut_WORLD_mean[["thresh"]] <- ifel(Fut_WORLD_mean > thresh1, 1, 0)


####### Final Map
final_map <- c(Fut_WORLD_mean[["thresh"]], Fut_EU_mean[["thresh"]]) %>% mean()

final_map <- ifel(final_map == 1, 2, final_map)
final_map <- ifel(final_map == 0.5, 1, final_map)

cls <- data.frame(id = seq(0, 2, 1), cover = c("Not Suitable", "1/2 Agrees", "Both Agree"))
levels(final_map) <- cls
```

#### Standard deviation
```{r}
Fut_ALL_std <- rast(c(
    "./4_output/5. EU_hig_res_CV_PRED_future/Run_std.tif",
    "./4_output/6. WORLD_hig_res_CV_PRED_future/Run_std.tif"
)) %>% mean()
```

#### Final stack
```{r}
final_res <- c(Fut_EU_mean, Fut_WORLD_mean, final_map, Fut_ALL_std)

names(final_res) <- c("EU_mean", "EU_thresh", "WORLD_mean", "WORLD_thresh", "final", "std")
terra::writeRaster(final_res, "./4_output/Result/FUTURE_Final_map.tif", overwrite = T)
```

### Germany Maps
```{r}
rast("./4_output/Result/TODAY_Final_map.tif") %>%
    crop(AOI[AOI$Name == "DEU", ]) %>%
    mask(AOI[AOI$Name == "DEU", ], filename = "./4_output/Result/TODAY_Final_map_GERMANY.tif", overwrite = TRUE)

rast("./4_output/Result/FUTURE_Final_map.tif") %>%
    crop(AOI[AOI$Name == "DEU", ]) %>%
    mask(AOI[AOI$Name == "DEU", ], filename = "./4_output/Result/FUTURE_Final_map_GERMANY.tif", overwrite = TRUE)
```

### Plots .{tabset}
```{r}
AOI <- st_read("./3_ready/AOI_border.shp")

download.file(
    url = "https://daten.gdz.bkg.bund.de/produkte/vg/vg2500/aktuell/vg2500_12-31.tm32.shape.zip",
    destfile = "./1_input/German_states.zip"
)

unzip(
    "./1_input/German_states.zip",
    exdir = "./1_input/German_States"
)

DE_districts <- st_read("./1_input/German_States/vg2500_12-31.tm32.shape/vg2500/VG2500_LAN.shp") %>%
    st_transform(st_crs(AOI))
```

#### Base - Europe

EU-wide and Germany-wide plots of the suitability for today, future prediction, and the standard deviations between all model runs

```{r}
save.to <- "./4_output/Plots and tables/"
pdf(
    file = paste0(save.to, "EU_plot", ".pdf"),
    width = 12,
    height = 9
   )

mat <- matrix(
    c(  1,1,1,2,
        1,1,1,3,
        4,5,5,6),
    nrow = 3, 
    byrow = T)

layout(mat, widths = c(0.25,0.25,0.25,0.25), heights = c(1,1,1.4))

my_col <- c("#ffffff", "#99d8c9", "#1e854b")
my_comp_type <- "rose"
my_comp_lable <- 3
my_comp_size <- 5
my_comp_pos <- c("right", "top")

final_res_curr <- rast("./4_output/Result/TODAY_Final_map.tif")
final_res_fut <- rast("./4_output/Result/FUTURE_Final_map.tif")

my_bbox <- 
    matrix(
        c(-1275875, 4470206, 3696405, 7957273), 
        byrow = F, 
        nrow = 2) %>% 
    bbox() %>% 
    extent()

plot_levels <- final_res_curr[["final"]] %>% 
    levels() %>% 
    .[[1]] %>% 
    .[,2]

minmax_curr <- final_res_curr[["std"]] %>% 
    terra::minmax() %>% 
    as.vector() %>% 
    multiply_by(100)

minmax_fut <- final_res_fut[["std"]] %>% 
    terra::minmax() %>% 
    as.vector() %>% 
    multiply_by(100)

SD_A <- final_res_curr[["std"]][] %>% mean(na.rm = T) %>% round(2)
SD_C <- final_res_fut[["std"]][] %>% mean(na.rm = T) %>% round(2)

par(mai=c(0,0,0,0), bg="white", xpd = NA)

mar <- c(0.5, 1, 2, 0.5)
#mar <- c(0,0,0,0)
pax <- list(
    side = c(1,2,3,4),
    tick = F,
    labels = F,
    cex.axis = 2,
    outer = F,
    mgp = c(1,-1,0)
)

inset <- c(0, 0, 0, 0)




{
plot(final_res_curr[["final"]], ext = my_bbox, col = my_col, legend = F, pax = pax, mar = mar,clip = F); plot(AOI$geometry, add = T)
legend("topleft", legend = "A) Current suitability", cex = 2, box.lty = 0, bg = NA, inset = inset,xpd = T)

plot(c(0,2),c(0,1),type = 'n', axes = F,xlab = '', ylab = '', main =  TeX("$\\textbf{Suitabiliy\\ categories}$"), cex.main = 2)
legend("center", legend = plot_levels, fill = my_col, cex = 2, box.lty = 0,xpd = T)


legend_image <- as.raster(matrix(rev(my_col), ncol=1))
plot(c(0,2),c(0,1),type = 'n', axes = F,xlab = '', ylab = '', main = TeX("$\\textbf{Standard\\ deviation\\ (SD)}$"), cex.main = 2)
text(x=0.5, y = seq(0.1,0.85,l=4), labels = seq(minmax_curr[1],minmax_curr[2],l=4) %>% round(0) %>% as.character()  %>% paste(., "%"), cex = 2,xpd = T)
rasterImage(legend_image, 0, 0, 0.2,1)

text(x=1.7, y = seq(0.1,0.85,l=4), labels = seq(minmax_fut[1],minmax_fut[2],l=4) %>% round(0) %>% as.character()  %>% paste(., "%"), cex = 2,xpd = T)
rasterImage(legend_image, 1.2, 0, 1.4,1)

text(-0.1, 0.5, "Map: B", srt = 90, xpd = T, cex =2)
text(1.1, 0.5, "Map: D", srt = 90, xpd = T, cex =2)


plot(final_res_curr[["std"]], ext = my_bbox, col = my_col, legend = F, pax = pax, mar = mar,clip = F); plot(AOI$geometry, add = T)
legend("topleft", legend = "B) SD of A", cex = 2, box.lty = 0, bg = NA, inset = inset,xpd = T)
legend("bottomleft", legend = paste("Mean SD =", SD_A*100, "%"), cex = 2, box.lty = 0, bg = NA, inset = inset,xpd = T)

plot(final_res_fut[["final"]], ext = my_bbox, col = my_col, legend = F, pax = pax, mar = mar,clip = F); plot(AOI$geometry, add = T)
legend("topleft", legend = "C) Future suitability", cex = 2, box.lty = 0, bg = NA, inset = inset,xpd = T)
plot(final_res_fut[["std"]], ext = my_bbox, col = my_col, legend = F, pax = pax, mar = mar,clip = F); plot(AOI$geometry, add = T)
legend("topleft", legend = "D) SD of C", cex = 2, box.lty = 0, bg = NA, inset = inset,xpd = T)
legend("bottomleft", legend = paste(TeX("Mean SD ="), SD_C*100, "%"), cex = 2, box.lty = 0, bg = NA, inset = inset,xpd = T)
}

dev.off()
```

#### Base - Germany

```{r}
pdf(
    file = paste0(save.to, "GERMANY_plot", ".pdf"),
    width = 12,
    height = 9
   )

# Create layout
mat <- matrix(
    c(  1,1,1,2,
        1,1,1,3,
        4,5,5,6),
    nrow = 3, 
    byrow = T)

layout(mat, widths = c(0.25,0.25,0.25,0.25), heights = c(1,1,1.4))

my_col <- c("#ffffff", "#99d8c9", "#1e854b")
my_comp_type <- "rose"
my_comp_lable <- 3
my_comp_size <- 5
my_comp_pos <- c("right", "top")

# load and prepare data
final_res_curr <- rast("./4_output/Result/TODAY_Final_map_GERMANY.tif")
final_res_fut <- rast("./4_output/Result/FUTURE_Final_map_GERMANY.tif")
my_bbox <- ext(final_res_curr)
my_bbox[4] %<>% multiply_by(1.03)

plot_levels <- final_res_curr[["final"]] %>% 
    levels() %>% 
    .[[1]] %>% 
    .[,2]
minmax_curr <- final_res_curr[["std"]] %>% 
    terra::minmax() %>% 
    as.vector() %>% 
    multiply_by(100)

minmax_fut <- final_res_fut[["std"]] %>% 
    terra::minmax() %>% 
    as.vector() %>% 
    multiply_by(100)

SD_A <- final_res_curr[["std"]][] %>% mean(na.rm = T) %>% round(2)
SD_C <- final_res_fut[["std"]][] %>% mean(na.rm = T) %>% round(2)



mar <- c(0.5, 1, 2, 0.5)
par(mai=c(0,1,0,0), bg="white")

pax <- list(
    side = c(1,2,3,4),
    tick = F,
    labels = F,
    cex.axis = 2,
    outer = F,
    mgp = c(1,-1,0)
)

inset <- c(0, 0, 0, 0)

#plot
{
plot(final_res_curr[["final"]], ext = my_bbox, col = my_col, legend = F, pax = pax, mar = mar,clip = F); plot(DE_districts$geometry[DE_districts$GF != 8], add = T)
legend("topleft", legend = "A) Current suitability", cex = 2, box.lty = 0, bg = NA, inset = inset,xpd = T)

plot(c(0,2),c(0,1),type = 'n', axes = F,xlab = '', ylab = '', main =  TeX("$\\textbf{Suitabiliy\\ categories}$"), cex.main = 2)
legend("center", legend = plot_levels, fill = my_col, cex = 2, box.lty = 0)


legend_image <- as.raster(matrix(rev(my_col), ncol=1))
plot(c(0,2),c(0,1),type = 'n', axes = F,xlab = '', ylab = '', main = TeX("$\\textbf{Standard\\ deviation\\ (SD)}$"), cex.main = 2)
text(x=0.5, y = seq(0.1,0.85,l=4), labels = seq(minmax_curr[1],minmax_curr[2],l=4) %>% round(0) %>% as.character()  %>% paste(., "%"), cex = 2)
rasterImage(legend_image, 0, 0, 0.2,1)

text(x=1.7, y = seq(0.1,0.85,l=4), labels = seq(minmax_fut[1],minmax_fut[2],l=4) %>% round(0) %>% as.character()  %>% paste(., "%"), cex = 2)
rasterImage(legend_image, 1.2, 0, 1.4,1)

text(-0.1, 0.5, "Map: B", srt = 90, xpd = T, cex =2)
text(1.1, 0.5, "Map: D", srt = 90, xpd = T, cex =2)

plot(final_res_curr$std, ext = my_bbox, col = my_col, legend = F, pax = pax, mar = mar,clip = F); plot(DE_districts$geometry[DE_districts$GF != 8], add = T)
legend("topleft", legend = "B) SD of A", cex = 2, box.lty = 0, bg = NA, inset = inset,xpd = T)
legend("bottomleft", legend = paste("Mean SD =", SD_A*100, "%"), cex = 2, box.lty = 0, bg = NA, inset = inset,xpd = T)


plot(final_res_fut[["final"]], ext = my_bbox, col = my_col, legend = F, pax = pax, mar = mar,clip = F); plot(DE_districts$geometry[DE_districts$GF != 8], add = T)
legend("topleft", legend = "C) Future suitability", cex = 2, box.lty = 0, bg = NA, inset = inset,xpd = T)
my_bbox <- ext(final_res_curr)
plot(final_res_fut[["std"]], ext = my_bbox, col = my_col, legend = F, pax = pax, mar = mar,clip = F); plot(DE_districts$geometry[DE_districts$GF != 8], add = T)
legend("topleft", legend = "D) SD of C", cex = 2, box.lty = 0, bg = NA, inset = inset,xpd = T)
legend("bottomleft", legend = paste("Mean SD =", SD_C*100, "%"), cex = 2, box.lty = 0, bg = NA, inset = inset,xpd = T)

}

dev.off()

```


# Predators {.tabset}
## Wolf
First, georeference the map from the paper: [Kramer-Schadt et al., 2020](https://doi.org/10.19217/skr556)

```{r}
# Load georeferenced map
wolf_work <- rast("./2_work/predators/wolf_work.tif")

# Crop
wolf_work %<>%
    crop(AOI[AOI$Name == "DEU", ]) %>%
    mask(AOI[AOI$Name == "DEU", ], filename = "./2_work/predators/wolf_work_crop.tif", overwrite = T)


wolf_work2 <- ifel(wolf_work %in% c(176, 234, 147, 148, 206, 197, 142, 149, 186, 139), 0, wolf_work)


wolf_work2 <- wolf_work2 %>% sum()

# Calculation
ifel(wolf_work2 %in% seq(100, 900, 1), 10, 0) %>% writeRaster("./2_work/predators/wolf_work3.tif", overwrite = T)

wbt_resample(
    inputs = "./2_work/predators/wolf_work3.tif",
    output = "./2_work/predators/wolf_work4.tif",
    base = "./4_output/Result/TODAY_Final_map.tif",
    method = "cc"
)

rast("./2_work/predators/wolf_work4.tif") %>%
    crop(AOI[AOI$Name == "DEU", ]) %>%
    mask(AOI[AOI$Name == "DEU", ], filename = "./2_work/predators/wolf_work5.tif", overwrite = T)

wolf_work5 <- rast("./2_work/predators/wolf_work5.tif")
wolf_work5 <- ifel(wolf_work5 > 8, 10, 0)
writeRaster(wolf_work5, "./2_work/predators/wolf_work5.tif", overwrite = T)

final_res_curr <- rast("./4_output/Result/TODAY_Final_map_GERMANY.tif")[["final"]]

# Change to categories
wolf_overlap <- ifel((final_res_curr + wolf_work5) <= 10, 0, (final_res_curr + wolf_work5))

cls <- data.frame(id = c(0, 11, 12), cover = c("No Overlap/Not Suitable", "1/2 Overlap", "Both Overlap"))
levels(wolf_overlap) <- cls

writeRaster(wolf_overlap, "./4_output/Predators/wolf_overlap.tif", overwrite = T)
```

## Lynx

```{r}
# Load georeferenced map
lynx_work <- rast("./2_work/predators/Lynx_referenced.tif") %>%
    terra::project(AOI)

# Crop
lynx_work %<>%
    crop(AOI[AOI$Name == "DEU", ]) %>%
    mask(AOI[AOI$Name == "DEU", ], filename = "./2_work/predators/lynx_work_crop.tif", overwrite = T)


lynx_work2 <- ifel(lynx_work %in% c(0, 1, 211, 183, 206), 0, lynx_work)


lynx_work2 <- lynx_work %>% sum()

# Calculation
ifel(lynx_work2 %in% c(seq(10, 30, 1), seq(450, 500, 1)), 10, 0) %>% writeRaster("./2_work/predators/lynx_work3.tif", overwrite = T)

wbt_resample(
    inputs = "./2_work/predators/lynx_work3.tif",
    output = "./2_work/predators/lynx_work4.tif",
    base = "./4_output/Result/TODAY_Final_map.tif",
    method = "cc"
)

rast("./2_work/predators/lynx_work4.tif") %>%
    crop(AOI[AOI$Name == "DEU", ]) %>%
    mask(AOI[AOI$Name == "DEU", ], filename = "./2_work/predators/lynx_work5.tif", overwrite = T)

lynx_work5 <- rast("./2_work/predators/lynx_work5.tif")
lynx_work5 <- ifel(lynx_work5 > 2, 10, 0)
writeRaster(lynx_work5, "./2_work/predators/lynx_work5.tif", overwrite = T)

final_res_curr <- rast("./4_output/Result/TODAY_Final_map_GERMANY.tif")[["final"]]

# Change into categories
lynx_overlap <- ifel((final_res_curr + lynx_work5) <= 3, 0, (final_res_curr + lynx_work5))

cls <- data.frame(id = c(0, 11, 12), cover = c("No Overlap/Not Suitable", "1/2 Overlap", "Both Overlap"))
levels(lynx_overlap) <- cls

writeRaster(lynx_overlap, "./4_output/Predators/lynx_overlap.tif", overwrite = T)
```

## Fox
Download data from: [GBIF](https://doi.org/10.15468/dl.usq8mf).

```{r}
download.file(
    "https://api.gbif.org/v1/occurrence/download/request/0250155-230224095556074.zip",
    "./1_input/Fox_occurrences.zip"
)

unzip(
    "./1_input/Fox_occurrences.zip",
    exdir = "./1_input/Fox_occurrences"
)

foxgbif <- read_delim("./1_input/Fox_occurrences/0250155-230224095556074.csv", delim = "\t")

foxgbif %<>%
    select(year, countryCode, decimalLatitude, decimalLongitude) %>%
    drop_na() %>%
    st_as_sf(coords = c("decimalLongitude", "decimalLatitude"), crs = 4326) %>%
    st_transform(crs = 4087) %>%
    mutate(source = rep("GBIF", nrow(.))) %>%
    .[AOI[AOI$Name == "DEU", ], ]

st_write(foxgbif, "./3_ready/predators/Fox_Occurrences.shp")

wbt_heat_map(
    input = "./3_ready/predators/Fox_Occurrences.shp",
    output = "./4_output/Predators/Fox_density.tif",
    bandwidth = 100000,
    kernel = "triangular",
    cell_size = 927.6624,
    base = "./4_output/Predators/wolf_overlap.tif"
)

fox_density <- rast("./4_output/Predators/Fox_density.tif")
fox_density %<>% crop(AOI[AOI$Name == "DEU", ]) %>% mask(AOI[AOI$Name == "DEU", ], filename = "./4_output/Predators/Fox_density.tif", overwrite = T)
```


### Base plot

```{r}
pdf(
    file = paste0(save.to, "Predator_plot", ".pdf"),
    width = 12.8,
    height = 
   )

mat <- matrix(
    c(  1,2,3,
        4,4,5),
    nrow = 2, 
    byrow = T)
layout(mat, widths = c(1,1,1), heights = c(1, 0.3))

my_col <- c("#ffffff", "#99d8c9", "#1e854b")
my_comp_type <- "rose"
my_comp_lable <- 3
my_comp_size <- 5
my_comp_pos <- c("right", "top")

wolf_overlap <- rast("./4_output/Predators/wolf_overlap.tif")
lynx_overlap <- rast("./4_output/Predators/lynx_overlap.tif")
fox_density <- rast("./4_output/Predators/Fox_density.tif")
fox_breaks <- c(0, 25, 50, 100, 200, 400, 800, Inf)
my_bbox <- ext(wolf_overlap)
my_bbox[4] %<>% multiply_by(1.015)

plot_levels <- wolf_overlap%>% 
    levels() %>% 
    .[[1]] %>% 
    .[,2]
minmax_curr <- fox_density%>% 
    terra::minmax() %>% 
    as.vector()

minmax_fut <- fox_density %>% 
    terra::minmax() %>% 
    as.vector()
par(mai=c(5,1,0,0), bg="white")
mar <- c(0.5, 1, 2, 0.5)
pax <- list(
    side = c(1,2,3,4),
    tick = F,
    labels = F,
    cex.axis = 2,
    outer = F
)

inset <- c(0, 0, -2, 0)

{
plot(wolf_overlap, ext = my_bbox, col = my_col, legend = F, pax = pax, mar = mar, clip = F); plot(DE_districts$geometry[DE_districts$GF != 8], add = T)
legend("topleft", legend = "A) Wolf overlap", cex = 2, box.lty = 0, bg = NA, inset = inset, xpd = T)

plot(lynx_overlap, ext = my_bbox, col = my_col, legend = F, pax = pax, mar = mar, clip = F); plot(DE_districts$geometry[DE_districts$GF != 8], add = T)
legend("topleft", legend = "B) Lynx overlap", cex = 2, box.lty = 0, bg = NA, inset = inset, xpd = T)

plot(fox_density, breaks = fox_breaks, ext = my_bbox, col = colorRampPalette(my_col)(length(fox_breaks)), legend = F, pax = pax, mar = mar, clip = F); plot(DE_districts$geometry[DE_districts$GF != 8], add = T)
legend("topleft", legend = "C) Fox density", cex = 2, box.lty = 0, bg = NA, inset = inset, xpd = T)

plot(c(0,2),c(0,1),type = 'n', axes = F,xlab = '', ylab = '', main =  TeX("$\\textbf{Suitabiliy\\ categories}$"), cex.main = 2)
legend("center", legend = plot_levels, fill = my_col, cex = 2, box.lty = 0)

plot(c(0,1),c(0,1),type = 'n', axes = F,xlab = '', ylab = '', main =  TeX("$\\textbf{Fox\\ density}$"), cex.main = 2)

legend_image <- as.raster(matrix(my_col, nrow=1))
text(x=seq(0.1,0.9,l=4), y = 0.3, labels = seq(minmax_curr[1],minmax_curr[2],l=4) %>% round(0), cex = 2, xpd = T)
rasterImage(legend_image, 0, 0.5, 1,0.8)
}

dev.off()
```

# Area calculations {.tabset}
## Europe
```{r}
## Today
final_res_curr <- rast("./4_output/Result/TODAY_Final_map.tif")[["final"]]
truesize <- terra::cellSize(final_res_curr, unit = "km") # using truesize for paying atention to the worlds distrortion
EU_curr_area <- terra::zonal(truesize, final_res_curr, fun = "sum") %>%
    mutate(proportion = area / sum(area))

## Future
final_res_fut <- rast("./4_output/Result/FUTURE_Final_map.tif")[["final"]]
truesize <- terra::cellSize(final_res_fut, unit = "km")
EU_fut_area <- terra::zonal(truesize, final_res_fut, fun = "sum") %>%
    mutate(proportion = area / sum(area))

## Overlap
writeRaster(rast("./4_output/Result/FUTURE_Final_map.tif")[["final"]], "./4_output/Area/FUTURE_Final_map_final.tif", overwrite = T)
wbt_resample(
    input = "./4_output/Area/FUTURE_Final_map_final.tif",
    output = "./4_output/Area/FUTURE_Final_map_final_hires.tif",
    base = "./4_output/Result/TODAY_Final_map.tif"
)

final_res_fut <- rast("./4_output/Area/FUTURE_Final_map_final_hires.tif")

cls <- data.frame(id = c(0, 1, 2), cover = c("No Overlap/Not Suitable", "1/2 Overlap", "Both Overlap"))
levels(final_res_fut) <- cl
writeRaster(final_res_fut, "./4_output/Area/FUTURE_Final_map_final_hires2.tif", overwrite = T)

final_res_fut <- rast("./4_output/Area/FUTURE_Final_map_final_hires2.tif")
same_class <- final_res_curr == final_res_fut
truesize <- terra::cellSize(same_class, unit = "km")
same_class_area <- terra::zonal(truesize, same_class, fun = "sum") %>%
    mutate(proportion = area / sum(area))
```

## Germany
```{r}
## Today
final_res_curr <- rast("./4_output/Result/TODAY_Final_map_GERMANY.tif")[["final"]]
truesize <- terra::cellSize(final_res_curr, unit = "km")
GER_curr_area <- terra::zonal(truesize, final_res_curr, fun = "sum") %>%
    mutate(proportion = area / sum(area))

## Future
final_res_fut <- rast("./4_output/Result/FUTURE_Final_map_GERMANY.tif")[["final"]]
truesize <- terra::cellSize(final_res_fut, unit = "km")
GER_fut_area <- terra::zonal(truesize, final_res_fut, fun = "sum") %>%
    mutate(proportion = area / sum(area))

## Overlap
writeRaster(rast("./4_output/Result/FUTURE_Final_map_GERMANY.tif")[["final"]], "./4_output/Area/FUTURE_Final_map_GERMANY_final.tif", overwrite = T)
wbt_resample(
    input = "./4_output/Area/FUTURE_Final_map_GERMANY_final.tif",
    output = "./4_output/Area/FUTURE_Final_map_GERMANY_final_hires.tif",
    base = "./4_output/Result/TODAY_Final_map_GERMANY.tif"
)

final_res_fut <- rast("./4_output/Area/FUTURE_Final_map_GERMANY_final_hires.tif")
cls <- data.frame(id = c(0, 1, 2), cover = c("No Overlap/Not Suitable", "1/2 Overlap", "Both Overlap"))
levels(final_res_fut) <- cls
writeRaster(final_res_fut, "./4_output/Area/FUTURE_Final_map_GERMANY_final_hires2.tif", overwrite = T)

final_res_fut <- rast("./4_output/Area/FUTURE_Final_map_GERMANY_final_hires2.tif")
same_class <- final_res_curr == final_res_fut
truesize <- terra::cellSize(same_class, unit = "km")
same_class_area <- terra::zonal(truesize, same_class, fun = "sum") %>%
    mutate(proportion = area / sum(area))
```

## Table of the covered areas in percent

```{r}
area_table <- GER_curr_area[,c(1,3)]  %>% 
    rename("Class" = final, "Germany current" = proportion) %>% 
    mutate(
        "Germany future" = GER_fut_area[,c(3)],
        "Europe current" = EU_curr_area[,3],
        "Europe future" = EU_fut_area[,3]
        )

area_table[,-1]  %<>% multiply_by(100)

xtable(area_table,
    caption = "Present and future area suitable for muntjac per assigned class in percent for Germany and Europe. Not Suitable = Both conservative and less conservative models reject that region, 1/2 Agrees = One of both indicates suitability for the muntjac, Both Agree = Both models agree in their prediction.",
    label = "tab:suit_areas"
) %>%
    print(file = "./4_output/Plots and tables/suitable areas.tex", caption.placement = getOption("xtable.caption.placement", "top"), include.rownames=FALSE)

```


## Predators
```{r}
## Overlapping area
wolf_overlap <- rast("./4_output/Predators/wolf_overlap.tif")
truesize <- terra::cellSize(wolf_overlap, unit = "km")
Wolf_area <- terra::zonal(truesize, wolf_overlap, fun = "sum") %>%
    mutate(proportion = area / sum(area))

lynx_overlap <- rast("./4_output/Predators/lynx_overlap.tif")
truesize <- terra::cellSize(lynx_overlap, unit = "km")
Lynx_area <- terra::zonal(truesize, lynx_overlap, fun = "sum") %>%
    mutate(proportion = area / sum(area))

## General coverage of predators

wolf_cover <- rast("./2_work/predators/wolf_work5.tif")
truesize <- terra::cellSize(wolf_cover, unit = "km")
Wolf_cover_area <- terra::zonal(truesize, wolf_cover, fun = "sum") %>%
    mutate(proportion = area / sum(area))

lynx_cover <- rast("./2_work/predators/lynx_work5.tif")
truesize <- terra::cellSize(lynx_cover, unit = "km")
Lynx_cover_area <- terra::zonal(truesize, lynx_cover, fun = "sum") %>%
    mutate(proportion = area / sum(area))


c(
    "Wolf_Muntjac_overlap" = Wolf_area[2:3, 3] %>% sum(),
    "Wolf_Cover_Germany" = Wolf_cover_area[2, 3]
)

c(
    "Lynx_Muntjac_overlap" = Lynx_area[2:3, 3] %>% sum(),
    "Lynx_Cover_Germany" = Lynx_cover_area[2, 3] - 0.01 # minus 1 % due to high digitalization fragments within the map
)
```

# Additional Plots
## MESS
Multivariate environmental simillarity surface 

### Load and prepare the data
```{r}
load("./3_ready/model input/PA_AOI.Rdata")

Presences.cv <- all_data$train.df %>%
    filter(pa == 1) %>%
    add_row(
        all_data$test.df %>%
            filter(pa == 1)
    )

all.points <- all_data$train.points %>%
    filter(pa == 1) %>%
    add_row(all_data$test.points %>% filter(pa == 1)) %>%
    add_row(all_data$train.points %>% filter(pa == 0)) %>%
    add_row(all_data$test.points %>% filter(pa == 0))

AOI <- st_read("./3_ready/AOI_border.shp")
```

### Calculations + Plot
```{r}
EU_environment <- rast("./3_ready/EU_environment.tif")
envMESS <- EU_environment[[
    c("slope", "bio_12", "bio_1", "water_distance", "trees")
]] %>%
    brick()
pointsMESS <- Presences.cv %>%
    select(c("slope", "bio_12", "bio_1", "water_distance", "trees")) %>%
    as.data.frame()
mess_raster_high <- 
    mess(
        x = envMESS,
        v = pointsMESS,
        full = FALSE
    )

mess_raster_high %<>% rast()
writeRaster(mess_raster_high, "./2_work/MESS_unscaled.tif", overwrite = T)

mess_raster_high <- rast("./2_work/MESS_unscaled.tif")

mess_extr <- terra::extract(mess_raster_high, all.points$geometry %>% st_coordinates()) %>%
    mutate(pa = all.points$pa) %>%
    as_tibble()

mess_extr %<>% .[complete.cases(.), ]
mess_eval <- ROCR::prediction(mess_extr$mess, mess_extr$pa)
mess_thresh <- ROCR::performance(mess_eval, measure = "acc")@x.values[[1]][which(ROCR::performance(mess_eval, measure = "acc")@y.values[[1]] == max(ROCR::performance(mess_eval, measure = "acc")@y.values[[1]]))] %>%
    unlist() %>%
    min()

mess_raster_high_new <- ifel(
    mess_raster_high > mess_thresh,
    2,
    ifel(mess_raster_high < 0, 0, 1)
)


cls <- data.frame(id = c(2, 1, 0), cover = c("Similar", "Different", "Not in Range"))
levels(mess_raster_high_new) <- cls

writeRaster(mess_raster_high_new, "./4_output/Result/MESS_final.tif")

mess_raster_high_new <- rast("./4_output/Result/MESS_final.tif")
my_bbox <- matrix(c(-1275875, 4470206, 3696405, 7907273), byrow = F, nrow = 2) %>% bbox()
my_col <- c("#ffffff", "#99d8c9", "#1e854b")
mess_plot <- tm_shape(mess_raster_high_new, bbox = my_bbox) + tm_raster(palette = my_col, legend.show = T, title = "MESS analysis") +
    tm_shape(AOI) + tm_borders(col = "black", lwd = 2)

tmap_save(
    tm = mess_plot,
    filename = "./4_output/Plots and tables/MESS.pdf",
    width = 10,
    height = 7,
    dpi = 300
    )

```


## Variable range
Plots between Europe and Asia

```{r}
most.important <- c("bio_1", "bio_12", "trees", "water_distance", "slope")


presence.points <- all.points[all.points$pa == 1, ] %>%
    .[AOI[AOI$Name %in% c("CHN", "TWN"), ], ]
presence.points %<>%
    rownames() %>%
    as.numeric()
TWN.env <- Presences.cv[presence.points, ] %>%
    select(all_of(most.important))

presence.points <- all.points[all.points$pa == 1, ] %>%
    .[AOI[AOI$Name %!in% c("CHN", "TWN"), ], ]
presence.points %<>%
    rownames() %>%
    as.numeric()
other.env <- Presences.cv[presence.points, ] %>%
    select(all_of(most.important))

all.melt <- melt(other.env) %>%
    rbind(melt(TWN.env)) %>%
    mutate(
        country = c(
            rep(
                "Europe",
                nrow(other.env) * ncol(other.env)
            ),
            rep(
                "Asia",
                nrow(TWN.env) * ncol(TWN.env)
            )
        )
    )

all.melt %<>%
    as_tibble() %>%
    mutate(variable = case_when(
        variable == "slope" ~ "Slope",
        variable == "bio_12" ~ "Mean Precipitation",
        variable == "bio_1" ~ "Mean Temperature",
        variable == "water_distance" ~ "Water Distance",
        variable == "trees" ~ "Tree Density"
    ))

g_plot1 <- grouped_ggbetweenstats(
    data = all.melt,
    x = country,
    y = value,
    grouping.var = variable,
    map_signif_level = T,
    pairwise.display = "all",
    type = "nonparametric",
    plot.type = "violin",
    point.args = list(alpha = 0),
    violin.args = list(aes(col = country), fill = NA, scale = "width", adjust = 1 / 2),
    results.subtitle = T,
    xlab = "Country",
    ylab = "Value",
    centrality.plotting = T,
    centrality.label.args = list(alpha = 0),
    centrality.point.args = list(col = "black", size = 4)
)

# extract subtitle
g_plot2 <- list()
for (i in 1:5) {
    g_plot2[[i]] <- extract_subtitle(g_plot1[[i]])
}

# paste necessary parts of the subtitle into the graph
for (i in 1:5) {
    g_plot1[[i]] <- g_plot1[[i]] + 
        labs(subtitle = g_plot2[[i]][c(1:3, 7)]) + 
        theme(
            panel.border = element_rect(colour = "black", fill=NA, linewidth=1))
}

ggsave(
    filename = paste0(save.to, "ggstat_env",".pdf"),
    plot = g_plot1,
    device = "pdf",
    width = 12.0,
    height = 7
   )

```


## World/AOI Plot

```{r}
world_border <- st_read("./3_ready/WORLD_border.shp")
AOI <- st_read("./3_ready/AOI_border.shp")
all_occs <- st_read("./3_ready/all_occs.shp")
my_col <- c("#ffffff", "#99d8c9", "#1e854b")

point_aoi_inter <- 
    st_intersects(all_occs, AOI, sparse = F) %>%
    apply(., 2, function(x) table(x)["TRUE"])
AOI %<>% 
    add_column(point_aoi_inter)

extent_Europe <- 
    AOI[AOI$Name %!in% c("CHN", "TWN"), ] %>% 
    extent() 

extent_Europe[1] %<>% 
    multiply_by(0.5)

extent_Europe[3] %<>% 
    multiply_by(1.2)

extent_Europe %<>% 
    multiply_by(1.1) %>% 
    as('SpatialPolygons') %>% 
    st_as_sf() %>% 
    mutate(text = "Non-native distribution")

st_crs(extent_Europe) <- st_crs(AOI)

extent_Asia <- 
    AOI[AOI$Name %in% c("CHN", "TWN"), ] %>% 
    extent()  %>% 
    multiply_by(1.1) %>% 
    as('SpatialPolygons') %>% 
    st_as_sf() %>% 
    mutate(text = "Endemic distribution")

st_crs(extent_Asia) <- st_crs(AOI)

extent_cons <- 
    AOI %>% 
    extent()

extent_cons[1] %<>% 
    multiply_by(0.5)

extent_cons %<>%
    multiply_by(1.2) %>% 
    as('SpatialPolygons') %>% 
    st_as_sf() %>% 
    mutate(text = "Conservative absence area")

st_crs(extent_cons) <- st_crs(AOI)

my_col <- c("#ffffff", "#99d8c9", "#1e854b")

###########################################

appendix_world_plot <- 
    tm_shape(world_border) +
        tm_fill(my_col[1]) +
        tm_borders("black") +

        tm_shape(extent_Europe) +
        tm_borders(my_col[3], lwd = 5, lty = "dashed") +
        tm_text("text", col = "black", size = 2, xmod = 0, ymod = -6, bg.color = "white") +

        tm_shape(extent_Asia) +
        tm_borders(my_col[2], lwd = 5, lty = "dashed") +
        tm_text("text", col = "black", size = 2, xmod = 0, ymod = 5.5, bg.color = "white") +

        tm_shape(extent_cons) +
        tm_borders("orange", lwd = 5, lty = "dashed") +
        tm_text("text", col = "black", size = 2, xmod = 0, ymod = -8, bg.color = "white") +

        tm_shape(AOI) +
        tm_fill(col = "point_aoi_inter", style = "log10", palette = my_col, title = paste("Occurrences per country\nn =", sum(AOI$point_aoi_inter, na.rm = T))) +
        tm_borders(col = "black") +


        tm_layout(legend.position = c("left", "bottom"), legend.bg.color = "white", legend.title.size = 1.5, legend.text.size = 1.4, frame.lwd = 5)

tmap_save(
    tm = appendix_world_plot,
    filename = "./4_output/Plots and tables/appendix_world.pdf",
    width = 16,
    height = 7,
    dpi = 300
    )
```



