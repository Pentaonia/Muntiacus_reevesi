---
title: "Muntjacs invading Germany"
subtitle: "Potential distribution of the small Deer (Cervidae) species Reeves’ Muntjac (Muntiacus reevesi) in Germany - Code documentation"
author: "Louis-Marvin Sander"
date: 
output:
  html_notebook:
    toc: true
    toc_float: true
    number_sections: true
    theme: united
  
---

```{r setup}
knitr::opts_chunk$set(eval = FALSE)
```


Generate the data outside of the repository.
```{r}
setwd(paste0(getwd(), "/.."))
```

# Preparation

## Packages
```{r}
library(raster)
library(tidyverse)
library(sf)
library(terra)
library(rgdal)
library(dismo)
library(tmap)
library(tmaptools)
library(magrittr)
library(pROC)
library(spdep)
library(stan4bart)
library(countrycode)
library(geodata)
library(whitebox)
library(readxl)
library(ROCR)
library(scales)
library(reshape2)
library(ggbreak)
library(ggstatsplot)
library(spatstat)
library(gridExtra)
```

## Seed
```{r}
set.seed(2121997)
```

## Self defined functions {.tabset}

### Negate
```{r}
`%!in%` <- Negate(`%in%`)
```

### Get n Minimal/Maximal result
List the first n results of a dataframe sorted by a column. Interesting for seeing the most collinear values late on.

Input:

- __a__ = data frame/tibble that sould be displayed
- __b__ = column to sort the results
- __c__ = number of rows that sould be displayed
- __mode__ = c("max", "min") means either sort decreasing or increasing.

Output:

- __result__ = ordered tibble with nrow() = c

```{r}
owncount <- function(a, b, c = ncol(a), mode = c("max", "min")) {
    mode <- ifelse(mode == "max", TRUE, FALSE)
    if (c > nrow(a)) c <- nrow(a)
    result <- tibble()
    b <- match(b, colnames(a))
    result <- a[order(a[, b], decreasing = mode), ] %>% head(., n = c)
    return(result)
}
```

### Data Preparation
It automatically appends the data set with randomly sampled absence points based on the extent of the SpatRaster and creates data frames that can be used in the modelling process
The data have to be in the same coordinate reference system.

Attention: Here is implemented directly the rule of thumb after Huberty 1994 for splitting into train and test data.

Inputs:

- __start__ = environment as a SpatRaster with different layers as predictors
- __species__ = sf object of occurrence points
- __most.important__ = vector of variables threatened as important ones that should be extracted from the SpatRaster
- __randoms__ = same as most.important but for the random variables

Output:

List of:

- __train.points__ = sf object of model training points
- __test.points__ = sf object of model test points
- __train.df__ = data frame of variables at train points + pa = column for presence absence
- __test.df__ = data frame of variables at test points + pa = column for presence absence
- __removedNA__ = removed points due to NA in an environmental layer

```{r}
fuzzySim::percentTestData(5) # in our case at the end 5 main variables

extraction_format <- function(start, species, most.important = NULL, randoms = NULL) {
    if (class(most.important) != "NULL") {
        start <- start[[c(most.important, randoms)]]
    }

    sample <- sample(
        c(TRUE, FALSE),
        nrow(species),
        replace = TRUE,
        prob = c(0.66, 0.33) # variable split after Huberty
    )

    species.train.points <- species[sample, ]
    species.test.points <- species[!sample, ]


    maxabsencepoints <- nrow(species.train.points)

    absences <- dismo::randomPoints(mask = start[[1]] %>% raster(), n = maxabsencepoints, p = species.train.points %>% st_coordinates())
    absences.train <- absences

    species.train.df <- data.frame(
        rbind(
            terra::extract(start, species.train.points, ID = F),
            terra::extract(start, absences)
        ),
        pa = c(rep(1, nrow(absences)), rep(0, nrow(species.train.points)))
    ) %>%
        as_tibble()


    maxabsencepoints <- nrow(species.test.points)

    absences <- dismo::randomPoints(mask = start[[1]] %>% raster(), n = maxabsencepoints, p = species.test.points %>% st_coordinates())
    absences.test <- absences

    species.test.df <- data.frame(
        rbind(
            terra::extract(start, species.test.points, ID = F),
            terra::extract(start, absences)
        ),
        pa = c(rep(1, nrow(absences)), rep(0, nrow(species.test.points)))
    ) %>%
        as_tibble()

    train.points <- species.train.points %>%
        mutate(pa = 1) %>%
        select(pa, geometry) %>%
        add_row(st_as_sf(absences.train %>% as_tibble(), coords = c("x", "y"), crs = st_crs(species.train.points)) %>% mutate(pa = 0))

    test.points <- species.test.points %>%
        mutate(pa = 1) %>%
        select(pa, geometry) %>%
        add_row(st_as_sf(absences.test %>% as_tibble(), coords = c("x", "y"), crs = st_crs(species.test.points)) %>% mutate(pa = 0))

    removedNA <- list(
        train.data = complete.cases(species.train.df) %>%
            table() %>%
            as_tibble() %>%
            rename("which" = ".") %>%
            mutate(which = c("Out", "In")),
        test.data = complete.cases(species.test.df) %>%
            table() %>%
            as_tibble() %>%
            rename("which" = ".") %>%
            mutate(which = c("Out", "In"))
    )
    train.points <- train.points[complete.cases(species.train.df), ]
    test.points <- test.points[complete.cases(species.test.df), ]
    species.train.df <- species.train.df[complete.cases(species.train.df), ]
    species.test.df <- species.test.df[complete.cases(species.test.df), ]

    return(
        list(
            train.points = train.points,
            test.points = test.points,
            train.df = species.train.df,
            test.df = species.test.df,
            removedNA = removedNA
        )
    )
}
```

### wbt_resample bugfix

I dont know when it is fixed, therefore I included the fixed function here.
For documentation see: [WhiteboxTools](https://cran.r-project.org/web/packages/whitebox/whitebox.pdf).

```{r}
wbt_resample <- function(
    inputs, output, cell_size = NULL, base = NULL, method = "cc",
    wd = NULL, verbose_mode = FALSE, compress_rasters = FALSE,
    command_only = FALSE) {
    wbt_init()
    args <- ""
    args <- paste(args, paste0("--inputs=", whitebox:::wbt_file_path(inputs)))
    args <- paste(args, paste0("--output=", whitebox:::wbt_file_path(output)))
    if (!is.null(cell_size)) {
        args <- paste(args, paste0("--cell_size=", cell_size))
    }
    if (!is.null(base)) {
        args <- paste(args, paste0("--base=", whitebox:::wbt_file_path(base)))
    }
    if (!is.null(method)) {
        args <- paste(args, paste0("--method=", method))
    }
    if (!missing(wd)) {
        args <- paste(args, paste0("--wd=", whitebox:::wbt_file_path(wd)))
    }
    if (!missing(compress_rasters)) {
        args <- paste(args, paste0("--compress_rasters=", compress_rasters))
    }
    tool_name <- "resample"
    wbt_run_tool(tool_name, args, verbose_mode, command_only)
}
```


### Multi collinearity
Adapted "multicol" function from the "fuzzySim"-Package to display more information in the result.

Input:

- __vars__ = data frame of environmental conditions
- __model__ = not needed in this context
- __reorder__ = order result at the end?

Output:

- result = tibble with several columns, nrow(result) = ncol(vars)
    - __Rsquared__ = R² of the built model
    - __Tolerance__ = 1 - R²
    - __VIF__ = Variance Inflation Factor 1 / (1 - R²)
    - __count__ = Number of collinear variables
    - __significant_vars__ = Significant collinear variables
    - __insignificant_vars__ = Not collinear variables

```{r}
multicol_own <- function(vars = NULL, model = NULL, reorder = TRUE) {
    if (is.null(vars)) {
        if (is.null(model)) {
            stop("You must provide either 'vars' or 'model'.")
        }
        if (!("glm" %in% class(model))) {
            stop("'model' must be an object of class 'glm'.")
        }
        vars <- model$model[, -1]
    }
    vars <- as.data.frame(vars)
    if (ncol(vars) < 2) {
        return(message("Cannot compute collinearity with less than two variables."))
    }

    result <- tibble(factor = colnames(vars))

    for (v in 1:ncol(vars)) {
        v.name <- colnames(vars)[v]
        other.v.names <- colnames(vars)[-v]
        mod.formula <- as.formula(paste(v.name, "~", paste(other.v.names,
            collapse = "+"
        )))
        mod <- lm(mod.formula, data = vars)
        R2 <- summary(mod)$r.squared
        result[v, "Rsquared"] <- R2
        result[v, "Tolerance"] <- 1 - R2
        result[v, "VIF"] <- 1 / (1 - R2)
        result[v, "count"] <- (summary(mod)$coefficients[, 4] < 0.05) %>%
            table() %>%
            .["TRUE"]
        result[v, "significant_vars"] <- enframe(list(names(summary(mod)$coefficients[, 4])[summary(mod)$coefficients[, 4] < 0.05][order(summary(mod)$coefficients[, 1][summary(mod)$coefficients[, 4] < 0.05])]))[2]
        result[v, "insignificant_vars"] <- enframe(list(names(summary(mod)$coefficients[, 4])[summary(mod)$coefficients[, 4] > 0.05][order(summary(mod)$coefficients[, 1][summary(mod)$coefficients[, 4] > 0.05])]))[2]
    }

    if (reorder) {
        result <- result[order(result$VIF, decreasing = TRUE), ]
    }
    return(result)
}
```


### Nearest distance
Creation of a vector that represents the distance of a point to the nearest feature.
This can be used if there is no raster available, for example if you want to use "distance to streets/urban areas".

Input:

- __a__ = sf object, here presence/absence points
- __b__ = sf object, here polygons of cities, lines of streets, ... it can also be a named list if more than one variable sould be added

Output:

- __distance__ = Distance of every point in _a_ to the nearest polygon in _b_

```{r}
nearestdistance_to <- function(a, b) {
    nearest <- vector()
    distance <- tibble(1:nrow(a))


    for (i in seq(1, length(b), 1)) {
        nearest <- st_nearest_feature(a, b[[i]])
        distance[, i] <- st_distance(a, b[[i]][nearest, ], by_element = TRUE) %>% as.vector()
    }
    names(distance) <- names(b)

    return(distance)
}
```

### Weights 
Creation of weights according to the number of features in a radius, means 0.5/n where n = number of points in a radius. 
That means, if n = 1 than the occurrence has one neighbor, therefore 0.5/1 = 0.5 and bot occurrences are weighted 0.5.
Default: the radius of a circle that results in the average territorial size of the muntjac according to ...

Input:

- __sf_geom__ = sf object of points, here muntjac occurrences
- __buffer_radius__ = radius of a circle that results in the size of an average territory

Output:

- vector of length(sf_geom) with values [1,0[.

```{r}
nbfunction <- function(sf_geom, buffer_radius = 298.5411) {
    # function from the spdep package, count of neighbours within a radius
    dnearneigh(sf_geom, 0, buffer_radius) %>%
        # set NA to 0 neigbours
        lapply(function(x) ifelse(x == 0, NA, length(x))) %>%
        lapply(unique) %>%
        unlist() %>%
        # calculate the weights
        (function(x) (0.5 / x)) %>%
        # division by 0 not possible, therefore exchange NA by 0
        ifelse(is.na(.), 1, .)
}
```

### Brier Score
Get data out of a ROCR-Object and calculate the brier score.

Input: 

- ROCR-Object

Output:

- Brier Score

```{r}
get_and_calc_bri <- function(x) {
    tru <- x@labels %>%
        unlist() %>%
        as.character() %>%
        as.numeric()
    preds <- x@predictions %>% unlist()

    return(
        (1 / length(tru) * sum((preds - tru)^2))
    )
}
```


### Easy prediction wrapper - NOT RECOMMENDED!
Predicts a stan4bart model to a SpatRaster of environmental variables.
Only recommended if the raster is relatively small, low number of predictions or predictions to different raster are pending.
If you often use the same raster stack for prediction, use the other function where you have to export your raster as table first.

Input:

- __model__ = stan4bart object with "keepTrees = T"
- __raster__ = SpatRaster with new environment (for prediction) or old environment (for inter/extrapolation)
- __type__ = one of types of predict.stan4bartFit

Output:

- __new_raster__ = Predicted raster

```{r}
raster_pred_stan4bart <- function(model, raster, type = "ev") {
    # Raster conversion to df and save places where not NA, afterwards remove NAs
    data_map_df <- as.matrix(raster, xy = F, na.rm = F, byrow = T) %>% as.data.frame()
    data_map_df_comp <- which(complete.cases(data_map_df))
    data_map_df <- data_map_df[data_map_df_comp, ]

    # predicting the df with help of the generic function
    new_data <- predict.stan4bartFit(
        object = model,
        newdata = data_map_df,
        type = type,
        combine_chains = TRUE,
        sample_new_levels = TRUE
    ) %>%
        rowMeans(na.rm = T) # Here you can tweak how many iterations should be included at the end. If the model needs a long time for reaching convergence it might be interesting to look at different stages. Looking at only one iteration at once, you can see the model "learning".

    # preparation to rasterize the df
    pre_raster <- rep(NA, ncell(raster))
    pre_raster[data_map_df_comp] <- new_data
    pre_raster %<>%
        matrix(
            nrow = nrow(raster),
            ncol = ncol(raster),
            byrow = T
        )

    # create the new raster
    new_raster <- rast(
        pre_raster,
        crs = crs(raster),
        extent = ext(raster)
    )

    return(new_raster)
}
```

### Efficient prediction

#### Raster preparation
Function that converts a raster into a table for efficient reuse in prediction function.

Input:

- __in_raster__ = Raster stack to be converted
- __in_vars__ = Names of the layers that should be converted
- __save.path__ = Path where to store + Base name of the documents. Attention: File ending and identifier are added automatically.


Output = Two output files:

- __*_na-free.txt__ = Raster as table, every column that does not match "complete.cases()" removed.
- __*_comp_cases.txt__ = Vector of line numbers that match "complete.cases()"

```{r}
raster_prep_stan4bart <- function(in_raster, in_vars, save.path = tempdir()) {
    data_map_df <- as.matrix(
        in_raster[[in_vars]],
        xy = F,
        na.rm = F,
        byrow = T
    ) %>%
        as.data.frame()

    data_map_df_comp <- which(complete.cases(data_map_df))
    data_map_df <- data_map_df[data_map_df_comp, ]

    write.table(data_map_df, paste0(save.path, "_na-free.txt"))

    write.table(data_map_df_comp, paste0(save.path, "_comp_cases.txt"))
}
```

#### Fast prediction
Prediction of a stan4bart-object to new data that has been prepaired with the "raster_prep_stan4bart"-function.

Input:

- __model__ = stan4bart-object
- __newdata__ = object created with read.table("*_na-free.txt")
- __complete_cases__ = object created with read.table("*_comp_cases.txt")
- __base_raster__ = raster with the same properties as the raster fron which the newdata object was created --> the function needs to know on which basis the resulting raster has to be built.
- __type__ = one of types of predict.stan4bartFit
- __coltake__ = object created in the for-loop lateron, is only needed if you want only a part of the iterations/chains in your result. It simply is a vector including values [1, iterations*chains] for every iteration (of chains) that should be used.

As the predicted chains and iterations are combined to one big matrix (colbind, one column per iteration) it aplies for creating __coltake__:

- 1. Chain [1, iterations-burn_in]
- 2. Chain [iterations-burn_in+1, (iterations-burn_in)*2]
- n. Chain [(iterations-burn_in)\*(n-1)+1, (iterations-burn_in)\*n]

Output:

- fast_result = Raster with the same properties than __base_raster__.

```{r}
fast_predict <- function(model, newdata, complete_cases, base_raster, type = "ev", coltake = NULL) {
    new_data <- predict(
        object = model,
        newdata = newdata,
        type = type,
        combine_chains = TRUE,
        sample_new_levels = TRUE
    )

    if (is.null(coltake)) {
        new_data %<>% rowMeans(na.rm = T)
    } else {
        new_data %<>%
            .[, coltake] %>%
            rowMeans(na.rm = T)
    }

    pre_raster <- rep(NA, ncell(base_raster))
    pre_raster[complete_cases$x] <- new_data
    pre_raster %<>%
        matrix(
            nrow = nrow(base_raster),
            ncol = ncol(base_raster),
            byrow = T
        )

    fast_result <- rast(
        pre_raster,
        crs = crs(base_raster),
        extent = ext(base_raster)
    )


    return(fast_result)
}
```

#### Finding the threshold
Here the function tries to find the threshold for a 1/0 classification of a map, according to a specific accurracy/confidence.

Input:

- __eval_list__ = ROCR-Object
- __thresh__ = confidence/accurracy threshold

Output:

- 1/0 classification threshold of [1,0]


```{r}
thresh_01 <- function(eval_list, thresh = 0.925) {
    lapply(eval_list, function(x) {
        ROCR::performance(x, measure = "acc")@x.values[[1]][which(ROCR::performance(x, measure = "acc")@y.values[[1]] > 0.925)] %>%
            unlist() %>%
            min()
    }) %>%
        unlist() %>%
        mean()
}
```


## Directories
```{r}
dir.create("./1_input/")
dir.create("./2_work")
dir.create("./3_ready")
dir.create("./4_output")
```

## Variables 
### Boundaries World and Area of interest {.tabset}
Choosen Coutries as area of interest (AOI)
```{r}
countryCodes <- tibble(isoA3 = vector(length = 40))
countryCodes$isoA3 <- c("AUT", "BEL", "BGR", "HRV", "CYP", "CZE", "DNK", "EST", "FIN", "FRA", "DEU", "GRC", "HUN", "IRL", "ITA", "LVA", "LTU", "LUX", "MLT", "NLD", "POL", "PRT", "ROU", "SVK", "SVN", "ESP", "SWE", "GBR", "TWN", "CHE", "NOR", "BLR", "UKR", "SRB", "MKD", "MNE", "BIH", "HRV", "MDA", "CHN")
countryCodes$isoA2 <- countrycode(countryCodes$isoA3, "iso3c", "iso2c")
```

#### World border 
Downloaded from [opendatasoft.com](https://public.opendatasoft.com/explore/dataset/world-administrative-boundaries/information/?location=2,44.59047,46.93359&basemap=jawg.light&dataChart=eyJxdWVyaWVzIjpbeyJjb25maWciOnsiZGF0YXNldCI6IndvcmxkLWFkbWluaXN0cmF0aXZlLWJvdW5kYXJpZXMiLCJvcHRpb25zIjp7fX0sImNoYXJ0cyI6W3siYWxpZ25Nb250aCI6dHJ1ZSwidHlwZSI6ImNvbHVtbiIsImZ1bmMiOiJDT1VOVCIsInNjaWVudGlmaWNEaXNwbGF5Ijp0cnVlLCJjb2xvciI6IiNGRjUxNUEifV0sInhBeGlzIjoic3RhdHVzIiwibWF4cG9pbnRzIjo1MCwic29ydCI6IiJ9XSwidGltZXNjYWxlIjoiIiwiZGlzcGxheUxlZ2VuZCI6dHJ1ZSwiYWxpZ25Nb250aCI6dHJ1ZX0%3D).

```{r}
world_border <- st_read("https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/world-administrative-boundaries/exports/kml?lang=en&timezone=Europe%2FBerlin")
st_write(world_border, "./1_input/world-administrative-boundaries.shp")

world_border %<>%
    select(Name, geometry) %>%
    st_transform(crs = 4087)

st_write(world_border, "./3_ready/WORLD_border.shp")
world_border <- st_read(("./3_ready/WORLD_border.shp"))
```

#### AOI border
Crop to AOI border
```{r}
AOI <- world_border

AOI %<>%
    select(Name, geometry) %>%
    filter(Name %in% countryCodes$isoA3)

st_write(AOI, "./3_ready/AOI_border.shp", append = F)
AOI <- st_read("./3_ready/AOI_border.shp")
```

### Response (Muntiacus reevesi occurrences) {.tabset}
#### GBIF
Source: [GBIF](https://www.gbif.org/occurrence/download/0065916-230224095556074)

```{r}
muntgbif <- read_delim("./1_input/occurrence.txt", delim = "\t")

muntgbif %<>%
    select(year, countryCode, decimalLatitude, decimalLongitude) %>%
    drop_na() %>%
    st_as_sf(coords = c("decimalLongitude", "decimalLatitude"), crs = 4326) %>%
    st_transform(crs = 4087) %>%
    mutate(source = rep("GBIF", nrow(.))) %>%
    unique() %>%
    distinct(geometry, .keep_all = T) %>%
    .[AOI, ]
```

#### Own extraction
Please find the document in the "important_files" directory and copy it to the "1_input" directory.

```{r}
muntown <- readxl::read_xlsx("./1_input/Own_muntiac.xlsx")

muntown %<>%
    st_as_sf(coords = c("decimalLongitude", "decimalLatitude"), crs = 4326) %>%
    st_transform(crs = 4087) %>%
    unique() %>%
    distinct(geometry, .keep_all = T) %>%
    mutate(year = as.numeric(year)) %>%
    .[AOI, ]
```

#### NBN Atlas 
Source: [NBN Atlas](https://ror.org/00mcxye41)

```{r}
muntnbn <- read_delim("./1_input/records-NBN.csv", delim = ",")

muntnbn %<>%
    select("year processed", "decimalLongitude processed", "decimalLatitude processed") %>%
    drop_na() %>%
    st_as_sf(coords = c("decimalLongitude processed", "decimalLatitude processed"), crs = 4326) %>%
    st_transform(crs = 4087) %>%
    mutate(source = rep("NBN", nrow(.)), countryCode = rep("GB", nrow(.))) %>%
    unique() %>%
    distinct(geometry, .keep_all = T) %>%
    .[AOI, ]

colnames(muntnbn)[1] <- "year"
```

#### Schleswig Holstein
Source: [Landesamt für Landwirtschaft, Umwelt und ländliche Räume in Schleswig-Holstein](https://www.schleswig-holstein.de/DE/landesregierung/ministerien-behoerden/LLUR/llur_node.html), received from [Dipl.-Geogr. Heiko Schmüser (CAU Kiel)](https://www.landscape-ecology.uni-kiel.de/de/team-1/heiko-schmueser)

Please find the document in the "important_files" directory and copy it to the "1_input" directory.

```{r}
muntsw <- st_read("./1_input/schmueser muntjac/20221219_MuntjakDaten_Multibase.shp")

muntsw %<>%
    select("Wolfsjahr", "geometry") %>%
    set_colnames(c("year", "geometry")) %>%
    drop_na() %>%
    st_transform(crs = 4087) %>%
    mutate(source = rep("SW", nrow(.)), countryCode = rep("DE", nrow(.))) %>%
    unique() %>%
    distinct(geometry, .keep_all = T) %>%
    .[AOI, ]

muntsw$year %<>% gsub(".*/", "", .) %>% as.numeric()
```

#### Combine to one dataset
```{r}
all_occs <- add_row(muntgbif, muntnbn) %>%
    add_row(muntown) %>%
    add_row(muntsw) %>%
    unique() %>%
    distinct(geometry, .keep_all = T)

rm(muntgbif, muntnbn, muntown, muntsw)

st_write(all_occs, "./2_work/all_occs.shp")
```

### Water bodies
Sources: [water bodies](https://hub.arcgis.com/content/esri::world-water-bodies/about) and [linear waters](https://www.arcgis.com/home/item.html?id=273980c20bc74f94ac96c7892ec15aff)

Preprocessing via QGIS:
- Combine both files
- Export as shape with CRS = EPSG4087

```{r}
water <- st_read("./2_work/world_water.shp")

water %<>%
    select(ISO_CC, geometry) %>%
    sf::st_simplify(dTolerance = 100)

st_write(water, "./2_work/water_simple.shp")
water <- st_read("./2_work/water_simple.shp")
```

#### Check occurrences of ones in waterbodies
```{r}
water_dubles <- all_occs %>% st_filter(water, .predicate = st_intersects)

all_occs %<>% .[all_occs$geometry %!in% water_dubles$geometry, ]

st_write(all_occs, "./3_ready/all_occs.shp", append = F)
```

### Road data
Source: [Natural Earth](https://naciscdn.org/naturalearth/10m/cultural/ne_10m_roads.zip)
```{r}
download.file(
    url = "https://naciscdn.org/naturalearth/10m/cultural/ne_10m_roads.zip",
    destfile = "./1_input/ne_10m_roads.zip"
)

unzip(
    "./1_input/ne_10m_roads.zip",
    exdir = "./1_input/"
)

roads <- st_read("./1_input/ne_10m_roads.shp")

roads %<>%
    select(type, name, length_km, continent, geometry) %>%
    filter(type != "Ferry Route", type != "Ferry, seasonal") %>%
    st_transform(crs = 4087)

st_write(roads, "./3_ready/roads.shp", append = F)
```

### Urban areas
Source: [Natural Earth](https://naciscdn.org/naturalearth/10m/cultural/ne_10m_urban_areas.zip)
```{r}
download.file(
    url = "https://naciscdn.org/naturalearth/10m/cultural/ne_10m_urban_areas.zip",
    destfile = "./1_input/ne_10m_urban_areas.zip"
)

unzip(
    "./1_input/ne_10m_urban_areas.zip",
    exdir = "./1_input/"
)

urban <- st_read("./1_input/ne_10m_urban_areas.shp")

urban %<>%
    select(area_sqkm, geometry) %>%
    st_transform(crs = 4087)

st_write(urban, "./3_ready/urban.shp", append = F)
```

### Elevation + Slope
```{r}
elevation <- elevation_global(res = 0.5, path = "./1_input/elevation")

elevation %<>% terra::project(AOI)

terra::writeRaster(elevation_work, "./2_work/elevation.tif", overwrite = T)

slope <- elevation %>%
    terra::terrain(
        v = c("slope"),
        unit = "degrees",
        filename = "./2_work/slope.tif",
        overwrite = T
    )

elevation <- rast("./2_work/elevation.tif")
slope <- rast("./2_work/slope.tif")
```

### Climate
```{r}
climate <- worldclim_global(
    var = "bio",
    res = 0.5,
    path = "./1_input/bioclim",
    version = "2.1"
)

climate %<>% terra::project(AOI)

terra::writeRaster(climate_work, "./2_work/climate.tif", overwrite = T)

climate <- rast("./2_work/climate.tif")
```

### Landcover
Get the data and prepare them for stacking with climate.

```{r}
landcover(var = "trees", path = "./1_input/landcover")
landcover(var = "grassland", path = "./1_input/landcover")
landcover(var = "shrubs", path = "./1_input/landcover")
landcover(var = "cropland", path = "./1_input/landcover")
landcover(var = "built", path = "./1_input/landcover")
landcover(var = "wetland", path = "./1_input/landcover")

landCover <- rast(paste0("./1_input/landcover/", list.files("./1_input/landcover")))

landCover %<>% terra::project(crs(AOI))

writeRaster(landCover, "./2_work/landcover.tif")

landCover <- rast("./2_work/landcover.tif")

mergerast <- rast(ext(climate$wc2.1_30s_bio_1), resolution = res(climate$wc2.1_30s_bio_1), crs = crs(climate), names = names(landCover), nlyrs = nlyr(landCover))

merge(mergerast, landCover, filename = "./2_work/landcover_merge.tif")
landCover <- rast("./2_work/landcover_merge.tif")
```

### Distance maps to Urban areas, Water and streets {.tabset}
#### Step I
The fist step was the rasterization of the urban areas, waters and streets in QGIS. R works too ineficient on large rasters. You can also try the ´fasterize´ function but its not working with MULTILINESTRING at the moment.

#### Step II
NAs have to be set to 0 for further processing in whitebox. Additionally the rasters were croped to the AOI.

```{r}
# Roads
WORLD_road_distance <- rast("./2_work/WORLD_roads_raster.tif")
WORLD_road_distance <- ifel(is.na(WORLD_road_distance), 0, WORLD_road_distance)
writeRaster(WORLD_road_distance, "./2_work/WORLD_roads_raster_0_1.tif", overwrite = T)
WORLD_road_distance %<>% mask(AOI) %>% crop(AOI)
writeRaster(WORLD_road_distance, "./2_work/AOI_roads_raster_0_1.tif", overwrite = T)

# Urban areas
WORLD_urban_distance <- rast("./2_work/WORLD_urban_raster.tif")
WORLD_urban_distance <- ifel(is.na(WORLD_urban_distance), 0, WORLD_urban_distance)
writeRaster(WORLD_urban_distance, "./2_work/WORLD_urban_raster_0_1.tif", overwrite = T)
WORLD_urban_distance %<>% mask(AOI) %>% crop(AOI)
writeRaster(WORLD_urban_distance, "./2_work/AOI_urban_raster_0_1.tif", overwrite = T)

# Water
WORLD_water_distance <- rast("./2_work/WORLD_water_raster.tif")
WORLD_water_distance <- ifel(is.na(WORLD_water_distance), 0, WORLD_water_distance)
writeRaster(WORLD_water_distance, "./2_work/WORLD_water_raster_0_1.tif", overwrite = T)
WORLD_water_distance %<>% mask(AOI) %>% crop(AOI)
writeRaster(WORLD_water_distance, "./2_work/AOI_water_raster_0_1.tif", overwrite = T)
```

#### Step III
Calculade eucledian distance maps via whitebox.

```{r}
wbt_euclidean_distance(
    "./2_work/AOI_roads_raster_0_1.tif",
    "./2_work/AOI_road_distance.tif"
)

wbt_euclidean_distance(
    "./2_work/AOI_urban_raster_0_1.tif",
    "./2_work/AOI_urban_distance.tif"
)

wbt_euclidean_distance(
    "./2_work/AOI_water_raster_0_1.tif",
    "./2_work/AOI_water_distance.tif"
)
```

### Combine
Combine all, crop to AOI and resample for faster preliminary model runs.

Note: The distane maps are not available in world size, therefore the distances to roads, waters and urban areas have to be extracted on an other way lateron.
That means that the AOI_environment.tif is fully self contained in all environmental factors that are needed but the WORLD_environment.tif is not.

```{r}
WORLD_environment <- terra::rast(
    c(
        "./2_work/elevation.tif",
        "./2_work/slope.tif",
        "./2_work/climate.tif",
        "./2_work/landcover_merge.tif"
    )
)

names(WORLD_environment) %<>% gsub(".*s_", "", .)

writeRaster(WORLD_environment, "./3_ready/WORLD_environment.tif")

WORLD_environment <- rast("./3_ready/WORLD_environment.tif")

AOI_environment <- WORLD_environment %>%
    crop(AOI) %>%
    mask(AOI) %>%
    c(
        .,
        rast(c(
            "./2_work/AOI_road_distance.tif",
            "./2_work/AOI_urban_distance.tif",
            "./2_work/AOI_water_distance.tif"
        ))
    )

names(AOI_environment) %<>% gsub("AOI_", "", .)

writeRaster(AOI_environment, "./3_ready/AOI_environment.tif")

AOI_environment <- rast("./3_ready/AOI_environment.tif")

EU_environment <- rast("./3_ready/AOI_environment.tif") %>%
    crop(AOI[AOI$Name %!in% c("TWN", "CHN"), ]) %>%
    terra::mask(AOI[AOI$Name %!in% c("TWN", "CHN"), ])

writeRaster(EU_environment, "./3_ready/EU_environment.tif")

EU_environment <- rast("./3_ready/EU_environment.tif")

# Resample with stacks is not possible at this moment in whitebox but will hopefully be included in future, therefore use the terra function, velox or QGIS.

wbt_resample(
    inputs = "./3_ready/WORLD_environment.tif",
    output = "./3_ready/WORLD_environment_low.tif",
    cell_size = 5000,
    method = "cc"
)

wbt_resample(
    inputs = "./3_ready/AOI_environment.tif",
    output = "./3_ready/AOI_environment_low.tif",
    cell_size = 5000,
    method = "cc"
)

wbt_resample(
    inputs = "./3_ready/EU_environment.tif",
    output = "./3_ready/EU_environment_low.tif",
    cell_size = 5000,
    method = "cc"
)

# Terra aggregrate

WORLD_environment_low <- terra::aggregate(WORLD_environment, fact = 10, filename = "./3_ready/WORLD_environment_low.tif")
AOI_environment_low <- terra::aggregate(AOI_environment, fact = 10, filename = "./3_ready/AOI_environment_low.tif")
EU_environment_low <- terra::aggregate(EU_environment, fact = 10, filename = "./3_ready/EU_environment_low.tif")

WORLD_environment_low <- rast("./3_ready/WORLD_environment_low.tif")
AOI_environment_low <- rast("./3_ready/AOI_environment_low.tif")
EU_environment_low <- rast("./3_ready/EU_environment_low.tif")
```


### Future conditions {.tabset}
#### Future climate
Source: [World Climate Reseach Programme](https://doi.org/10.22033/ESGF/CMIP6.4332)

Can be cropped directly because of no need of data outside of AOI for prediction.

```{r}
future_climate <- rast("./1_input/future data/wc2.1_2.5m_bioc_ACCESS-CM2_ssp585_2061-2080.tif")[[c(1, 12)]]

future_climate %<>% terra::project(AOI) %>%
    crop(AOI[AOI$Name %!in% c("TWN", "CHN"), ]) %>%
    terra::mask(AOI[AOI$Name %!in% c("TWN", "CHN"), ])

names(future_climate) <- c("bio_1", "bio_12")

dir.create("./2_work/future data")

writeRaster(future_climate, "./2_work/future data/EU_climate.tif", overwrite = T)
```

#### Future Urban
Source: [Land-Use Harmonization²](https://luh.umd.edu/data.shtml) and [Extractions made available here](https://doi.org/10.17161/bi.v16i1.15483)

For prediction only AOI is needed.

```{r}
future_urban <- rast("./1_input/future data/CMIP6_Land_Use_Harmonization_urban_SSP5_85_2071.tif")

future_urban %<>%
    terra::project(AOI) %>%
    crop(AOI[AOI$Name %!in% c("TWN", "CHN"), ]) %>%
    terra::mask(AOI[AOI$Name %!in% c("TWN", "CHN"), ])

writeRaster(future_urban, "./2_work/future data/urban_low.tif", overwrite = T)
```

#### Future Forest
Source: [Land-Use Harmonization²](https://luh.umd.edu/data.shtml) and [Extractions made available here](https://doi.org/10.17161/bi.v16i1.15483)

Here two forest raster files: primary and secondary forest.

```{r}
future_forest <- rast(c("./1_input/future data/CMIP6_Land_Use_Harmonization_primf_SSP5_85_2071.tif", "./1_input/future data/CMIP6_Land_Use_Harmonization_secdf_SSP5_85_2071.tif"))

future_forest <- future_forest[[1]] + future_forest[[2]]

future_forest %<>% terra::project(AOI) %>%
    crop(AOI[AOI$Name %!in% c("TWN", "CHN"), ]) %>%
    terra::mask(AOI[AOI$Name %!in% c("TWN", "CHN"), ])

writeRaster(future_forest, "./2_work/future data/forest_low.tif", overwrite = T)
```

#### Resampling
Attention: In my case, the whitebox had a bug in piping the resample function to the shell therefore I corrected the function.

```{r}
wbt_resample(
    inputs = "./2_work/future data/forest_low.tif",
    output = "./2_work/future data/forest_high.tif",
    base = "./2_work/future data/EU_climate.tif",
    method = "cc"
)

wbt_resample(
    inputs = "./2_work/future data/urban_low.tif",
    output = "./2_work/future data/urban_high.tif",
    base = "./2_work/future data/EU_climate.tif",
    method = "cc"
)

future_EU_environment <- rast("./3_ready/EU_environment.tif")[[c("slope", "water_distance", "road_distance")]]

writeRaster(future_EU_environment[[1]], "./2_work/future data/EU_environment_slope.tif")
writeRaster(future_EU_environment[[2]], "./2_work/future data/EU_environment_water_dist.tif")
writeRaster(future_EU_environment[[3]], "./2_work/future data/EU_environment_road_dist.tif")

wbt_resample(
    inputs = "./2_work/future data/EU_environment_slope.tif",
    output = "./2_work/future data/EU_environment_slope_final.tif",
    base = "./2_work/future data/EU_climate.tif",
    method = "cc"
)

wbt_resample(
    inputs = "./2_work/future data/EU_environment_water_dist.tif",
    output = "./2_work/future data/EU_environment_water_dist_final.tif",
    base = "./2_work/future data/EU_climate.tif",
    method = "cc"
)

wbt_resample(
    inputs = "./2_work/future data/EU_environment_road_dist.tif",
    output = "./2_work/future data/EU_environment_road_dist_final.tif",
    base = "./2_work/future data/EU_climate.tif",
    method = "cc"
)
```

#### New urban distance map
```{r}
future_urban <- rast("./2_work/future data/urban_high.tif")
future_urban <- ifel(is.na(future_urban) | future_urban < 0.1, 0, 1)
writeRaster(future_urban, "./2_work/future data/urban_distance.tif", overwrite = T)
future_urban %<>% mask(AOI) %>% crop(AOI)
writeRaster(future_urban, "./2_work/future data/urban_distance.tif", overwrite = T)

wbt_euclidean_distance(
    "./2_work/future data/urban_distance.tif",
    "./2_work/future data/urban_distance.tif"
)
```

#### Combine
```{r}
future_final <- rast(
    c(
        "./2_work/future data/EU_environment_slope_final.tif",
        "./2_work/future data/EU_environment_water_dist_final.tif",
        "./2_work/future data/EU_environment_road_dist_final.tif",
        "./2_work/future data/EU_climate.tif",
        "./2_work/future data/forest_high.tif",
        "./2_work/future data/urban_distance.tif"
    )
)

names(future_final) <- c("slope", "water_distance", "road_distance", "bio_1", "bio_12", "trees", "urban_distance")

writeRaster(future_final, "./3_ready/FUTURE_EU_environment.tif")

future_final <- rast("./3_ready/FUTURE_EU_environment.tif")
```

# Data extraction
```{r}
dir.create("./3_ready/model input")
```

## Input environment {.tabset}
### World high resolution
```{r}
all_data <- extraction_format(
    start = WORLD_environment,
    species = all_occs
)

all_data$train.df %<>%
    add_column(
        nearestdistance_to(
            all_data$train.points,
            list(
                road_distance = roads,
                urban_distance = urban,
                water_distance = water
            )
        )
    )

all_data$test.df %<>%
    add_column(
        nearestdistance_to(
            all_data$test.points,
            list(
                road_distance = roads,
                urban_distance = urban,
                water_distance = water
            )
        )
    )

save(all_data, file = "./3_ready/model input/PA_WORLD.Rdata")

load("./3_ready/model input/PA_WORLD.Rdata")
```

Now jump to the step "Collinearity", afterwards, when determine the least collinear variables, proceed here.

### AOI high resolution

```{r}
all_data <- extraction_format(
    start = AOI_environment,
    species = all_occs
)

save(all_data, file = "./3_ready/model input/PA_AOI.Rdata")

load("./3_ready/model input/PA_AOI.Rdata")
```

## Prediction environment

Define the choosen predictors and choosen randoms from the step "Collinearity".

```{r}
most.important <- c("bio_1", "bio_12", "trees", "water_distance", "slope")
randoms <- c("road_distance", "urban_distance")
```

Export raster environment as table for faster repetitive prediction.

```{r}
raster_prep_stan4bart(
    in_raster = rast("./3_ready/EU_environment.tif"),
    in_vars = c(most.important, randoms),
    save.path = "./3_ready/model input/EU_environment_rast"
)

raster_prep_stan4bart(
    in_raster = rast("./3_ready/EU_environment_low.tif"),
    in_vars = c(most.important, randoms),
    save.path = "./3_ready/model input/EU_environment_low_rast"
)

raster_prep_stan4bart(
    in_raster = rast("./3_ready/FUTURE_EU_environment.tif"),
    in_vars = c(most.important, randoms),
    save.path = "./3_ready/model input/FUTURE_environment_rast"
)
```

# Spatial Cluster Analysis
Analysis of spatial muntiac occurrence pattern. Assumed is a strong spatial clustering.

```{r}
load("./3_ready/model input/PA_AOI.Rdata")
Presences <- all_data$train.df %>%
    filter(pa == 1) %>%
    add_row(
        all_data$test.df %>%
            filter(pa == 1)
    )

Pres.points <- all_data$train.points %>%
    filter(pa == 1) %>%
    add_row(all_data$test.points %>% filter(pa == 1))

Presences.join <- Pres.points %>% cbind(Presences) %>% mutate(Name = seq(1, nrow(.), 1)) %>% st_transform()

AOI <- st_read("./3_ready/AOI_border.shp")

autocorr <- list()

## GB
autocorr$muntgbif_GB_ppp <- as.ppp(Presences.join$geometry[AOI[AOI$Name %in% c("GBR", "IRL"),]])
Window(autocorr$muntgbif_GB_ppp) <- as.owin(AOI[AOI$Name %in% c("GBR", "IRL"),])
unitname(autocorr$muntgbif_GB_ppp) <- "m/m"

## Taiwan
autocorr$muntgbif_TW_ppp <- as.ppp(Presences.join$geometry[AOI[AOI$Name %in% c("TWN"),]])
Window(autocorr$muntgbif_TW_ppp) <- as.owin(AOI[AOI$Name %in% c("TWN"),])
unitname(autocorr$muntgbif_TW_ppp) <- "m/m"

# Test against 100 Monte Carlo Iterations of complete spatial randomness
autocorr$GB_fest <-  envelope(autocorr$muntgbif_GB_ppp, fun = "Fest", nsim = 100, funargs = list(r = seq(0,14000,500)))
autocorr$TW_fest <-  envelope(autocorr$muntgbif_TW_ppp, fun = "Fest", nsim = 100, funargs = list(r = seq(0,14000,500)))

## GB Plot
autocorr$GB_fest_plot <- ggplot(autocorr$GB_fest, aes(x = r/1000, y = obs)) +
  geom_line(aes(), col = "black", lwd = 1.5) +
  geom_line(aes(y = theo), col = "red", lwd = 1.5) +
  geom_ribbon(aes(ymin = lo, ymax = hi), fill = "red", alpha = 0.5, show.legend = FALSE) +
  scale_colour_manual(name = 'F(r) statistics', 
    values = c('black'='black','red'='red'), labels = c('Observed','Theoretical')) +
  ylab("F(r)") + xlab("Radius (km)")+
  ggtitle("A)")

## TW Plot
autocorr$TW_fest_plot <- ggplot(autocorr$TW_fest, aes(x = r/1000, y = obs)) +
  geom_line(aes(col = "black"), lwd = 1.5) +
  geom_line(aes(y = theo, col = "red"), lwd = 1.5, show.legend = F) +
  geom_ribbon(aes(ymin = lo, ymax = hi, fill = "red"), alpha = 0.5, show.legend = FALSE) +
  scale_colour_manual(name = 'F(r) statistics', 
    values = c('black'='black','red'='red'), labels = c('Observed','Theoretical')) +
  ylab("F(r)") + xlab("Radius (km)") +
  ggtitle("B)")


#Inter-event distribution for Taiwanese and Brittish muntjac occurrences
grid.arrange(autocorr$GB_fest_plot, autocorr$TW_fest_plot, nrow = 1, widths = c(2.55,3))



#### Continent wide ####

## Europe
autocorr$muntgbif_GB_ppp <- as.ppp(Presences.join$geometry[AOI[AOI$Name %!in% c("TWN", "CHN"),]])
Window(autocorr$muntgbif_GB_ppp) <- as.owin(AOI[AOI$Name  %!in% c("TWN", "CHN"),])
unitname(autocorr$muntgbif_GB_ppp) <- "m/m"

## ASIA
autocorr$muntgbif_TW_ppp <- as.ppp(Presences.join$geometry[AOI[AOI$Name %in% c("TWN", "CHN"),]])
Window(autocorr$muntgbif_TW_ppp) <- as.owin(AOI[AOI$Name %in% c("TWN", "CHN"),])
unitname(autocorr$muntgbif_TW_ppp) <- "m/m"

# Test against 100 Monte Carlo Iterations of complete spatial randomness
autocorr$GB_fest <-  envelope(autocorr$muntgbif_GB_ppp, fun = "Fest", nsim = 100, funargs = list(r = seq(0,14000,500)))
autocorr$TW_fest <-  envelope(autocorr$muntgbif_TW_ppp, fun = "Fest", nsim = 100, funargs = list(r = seq(0,14000,500)))


## Europe Plot
autocorr$GB_fest_plot <- ggplot(autocorr$GB_fest, aes(x = r/1000, y = obs)) +
  geom_line(aes(), col = "black", lwd = 1.5) +
  geom_line(aes(y = theo), col = "red", lwd = 1.5) +
  geom_ribbon(aes(ymin = lo, ymax = hi), fill = "red", alpha = 0.5, show.legend = FALSE) +
  scale_colour_manual(name = 'F(r) statistics', 
    values = c('black'='black','red'='red'), labels = c('Observed','Theoretical')) +
  ylab("F(r)") + xlab("Radius (km)")+
  ggtitle("A)")

## Asia Plot
autocorr$TW_fest_plot <- ggplot(autocorr$TW_fest, aes(x = r/1000, y = obs)) +
  geom_line(aes(col = "black"), lwd = 1.5) +
  geom_line(aes(y = theo, col = "red"), lwd = 1.5, show.legend = F) +
  geom_ribbon(aes(ymin = lo, ymax = hi, fill = "red"), alpha = 0.5, show.legend = FALSE) +
  scale_colour_manual(name = 'F(r) statistics', 
    values = c('black'='black','red'='red'), labels = c('Observed','Theoretical')) +
  ylab("F(r)") + xlab("Radius (km)") +
  ggtitle("B)")


#Inter-event distribution for European and Asian muntjac occurrences
grid.arrange(autocorr$GB_fest_plot, autocorr$TW_fest_plot, nrow = 1, widths = c(2.55,3))
```

# Collinearity
```{r}
load("./3_ready/model input/PA_WORLD.Rdata")

col_test_df <- all_data$train.df %>%
    add_row(all_data$test.df) %>%
    filter(pa == 1)

col_result <- col_test_df %>%
    select(bio_1, bio_12, road_distance, trees, shrubs, cropland, water_distance, slope, grassland, urban_distance, water) %>%
    multicol_own()

owncount(col_result, "VIF", 10, "max")

col_result <- col_test_df %>%
    select(bio_1, bio_12, trees, water_distance, slope) %>%
    multicol_own()

owncount(col_result, "VIF", 10, "max")
```

Remaining variables: 
- Annual Precipitation (bio_12)
- Slope (slope)
- Annual Mean Temperature (bio_1)
- Tree cover in % (trees)
- Water distance in m (water_distance)

For expected sampling bias the following were included as random factors:
- Road distance (road_distance)
- Urban distance (urban_distance)

# Model
Create the necessary directories.
```{r}
dir.create("./4_output/1.EU_high_res_CV_PRED_low_res/")
dir.create("./4_output/2.EU_high_res_CV_PRED_high_res/")
dir.create("./4_output/3.WORLD_high_res_CV_PRED_low_res/")
dir.create("./4_output/4.WORLD_high_res_CV_PRED_high_res/")
dir.create("./4_output/5. EU_hig_res_CV_PRED_future/")
dir.create("./4_output/6. WORLD_hig_res_CV_PRED_future/")
```

Cross valiation loop, parameterization and predictions
```{r}
# Settings for the test runs:
cv.runs <- 5
iter_own <- 50
warmup_own <- 20
chains_own <- 2
trees_own <- 50


# Settings for the final run:
# cv.runs <- 25
# iter_own <- 500
# warmup_own <- 200
# chains_own <- 3
# trees_own <- 200

### In the following:
## Comment or uncomment the necessary parts for predicting AOI or WORLD data sets to high/low resolution EU or the FUTURE data set.
## The low resolution rasters were taken for finding the right parameterization (chains, iterations, trees, ...)

# ################ 1
# Predict from AOI to low EU
load("./3_ready/model input/PA_AOI.Rdata")
path_to_store <- "./4_output/1.EU_high_res_CV_PRED_low_res/"
prediction_to_what <- rast("./3_ready/EU_environment_low.tif")
data_map_df <- read.table("./3_ready/model input/EU_environment_low_rast_na-free.txt")
data_map_df_comp <- read.table("./3_ready/model input/EU_environment_low_rast_comp_cases.txt")


# ################ 2
# Predict from AOI to high EU
# load("./3_ready/model input/PA_AOI.Rdata")
# path_to_store <- "./4_output/2.EU_high_res_CV_PRED_high_res/"
# prediction_to_what <- rast("./3_ready/EU_environment.tif")
# data_map_df <- read.table("./3_ready/model input/EU_environment_rast_na-free.txt")
# data_map_df_comp <- read.table("./3_ready/model input/EU_environment_rast_comp_cases.txt")

# ################ 3
# Predict from WORLD to low EU
# load("./3_ready/model input/PA_WORLD.Rdata")
# path_to_store <- "./4_output/3.WORLD_high_res_CV_PRED_low_res/"
# prediction_to_what <- rast("./3_ready/EU_environment_low.tif")
# data_map_df <- read.table("./3_ready/model input/EU_environment_low_rast_na-free.txt")
# data_map_df_comp <- read.table("./3_ready/model input/EU_environment_low_rast_comp_cases.txt")

# ################ 4
# Predict from WORLD to high EU
# load("./3_ready/model input/PA_WORLD.Rdata")
# path_to_store <- "./4_output/4.WORLD_high_res_CV_PRED_high_res/"
# prediction_to_what <- rast("./3_ready/EU_environment.tif")
# data_map_df <- read.table("./3_ready/model input/EU_environment_rast_na-free.txt")
# data_map_df_comp <- read.table("./3_ready/model input/EU_environment_rast_comp_cases.txt")

################## 5
# Predict from AOI to FUTURE
# load("./3_ready/model input/PA_AOI.Rdata")
# path_to_store <- "./4_output/5. EU_hig_res_CV_PRED_future/"
# prediction_to_what <- rast("./3_ready/FUTURE_EU_environment.tif")
# data_map_df <- read.table("./3_ready/model input/FUTURE_environment_rast_na-free.txt")
# data_map_df_comp <- read.table("./3_ready/model input/FUTURE_environment_rast_comp_cases.txt")

################## 6
# Predict from WORLD to FUTURE
# load("./3_ready/model input/PA_WORLD.Rdata")
# path_to_store <- "./4_output/6. WORLD_hig_res_CV_PRED_future/"
# prediction_to_what <- rast("./3_ready/FUTURE_EU_environment.tif")
# data_map_df <- read.table("./3_ready/model input/FUTURE_environment_rast_na-free.txt")
# data_map_df_comp <- read.table("./3_ready/model input/FUTURE_environment_rast_comp_cases.txt")


# Do not change!
prediction.count.cv <- 0 # Has to be 0

# Empty output vectors
model.stan.cv <- list()
model.stan.predict.cv <- list()
PA_test_pred.cv <- list()
evaluation.cv <- list()
auc.cv <- list()
tss.thresh <- list()
tss <- list()
bri <- list()
accurr <- list()
acceptance <- list()
conf.matrix <- list()
convergence <- list()
tree_vars_imp <- list()

# Preparing data for CV
Presences.cv <- all_data$train.df %>%
    filter(pa == 1) %>%
    add_row(
        all_data$test.df %>%
            filter(pa == 1)
    )

Absences.cv <- all_data$train.df %>%
    filter(pa == 0) %>%
    add_row(
        all_data$test.df %>%
            filter(pa == 0)
    )

all.points <- all_data$train.points %>%
    filter(pa == 1) %>%
    add_row(all_data$test.points %>% filter(pa == 1)) %>%
    add_row(all_data$train.points %>% filter(pa == 0)) %>%
    add_row(all_data$test.points %>% filter(pa == 0))


#################### Automatic CV loop

for (i in 1:cv.runs) {

    # Random assembling of the data
    sample.pres <- sample(
        c(TRUE, FALSE),
        nrow(Presences.cv),
        replace = TRUE,
        prob = c(0.67, 0.33)
    )

    sample.abs <- sample(
        c(TRUE, FALSE),
        nrow(Absences.cv),
        replace = TRUE,
        prob = c(0.67, 0.33)
    )

    PA_train.cv <- Presences.cv[sample.pres, ] %>% rbind(Absences.cv[sample.abs, ])
    PA_train.cv %<>% .[, c(most.important, randoms, "pa")]
    PA_test.cv <- Presences.cv[!sample.pres, ] %>% rbind(Absences.cv[!sample.abs, ])
    PA_test.cv %<>% .[, c(most.important, randoms, "pa")]

    # Creating weights
    my_weights.cv <- nbfunction(all.points$geometry[c(sample.pres, sample.abs)], buffer_radius = 298.5411)
    print(paste("Weights", i, "created!"))

    # Defining and running the model
    model.stan.cv[[i]] <- stan4bart(
        formula = pa ~ bart(. - urban_distance - road_distance) +
            (1 + road_distance) + (1 + urban_distance),
        verbose = 1, # print progress
        data = PA_train.cv, # train data
        cores = 3, # Cores to use
        weights = my_weights.cv, # Weights to use
        chains = chains_own, # No. of independent created chains
        iter = iter_own, # No. of iterations and [result = iter - warmup]
        warmup = warmup_own, # No. of "iter" to draw and reject for warmup
        bart_args = list(
            weights = my_weights.cv, # Weights to use
            n.trees = trees_own, # No. of trees to form
            keepTrees = T, # Save trees for prediction
            combineChains = F, # Combine seperate chains to one
            n.chains = 1 # Nr. of MCMC-Chains within the bart component
        ),
    )

    print(paste("Model", i, "created!"))

    # Variable importance
    tree_vars_imp[[i]] <- apply(model.stan.cv[[i]]$bart_varcount, 3, FUN = rowMeans) %>%
        rowMeans() %>%
        as.data.frame() %>%
        cbind((apply(model.stan.cv[[i]]$bart_varcount, c(1, 3), FUN = sd) %>%
            rowMeans() %>%
            as.data.frame())) %>%
        setNames(c("mean", "sd")) %>%
        divide_by(sum(.$mean))

    # inclusion of coltake
    # tree_vars_imp[[i]] <- model.stan.cv[[i]]$bart_varcount %>% .[,coltake[1],] %>%
    #     rowMeans() %>%
    #     as.data.frame() %>%
    #     cbind((apply(model.stan.cv[[i]]$bart_varcount %>% .[,coltake[1],], 1, FUN = sd) %>%
    #         as.data.frame())) %>%
    #     setNames(c("mean", "sd")) %>%
    #     divide_by(sum(.$mean))



    # Definition of how many iterations and chains should be combined for prediction (needs to be activated in the prediction for testing and further down for the raster)
    # coltake <- seq(iter_own - warmup_own, (iter_own - warmup_own) * chains_own, iter_own - warmup_own)

    # Prediction of the model
    testpred <- predict(model.stan.cv[[i]], newdata = PA_test.cv) %>%
        # .[, coltake] %>% # uncomment if coltake should be used
        rowMeans()

    # Create a ROCR-object from the prediction + calculate several indices
    evaluation.cv[[i]] <- ROCR::prediction(testpred, PA_test.cv$pa)
    auc.cv[[i]] <- ROCR::performance(evaluation.cv[[i]], measure = "auc")@y.values %>%
        unlist() # area under the curve
    tss[[i]] <- max(
        ROCR::performance(evaluation.cv[[i]], measure = "tpr")@y.values %>%
            unlist() +
            ROCR::performance(evaluation.cv[[i]], measure = "tnr")@y.values %>%
            unlist() - 1
    ) # true skill statistics
    bri[[i]] <- get_and_calc_bri(evaluation.cv[[i]]) # brier score
    tss.thresh[[i]] <- ROCR::performance(evaluation.cv[[i]], measure = "acc")@x.values[[1]][which(ROCR::performance(evaluation.cv[[i]], measure = "acc")@y.values[[1]] == max(ROCR::performance(evaluation.cv[[i]], measure = "acc")@y.values[[1]]))] %>%
        unlist() %>%
        min() # "best" threshold at maximum accurracy
    accurr[[i]] <- max(ROCR::performance(evaluation.cv[[i]], measure = "acc")@y.values[[1]]) # accurracy
    acceptance[[i]] <- ifelse(accurr[[i]] > 0.9 & auc.cv[[i]] > 0.9 & bri[[i]] < 0.05, TRUE, FALSE) # can the model be accepted?
    convergence[[i]] <- model.stan.cv[[i]]$stan[6, , ] # internal convergence test

    # prediction if model is accepted
    if (acceptance[[i]]) {
        print(paste("Model", i, "accepted!"))
        prediction.count.cv <- prediction.count.cv + 1

        # Predict the model on basis of the new data (extracted rasters from before) and build new rasters
        model.stan.predict.cv <- fast_predict(
            model = model.stan.cv[[i]],
            newdata = data_map_df,
            complete_cases = data_map_df_comp,
            base_raster = prediction_to_what,
            type = "ev",
            coltake = NULL # exchange NULL to coltake if you want to use the coltake columns
        )


        names(model.stan.predict.cv) <- paste("Run", i)

        # Save created raster
        writeRaster(model.stan.predict.cv,
            paste0(path_to_store, "Run_", i, ".tif"),
            overwrite = T
        )
        print(paste("Model", i, "saved!"))


        # remove prediction from workspace
        rm(model.stan.predict.cv)
    } else {
        print(paste("Model", i, "rejected!"))
    }

    # save model and test results in case of PC crashing when calculating big models
    if (i %% 2 == 0) {
        save(evaluation.cv, auc.cv, tss.thresh, tss, acceptance, accurr, convergence, tree_vars_imp, bri, file = paste0(path_to_store, "test_stat.RData"))
    }
} # end of the loop

# save last state data
save(evaluation.cv, auc.cv, tss.thresh, tss, acceptance, accurr, convergence, tree_vars_imp, bri, file = paste0(path_to_store, "test_stat.RData"))

# load all created predictions
model.stan.predict.cv <- rast(paste0(path_to_store, list.files(path_to_store, pattern = "*.tif")))

# Calculate Mean and standard deviation
model.stan.predict.cv <- c(model.stan.predict.cv, model.stan.predict.cv %>% mean(na.rm = T))
model.stan.predict.cv <- c(model.stan.predict.cv, model.stan.predict.cv[[-(nlyr(model.stan.predict.cv))]] %>% stdev(na.rm = T))

# save mean
writeRaster(model.stan.predict.cv[["mean"]],
    paste0(path_to_store, "Run_mean.tif"),
    overwrite = T
)

# save standard deviation
writeRaster(model.stan.predict.cv[["std"]],
    paste0(path_to_store, "Run_std.tif"),
    overwrite = T
)
print("############### DONE! ###############")
```

# Exploring the data
## Load right data for further proceeding
Here you can run the necessary columns to load the data of a specific cv run.

```{r}
# ################ 1
# Predict from AOI to low EU
path_to_store <- "./4_output/1.EU_high_res_CV_PRED_low_res/"
load(paste0(path_to_store, "test_stat.RData"))
model.stan.predict.cv <- rast(paste0(path_to_store, list.files(path_to_store, pattern = "*.tif")))

# ################ 2
# Predict from AOI to high EU
path_to_store <- "./4_output/2.EU_high_res_CV_PRED_high_res/"
load(paste0(path_to_store, "test_stat.RData"))
model.stan.predict.cv <- rast(paste0(path_to_store, list.files(path_to_store, pattern = "*.tif")))

# ################ 3
# Predict from WORLD to low EU
path_to_store <- "./4_output/3.WORLD_high_res_CV_PRED_low_res/"
load(paste0(path_to_store, "test_stat.RData"))
model.stan.predict.cv <- rast(paste0(path_to_store, list.files(path_to_store, pattern = "*.tif")))

# ################ 4
# Predict from WORLD to high EU
path_to_store <- "./4_output/4.WORLD_high_res_CV_PRED_high_res/"
load(paste0(path_to_store, "test_stat.RData"))
model.stan.predict.cv <- rast(paste0(path_to_store, list.files(path_to_store, pattern = "*.tif")))

# ################ 5
# Predict from AOI to FUTURE
path_to_store <- "./4_output/5. EU_hig_res_CV_PRED_future/"
load(paste0(path_to_store, "test_stat.RData"))
model.stan.predict.cv <- rast(paste0(path_to_store, list.files(path_to_store, pattern = "*.tif")))

# ################ 6
# Predict from WORLD to FUTURE
path_to_store <- "./4_output/6. WORLD_hig_res_CV_PRED_future/"
load(paste0(path_to_store, "test_stat.RData"))
model.stan.predict.cv <- rast(paste0(path_to_store, list.files(path_to_store, pattern = "*.tif")))
```

## Variable importance
```{r}
tree_vars_imp_mean <- array(unlist(tree_vars_imp), dim = c(nrow(tree_vars_imp[[1]]), 2, length(tree_vars_imp))) %>%
    apply(1:2, mean) %>%
    as_tibble() %>%
    reframe(mean = V1, sd = V2)

# Mean Importance over all chains and iterations
ggplot(tree_vars_imp_mean * 100, aes(y = rownames(tree_vars_imp[[1]]), x = mean)) +
    geom_point() +
    geom_pointrange(aes(xmin = mean - sd, xmax = mean + sd)) +
    xlab("Permutation importance (percentage in which the predictor is responsible for a new branch) + mean SD across the chains and CV-runs") +
    ylab("Predictors in BART component")


# Convert matrix to data frame for use in ggplot2
my_dataframe <- reshape2::melt(tree_vars_imp, level = 2) %>% mutate(name = rep(rownames(tree_vars_imp[[1]]), max(L2) * 2))

# Create the plot with facets
# X-Axis = Iterations
# Y-Axis = Variable importance
# Boxplot = Importance of that variable over the iterations
# Line = Exact variable importance per iteration
ggplot(my_dataframe %>% filter(variable == "mean"), aes(x = L2, y = value, group = name)) +
    geom_line(aes(col = name)) +
    geom_boxplot(aes(col = name), fill = NA)
```

## Test statistics
```{r}
evaluation.cv # Can be used in the ROCR internal statistic functions

# pre evaluated statistics
auc.cv
tss.thresh
tss
acceptance
accurr
convergence
bri
```

## Result map stacks
### Directory
```{r}
dir.create("./4_output/Result")
```

### Today {.tabset}
#### Mean over all CV-Runs and base datasets
```{r}
Curr_EU_mean <- rast("./4_output/2.EU_high_res_CV_PRED_high_res/Run_mean.tif")

path_to_store <- "./4_output/2.EU_high_res_CV_PRED_high_res/"
load(paste0(path_to_store, "test_stat.RData"))

thresh1 <- thresh_01(evaluation.cv)

Curr_EU_mean[["thresh"]] <- ifel(Curr_EU_mean > thresh1, 1, 0)

####### World


Curr_WORLD_mean <- rast("./4_output/4.WORLD_high_res_CV_PRED_high_res/Run_mean.tif")

path_to_store <- "./4_output/4.WORLD_high_res_CV_PRED_high_res/"
load(paste0(path_to_store, "test_stat.RData"))

thresh1 <- thresh_01(evaluation.cv)

Curr_WORLD_mean[["thresh"]] <- ifel(Curr_WORLD_mean > thresh1, 1, 0)

final_map <- c(Curr_WORLD_mean[["thresh"]], Curr_EU_mean[["thresh"]]) %>% mean()

final_map <- ifel(final_map == 1, 2, final_map)
final_map <- ifel(final_map == 0.5, 1, final_map)

cls <- data.frame(id = seq(0, 2, 1), cover = c("Not Suitable", "1/2 Agrees", "Both Agree"))
levels(final_map) <- cls
```

#### Standard deviation
```{r}
Curr_ALL_std <- rast(c(
    "./4_output/2.EU_high_res_CV_PRED_high_res/Run_std.tif",
    "./4_output/4.WORLD_high_res_CV_PRED_high_res/Run_std.tif"
)) %>% mean()
```

#### Final stack
```{r}
final_res <- c(Curr_EU_mean, Curr_WORLD_mean, final_map, Curr_ALL_std)

names(final_res) <- c("EU_mean", "EU_thresh", "WORLD_mean", "WORLD_thresh", "final", "std")

terra::writeRaster(final_res, "./4_output/Result/TODAY_Final_map.tif", overwrite = T)
```

### Future {.tabset}
#### Mean over all CV-Runs and base datasets
```{r}
Fut_EU_mean <- rast("./4_output/5. EU_hig_res_CV_PRED_future/Run_mean.tif")

path_to_store <- "./4_output/5. EU_hig_res_CV_PRED_future/"
load(paste0(path_to_store, "test_stat.RData"))

thresh1 <- thresh_01(evaluation.cv)

Fut_EU_mean[["thresh"]] <- ifel(Fut_EU_mean > thresh1, 1, 0)

####### World

Fut_WORLD_mean <- rast("./4_output/6. WORLD_hig_res_CV_PRED_future/Run_mean.tif")

path_to_store <- "./4_output/6. WORLD_hig_res_CV_PRED_future/"
load(paste0(path_to_store, "test_stat.RData"))

thresh1 <- thresh_01(evaluation.cv)

Fut_WORLD_mean[["thresh"]] <- ifel(Fut_WORLD_mean > thresh1, 1, 0)

final_map <- c(Fut_WORLD_mean[["thresh"]], Fut_EU_mean[["thresh"]]) %>% mean()

final_map <- ifel(final_map == 1, 2, final_map)
final_map <- ifel(final_map == 0.5, 1, final_map)

cls <- data.frame(id = seq(0, 2, 1), cover = c("Not Suitable", "1/2 Agrees", "Both Agree"))
levels(final_map) <- cls
```

#### Standard deviation
```{r}
Fut_ALL_std <- rast(c(
    "./4_output/5. EU_hig_res_CV_PRED_future/Run_std.tif",
    "./4_output/6. WORLD_hig_res_CV_PRED_future/Run_std.tif"
)) %>% mean()
```

#### Final stack
```{r}
final_res <- c(Fut_EU_mean, Fut_WORLD_mean, final_map, Fut_ALL_std)

names(final_res) <- c("EU_mean", "EU_thresh", "WORLD_mean", "WORLD_thresh", "final", "std")
terra::writeRaster(final_res, "./4_output/Result/FUTURE_Final_map.tif", overwrite = T)
```

### Germany Maps
```{r}
rast("./4_output/Result/TODAY_Final_map.tif") %>%
    crop(AOI[AOI$Name == "DEU", ]) %>%
    mask(AOI[AOI$Name == "DEU", ], filename = "./4_output/Result/TODAY_Final_map_GERMANY.tif", overwrite = TRUE)

rast("./4_output/Result/FUTURE_Final_map.tif") %>%
    crop(AOI[AOI$Name == "DEU", ]) %>%
    mask(AOI[AOI$Name == "DEU", ], filename = "./4_output/Result/FUTURE_Final_map_GERMANY.tif", overwrite = TRUE)
```

### Plots
```{r}
AOI <- st_read("./3_ready/AOI_border.shp")

download.file(
    url = "https://daten.gdz.bkg.bund.de/produkte/vg/vg2500/aktuell/vg2500_12-31.tm32.shape.zip",
    destfile = "./1_input/German_states.zip"
)

unzip(
    "./1_input/German_states.zip",
    exdir = "./1_input/German_States"
)

DE_districts <- st_read("./1_input/German_States/vg2500_12-31.tm32.shape/vg2500/VG2500_LAN.shp") %>%
    st_transform(st_crs(AOI))
```

EU-wide and Germany-wide plots of the suitability, for today, future prediction and the standard deviations between all model runs

```{r}
# Europe
# my_col <- c("#F2F2F2", "#eea255", "#3daa62")
# my_col <- c("#a6cee3", "#1f78b4", "#b2df8a")
# my_col <- c("#8da0cb", "#66c2a5", "#fc8d62")
# my_col <- c("#ffffbf", "#fc8d59", "#91bfdb")
# my_col <- c("#edf8b1", "#7fcdbb", "#2c7fb8")
my_col <- c("#ffffff", "#99d8c9", "#1e854b")
my_comp_type <- "rose"
my_comp_lable <- 3
my_comp_size <- 5
my_comp_pos <- c("right", "top")


final_res_curr <- rast("./4_output/Result/TODAY_Final_map.tif")
final_res_fut <- rast("./4_output/Result/FUTURE_Final_map.tif")

my_bbox <- matrix(c(-1275875, 4470206, 3696405, 7907273), byrow = F, nrow = 2) %>% bbox()

curr_fin <- tm_shape(final_res_curr[["final"]], bbox = my_bbox) + tm_raster(palette = my_col, title = "A) Current suitability") +
    tm_shape(AOI) + tm_borders(col = "black", lwd = 2)

fut_fin <- tm_shape(final_res_fut[["final"]], bbox = my_bbox) + tm_raster(palette = my_col, title = "B) Future suitability") +
    tm_shape(AOI) + tm_borders(col = "black", lwd = 2)

curr_std <- tm_shape(final_res_curr[["std"]], bbox = my_bbox) + tm_raster(style = "cont", palette = my_col, title = "C) Current prediction \nstandard deviation") +
    tm_shape(AOI) + tm_borders(col = "black", lwd = 2)

fut_std <- tm_shape(final_res_fut[["std"]], bbox = my_bbox) + tm_raster(style = "cont", palette = my_col, title = "D) Future prediction \nstandard deviation") +
    tm_shape(AOI) + tm_borders(col = "black", lwd = 2) +
    tm_compass(type = my_comp_type, show.labels = my_comp_lable, size = my_comp_size, position = my_comp_pos)

tmap_arrange(
    curr_fin,
    fut_fin,
    curr_std,
    fut_std,
    nrow = 2
)
# Germany
final_res_curr <- rast("./4_output/Result/TODAY_Final_map_GERMANY.tif")
final_res_fut <- rast("./4_output/Result/FUTURE_Final_map_GERMANY.tif")


curr_fin <- tm_shape(final_res_curr[["final"]]) + tm_raster(palette = my_col, title = "A) Current suitability") +
    tm_shape(AOI) + tm_borders(col = "black", lwd = 2) +
    tm_shape(DE_districts$geometry[DE_districts$GF != 8]) + tm_borders(col = "black", lwd = 2)

fut_fin <- tm_shape(final_res_fut[["final"]]) + tm_raster(palette = my_col, title = "B) Future suitability") +
    tm_shape(AOI) + tm_borders(col = "black", lwd = 2) +
    tm_shape(DE_districts$geometry[DE_districts$GF != 8]) + tm_borders(col = "black", lwd = 2)

curr_std <- tm_shape(final_res_curr[["std"]]) + tm_raster(style = "cont", palette = my_col, title = "C) Current prediction \nstandard deviation") +
    tm_shape(AOI) + tm_borders(col = "black", lwd = 2) +
    tm_shape(DE_districts$geometry[DE_districts$GF != 8]) + tm_borders(col = "black", lwd = 2)

fut_std <- tm_shape(final_res_fut[["std"]]) + tm_raster(style = "cont", palette = my_col, title = "D) Future prediction \nstandard deviation") +
    tm_shape(AOI) + tm_borders(col = "black", lwd = 2) +
    tm_shape(DE_districts$geometry[DE_districts$GF != 8]) + tm_borders(col = "black", lwd = 2) +
    tm_compass(type = my_comp_type, show.labels = my_comp_lable, size = my_comp_size, position = my_comp_pos)

tmap_arrange(
    curr_fin,
    fut_fin,
    curr_std,
    fut_std,
    nrow = 2
)
```


# Predators {.tabset}

## Wolf
First, georeference the map from the paper: [Kramer-Schadt et al., 2020](https://doi.org/10.19217/skr556)

```{r}
# Load georeferenced map
wolf_work <- rast("./2_work/predators/wolf_work.tif")

# Crop

wolf_work %<>%
    crop(AOI[AOI$Name == "DEU", ]) %>%
    mask(AOI[AOI$Name == "DEU", ], filename = "./2_work/predators/wolf_work_crop.tif", overwrite = T)


wolf_work2 <- ifel(wolf_work %in% c(176, 234, 147, 148, 206, 197, 142, 149, 186, 139), 0, wolf_work)


wolf_work2 <- wolf_work2 %>% sum()
wolf_work2 %>% plot()


# Calculation
c(
    wolf_work2,
    ifel(wolf_work2 %in% seq(100, 900, 1), 10, 0)
) %>% plot()

ifel(wolf_work2 %in% seq(100, 900, 1), 10, 0) %>% writeRaster("./2_work/predators/wolf_work3.tif", overwrite = T)


wbt_resample(
    inputs = "./2_work/predators/wolf_work3.tif",
    output = "./2_work/predators/wolf_work4.tif",
    base = "./4_output/Result/TODAY_Final_map.tif",
    method = "cc"
)

rast("./2_work/predators/wolf_work4.tif") %>%
    crop(AOI[AOI$Name == "DEU", ]) %>%
    mask(AOI[AOI$Name == "DEU", ], filename = "./2_work/predators/wolf_work5.tif", overwrite = T)

wolf_work5 <- rast("./2_work/predators/wolf_work5.tif")
final_res_curr <- rast("./4_output/Result/TODAY_Final_map_GERMANY.tif")[["final"]]

wolf_overlap <- ifel((final_res_curr + wolf_work5) <= 10, 0, (final_res_curr + wolf_work5))

cls <- data.frame(id = c(0, 11, 12), cover = c("No Overlap/Not Suitable", "1/2 Overlap", "Both Overlap"))
levels(wolf_overlap) <- cls

writeRaster(wolf_overlap, "./4_output/Predators/wolf_overlap.tif", overwrite = T)

plot(rast("./4_output/Predators/wolf_overlap.tif"))
plot(DE_districts$geometry, add = T)
```

## Fox

Download DOI from: [GBIF](https://doi.org/10.15468/dl.usq8mf).

```{r}
download.file(
    "https://api.gbif.org/v1/occurrence/download/request/0250155-230224095556074.zip",
    "./1_input/Fox_occurrences.zip"
)

unzip(
    "./1_input/Fox_occurrences.zip",
    exdir = "./1_input/Fox_occurrences"
)

foxgbif <- read_delim("./1_input/Fox_occurrences/0250155-230224095556074.csv", delim = "\t")

foxgbif %<>%
    select(year, countryCode, decimalLatitude, decimalLongitude) %>%
    drop_na() %>%
    st_as_sf(coords = c("decimalLongitude", "decimalLatitude"), crs = 4326) %>%
    st_transform(crs = 4087) %>%
    mutate(source = rep("GBIF", nrow(.))) %>%
    .[AOI[AOI$Name == "DEU", ], ]

st_write(foxgbif, "./3_ready/predators/Fox_Occurrences.shp")

wbt_heat_map(
    input = "./3_ready/predators/Fox_Occurrences.shp",
    output = "./4_output/Predators/Fox_density.tif",
    bandwidth = 100000,
    kernel = "triangular",
    cell_size = 927.6624,
    base = "./4_output/Predators/wolf_overlap.tif"
)

fox_density <- rast("./4_output/Predators/Fox_density.tif")
fox_density %<>% crop(AOI[AOI$Name == "DEU", ]) %>% mask(AOI[AOI$Name == "DEU", ], filename = "./4_output/Predators/Fox_density.tif", overwrite = T)
```

## Plot
```{r}
wolf_overlap <- rast("./4_output/predator/wolf_overlap.tif")

wolf_over <- tm_shape(wolf_overlap) + tm_raster(palette = my_col, title = "B) Wolf overlap") +
    tm_shape(DE_districts$geometry[DE_districts$GF != 8]) + tm_borders(col = "black", lwd = 2) +
    tm_shape(AOI) + tm_borders(col = "black", lwd = 2) +
    tm_compass(type = my_comp_type, show.labels = my_comp_lable, size = my_comp_size, position = my_comp_pos)

fox_density <- rast("./4_output/predator/Fox_density.tif")

fox_breaks <- c(0, 25, 50, 100, 200, 400, 800, Inf)

fox_dens <- tm_shape(fox_density) + tm_raster(palette = my_col, title = "C) Fox densityy", breaks = fox_breaks) +
    tm_shape(DE_districts$geometry[DE_districts$GF != 8]) + tm_borders(col = "black", lwd = 2) +
    tm_shape(AOI) + tm_borders(col = "black", lwd = 2) +
    tm_compass(type = my_comp_type, show.labels = my_comp_lable, size = my_comp_size, position = my_comp_pos)

tmap_arrange(
    wolf_over,
    fox_dens,
    nrow = 1
)
```

# Area calculations {.tabset}
## Europe
```{r}
## Today
final_res_curr <- rast("./4_output/Result/TODAY_Final_map.tif")[["final"]]

truesize <- terra::cellSize(final_res_curr, unit = "km")

EU_curr_area <- terra::zonal(truesize, final_res_curr, fun = "sum") %>%
    mutate(proportion = area / sum(area))


## Future
final_res_fut <- rast("./4_output/Result/FUTURE_Final_map.tif")[["final"]]

truesize <- terra::cellSize(final_res_fut, unit = "km")

EU_fut_area <- terra::zonal(truesize, final_res_fut, fun = "sum") %>%
    mutate(proportion = area / sum(area))


## Overlap
writeRaster(rast("./4_output/Result/FUTURE_Final_map.tif")[["final"]], "./4_output/Area/FUTURE_Final_map_final.tif", overwrite = T)

wbt_resample(
    input = "./4_output/Area/FUTURE_Final_map_final.tif",
    output = "./4_output/Area/FUTURE_Final_map_final_hires.tif",
    base = "./4_output/Result/TODAY_Final_map.tif"
)

final_res_fut <- rast("./4_output/Area/FUTURE_Final_map_final_hires.tif")

cls <- data.frame(id = c(0, 1, 2), cover = c("No Overlap/Not Suitable", "1/2 Overlap", "Both Overlap"))
levels(final_res_fut) <- cls

writeRaster(final_res_fut, "./4_output/Area/FUTURE_Final_map_final_hires2.tif", overwrite = T)

final_res_fut <- rast("./4_output/Area/FUTURE_Final_map_final_hires2.tif")


same_class <- final_res_curr == final_res_fut

truesize <- terra::cellSize(same_class, unit = "km")

same_class_area <- terra::zonal(truesize, same_class, fun = "sum") %>%
    mutate(proportion = area / sum(area))
```

## Germany
```{r}
final_res_curr <- rast("./4_output/Result/TODAY_Final_map_GERMANY.tif")[["final"]]

truesize <- terra::cellSize(final_res_curr, unit = "km")

GER_curr_area <- terra::zonal(truesize, final_res_curr, fun = "sum") %>%
    mutate(proportion = area / sum(area))



# Future

final_res_fut <- rast("./4_output/Result/FUTURE_Final_map_GERMANY.tif")[["final"]]

truesize <- terra::cellSize(final_res_fut, unit = "km")

GER_fut_area <- terra::zonal(truesize, final_res_fut, fun = "sum") %>%
    mutate(proportion = area / sum(area))



## Overlap
writeRaster(rast("./4_output/Result/FUTURE_Final_map_GERMANY.tif")[["final"]], "./4_output/Area/FUTURE_Final_map_GERMANY_final.tif", overwrite = T)

wbt_resample(
    input = "./4_output/Area/FUTURE_Final_map_GERMANY_final.tif",
    output = "./4_output/Area/FUTURE_Final_map_GERMANY_final_hires.tif",
    base = "./4_output/Result/TODAY_Final_map_GERMANY.tif"
)

final_res_fut <- rast("./4_output/Area/FUTURE_Final_map_GERMANY_final_hires.tif")

cls <- data.frame(id = c(0, 1, 2), cover = c("No Overlap/Not Suitable", "1/2 Overlap", "Both Overlap"))
levels(final_res_fut) <- cls

writeRaster(final_res_fut, "./4_output/Area/FUTURE_Final_map_GERMANY_final_hires2.tif", overwrite = T)

final_res_fut <- rast("./4_output/Area/FUTURE_Final_map_GERMANY_final_hires2.tif")

same_class <- final_res_curr == final_res_fut

truesize <- terra::cellSize(same_class, unit = "km")

same_class_area <- terra::zonal(truesize, same_class, fun = "sum") %>%
    mutate(proportion = area / sum(area))
```

## Predators
```{r}
## Overlaping area
wolf_overlap <- rast("./4_output/Predators/wolf_overlap.tif")

truesize <- terra::cellSize(wolf_overlap, unit = "km")

Wolf_area <- terra::zonal(truesize, wolf_overlap, fun = "sum") %>%
    mutate(proportion = area / sum(area))
```

# MESS
Multivariate environmental simillarity surface 

## Load the data
```{r}
load("./3_ready/model input/PA_AOI.Rdata")

Presences.cv <- all_data$train.df %>%
    filter(pa == 1) %>%
    add_row(
        all_data$test.df %>%
            filter(pa == 1)
    )


all.points <- all_data$train.points %>%
    filter(pa == 1) %>%
    add_row(all_data$test.points %>% filter(pa == 1)) %>%
    add_row(all_data$train.points %>% filter(pa == 0)) %>%
    add_row(all_data$test.points %>% filter(pa == 0))

AOI <- st_read("./3_ready/AOI_border.shp")
```

## Plot
```{r}
EU_environment <- rast("./3_ready/EU_environment.tif")

envMESS <- EU_environment[[
    c("slope", "bio_12", "bio_1", "water_distance", "trees")
]] %>%
    brick()

pointsMESS <- Presences.cv %>%
    select(c("slope", "bio_12", "bio_1", "water_distance", "trees")) %>%
    as.data.frame()

mess_raster_high <- mess(
    x = envMESS,
    v = pointsMESS,
    full = FALSE
)

mess_raster_high %<>% rast()

writeRaster(mess_raster_high, "./2_work/MESS_unscaled.tif", overwrite = T)

mess_raster_high <- rast("./2_work/MESS_unscaled.tif")

mess_extr <- terra::extract(mess_raster_high, all.points$geometry %>% st_coordinates()) %>%
    mutate(pa = all.points$pa) %>%
    as_tibble()
mess_extr %<>% .[complete.cases(.), ]
mess_eval <- ROCR::prediction(mess_extr$mess, mess_extr$pa)
mess_thresh <- ROCR::performance(mess_eval, measure = "acc")@x.values[[1]][which(ROCR::performance(mess_eval, measure = "acc")@y.values[[1]] == max(ROCR::performance(mess_eval, measure = "acc")@y.values[[1]]))] %>%
    unlist() %>%
    min()

mess_raster_high_new <- ifel(
    mess_raster_high > mess_thresh,
    2,
    ifel(mess_raster_high < 0, 0, 1)
)


cls <- data.frame(id = c(2, 1, 0), cover = c("Similar", "Different", "Not in Range"))
levels(mess_raster_high_new) <- cls

writeRaster(mess_raster_high_new, "./4_output/Result/MESS_final.tif")

my_bbox <- matrix(c(-1275875, 4470206, 3696405, 7907273), byrow = F, nrow = 2) %>% bbox()

my_col <- c("#ffffff", "#99d8c9", "#1e854b")

tm_shape(mess_raster_high_new, bbox = my_bbox) + tm_raster(palette = my_col, legend.show = T, title = "MESS analysis") +
    tm_shape(AOI) + tm_borders(col = "black", lwd = 2)
```


# Vaiable range
Plots between Europe and Asia

```{r}
most.important <- c("bio_1", "bio_12", "trees", "water_distance", "slope")

presence.points <- all.points[all.points$pa == 1, ] %>%
    .[AOI[AOI$Name %in% c("CHN", "TWN"), ], ]
presence.points %<>%
    rownames() %>%
    as.numeric()
TWN.env <- Presences.cv[presence.points, ] %>%
    select(all_of(most.important))


presence.points <- all.points[all.points$pa == 1, ] %>%
    .[AOI[AOI$Name %!in% c("CHN", "TWN"), ], ]
presence.points %<>%
    rownames() %>%
    as.numeric()
other.env <- Presences.cv[presence.points, ] %>%
    select(all_of(most.important))




all.melt <- melt(other.env) %>%
    rbind(melt(TWN.env)) %>%
    mutate(
        country = c(
            rep(
                "Europe",
                nrow(other.env) * ncol(other.env)
            ),
            rep(
                "Asia",
                nrow(TWN.env) * ncol(TWN.env)
            )
        )
    )

all.melt %<>% 
    as_tibble() %>%
    mutate(variable = case_when(
        variable == "slope" ~ "Slope",
        variable == "bio_12" ~ "Mean Precipitation",
        variable == "bio_1" ~ "Mean Temperature",
        variable == "water_distance" ~ "Water Distance",
        variable == "trees" ~ "Tree Density"
        )
    )

g_plot1 <- grouped_ggbetweenstats(
    data = all.melt,
    x = country,
    y = value,
    grouping.var = variable,
    map_signif_level = T,
    pairwise.display = "all",
    type = "nonparametric",
    plot.type = "violin",
    point.args = list(alpha = 0),
    violin.args = list(aes(col = country), fill = NA, scale = "width", adjust = 1 / 2),
    results.subtitle = T,
    # subtitle = list("hi"),
    xlab = "Country",
    ylab = "Value",
    centrality.plotting = T,
    centrality.label.args = list(alpha = 0),
    centrality.point.args = list(col = "black", size = 4)
)

g_plot2 <- list()
for (i in 1:5) {
    g_plot2[[i]] <- extract_subtitle(g_plot1[[i]])
}

for (i in 1:5) {
    g_plot1[[i]] <- g_plot1[[i]] + labs(subtitle = g_plot2[[i]][c(1:3, 7)])
}

g_plot1
```

# World/AOI Plot
```{r}
world_border <- st_read("./3_ready/WORLD_border.shp")
AOI <- st_read("./3_ready/AOI_border.shp")

my_col <- c("#ffffff", "#99d8c9", "#1e854b")


tm_shape(world_border) +
    tm_fill(my_col[1]) +
    tm_borders("black") +
    tm_shape(AOI[AOI$Name %!in% c("CHN", "TWN"), ]) +
    tm_fill(my_col[3]) +
    tm_shape(AOI[AOI$Name %in% c("CHN", "TWN"), ]) +
    tm_fill(my_col[2]) +
    tm_add_legend(
        type = "fill",
        col = my_col[-1],
        labels = c("Endemic distribution", "Area of interest, Window of observation and invasive distribution"),
        title = "Muntjak Occurrences"
    ) +
    tm_add_legend(
        type = "line",
        col = c("#0400ff", "black"),
        labels = c("Conservative absence area", "Non-Conservative absence area"),
        lwd = 2,
        title = "Absence Areas"
    ) +
    tm_shape(AOI %>% st_union()) +
    tm_borders("#0400ff", lwd = 1) +
    tm_layout(legend.position = c("left", "bottom"), legend.bg.color = "white")
```